{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhvt00/PIPR/blob/master/models/PIPR_LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3tRl6ZSk8Oi"
      },
      "source": [
        "This notebook use for tunning model using embeddings file and language model embedder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz47D5H_R0UR"
      },
      "source": [
        "### Check GPU hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8kCH-Zfj2J_",
        "outputId": "c6152bd3-7114-4afd-eb16-4c5f5543300c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Feb  1 04:09:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-chmuAHjK8D0"
      },
      "source": [
        "### Download embedding files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrKgkXJA3wPb",
        "outputId": "3932056c-ac74-421f-b178-7efd3a4cb3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-01 04:09:19--  https://raw.githubusercontent.com/anhvt00/PIPR/master/embeddings/seq2tensor.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1104 (1.1K) [text/plain]\n",
            "Saving to: ‘seq2tensor.py’\n",
            "\n",
            "\rseq2tensor.py         0%[                    ]       0  --.-KB/s               \rseq2tensor.py       100%[===================>]   1.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-01 04:09:19 (37.9 MB/s) - ‘seq2tensor.py’ saved [1104/1104]\n",
            "\n",
            "--2022-02-01 04:09:19--  https://raw.githubusercontent.com/anhvt00/PIPR/master/embeddings/ac5_aph.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2335 (2.3K) [text/plain]\n",
            "Saving to: ‘ac5_aph.txt’\n",
            "\n",
            "ac5_aph.txt         100%[===================>]   2.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-01 04:09:19 (40.2 MB/s) - ‘ac5_aph.txt’ saved [2335/2335]\n",
            "\n",
            "--2022-02-01 04:09:19--  https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/S.cerevisae/yeast_pairs.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 179008 (175K) [text/plain]\n",
            "Saving to: ‘yeast_pairs.tsv’\n",
            "\n",
            "yeast_pairs.tsv     100%[===================>] 174.81K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2022-02-01 04:09:20 (11.3 MB/s) - ‘yeast_pairs.tsv’ saved [179008/179008]\n",
            "\n",
            "--2022-02-01 04:09:20--  https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/H.pylori/hp_pairs.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30791 (30K) [text/plain]\n",
            "Saving to: ‘hp_pairs.tsv’\n",
            "\n",
            "hp_pairs.tsv        100%[===================>]  30.07K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-02-01 04:09:20 (25.0 MB/s) - ‘hp_pairs.tsv’ saved [30791/30791]\n",
            "\n",
            "--2022-02-01 04:09:20--  https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/H.pylori/hp_dict.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 505633 (494K) [text/plain]\n",
            "Saving to: ‘hp_dict.tsv’\n",
            "\n",
            "hp_dict.tsv         100%[===================>] 493.78K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-02-01 04:09:20 (18.6 MB/s) - ‘hp_dict.tsv’ saved [505633/505633]\n",
            "\n",
            "--2022-02-01 04:09:21--  https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/S.cerevisae/yeast_dictionary.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1415079 (1.3M) [text/plain]\n",
            "Saving to: ‘yeast_dictionary.tsv’\n",
            "\n",
            "yeast_dictionary.ts 100%[===================>]   1.35M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-02-01 04:09:21 (35.0 MB/s) - ‘yeast_dictionary.tsv’ saved [1415079/1415079]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download file seq2tensor.py for converting protein sequences to tensors\n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/embeddings/seq2tensor.py\n",
        "\n",
        "# Download file ac5_aph.txt for ac5_aph embedding \n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/embeddings/ac5_aph.txt\n",
        "\n",
        "### Download interaction pairs and dictionary files\n",
        "# Download dictionary file (id: sequence)\n",
        "# Download dictionary file (id: sequence)\n",
        "# !wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast_pairs.tsv\n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/S.cerevisae/yeast_pairs.tsv\n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/H.pylori/hp_pairs.tsv\n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/H.pylori/hp_dict.tsv\n",
        "# Download pairs of proteins with labels file\n",
        "# !wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast_dictionary.tsv\n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Golden-tunning-datasets/S.cerevisae/yeast_dictionary.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiMnInVvlEjY"
      },
      "source": [
        "### Import libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBCZs6wgdV7E",
        "outputId": "87c4960b-9292-445c-8e26-288aba71f777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard_plugin_profile in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (57.4.0)\n",
            "Requirement already satisfied: gviz-api>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (1.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard_plugin_profile) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# Libraries for system and debug\n",
        "import sys\n",
        "import pdb\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Class for converting sequences to tensors\n",
        "from seq2tensor import s2t\n",
        "\n",
        "\n",
        "# Libraries for neural network training\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Input, Conv1D, Conv2D\n",
        "from tensorflow.keras.layers import Add, Flatten, subtract, multiply, concatenate\n",
        "from tensorflow.keras.layers import MaxPooling1D, AveragePooling1D, GlobalAveragePooling1D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow import keras\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "from tensorflow.keras.utils import get_custom_objects\n",
        "from tensorflow.keras.layers import Activation\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "# Import accessory modules\n",
        "import numpy as np\n",
        "import h5py\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "# For tensorboard extension\n",
        "!pip install -U tensorboard_plugin_profile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjxFKiABLDob"
      },
      "source": [
        "### Set CUDA environment variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjvCG7HCp0Af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6b395d-4c45-4978-ac22-02236a9ee63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "### Setting RAM GPU for training growth \n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "  try:\n",
        "    # Currently, memory growth needs to be the same across GPUs\n",
        "    for gpu in gpus:\n",
        "      tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "  except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# Optimisation Flags - Do not remove\n",
        "# ============================================\n",
        "\n",
        "# Disables caching (when set to 1) or enables caching (when set to 0) for just-in-time-compilation. When disabled,\n",
        "# no binary code is added to or retrieved from the cache.\n",
        "os.environ['CUDA_CACHE_DISABLE'] = '0' # orig is 0\n",
        "\n",
        "# When set to 1, forces the device driver to ignore any binary code embedded in an application \n",
        "# (see Application Compatibility) and to just-in-time compile embedded PTX code instead.\n",
        "# If a kernel does not have embedded PTX code, it will fail to load. This environment variable can be used to\n",
        "# validate that PTX code is embedded in an application and that its just-in-time compilation works as expected to guarantee application \n",
        "# forward compatibility with future architectures.\n",
        "os.environ['CUDA_FORCE_PTX_JIT'] = '1'# no orig\n",
        "\n",
        "\n",
        "os.environ['HOROVOD_GPU_ALLREDUCE'] = 'NCCL'\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
        "os.environ['TF_GPU_THREAD_COUNT']='1'\n",
        "\n",
        "os.environ['TF_USE_CUDNN_BATCHNORM_SPATIAL_PERSISTENT'] = '1'\n",
        "\n",
        "os.environ['TF_ADJUST_HUE_FUSED'] = '1'\n",
        "os.environ['TF_ADJUST_SATURATION_FUSED'] = '1'\n",
        "os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
        "\n",
        "os.environ['TF_SYNC_ON_FINISH'] = '0'\n",
        "os.environ['TF_AUTOTUNE_THRESHOLD'] = '2'\n",
        "os.environ['TF_DISABLE_NVTX_RANGES'] = '1'\n",
        "os.environ[\"TF_ENABLE_AUTO_MIXED_PRECISION_GRAPH_REWRITE\"] = \"1\"\n",
        "\n",
        "\n",
        "\n",
        "# =================================================\n",
        "# mixed_precision.set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYxewWysW5U5"
      },
      "source": [
        "### Hyperparameter set by default\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGt47faMW5U6"
      },
      "outputs": [],
      "source": [
        "# Default hyperparameters\n",
        "CONV_HIDDEN_DIM = 50\n",
        "RNN_HIDDEN = 50\n",
        "N_EPOCHS = 40\n",
        "HIDDEN_DIM=50\n",
        "BATCH_SIZE = 32\n",
        "DTYPE='float16'\n",
        "LEARNING_RATE=.001\n",
        "EPSILON=1e-6\n",
        "adam = Adam(learning_rate=LEARNING_RATE, amsgrad=True, epsilon=EPSILON)\n",
        "MAX_DATASET_SIZE = 11187\n",
        "DATASET_SIZE = MAX_DATASET_SIZE\n",
        "KERNEL_SIZE = 3\n",
        "POOLING_KERNEL = 3\n",
        "seq_size=2000\n",
        "dim = 1024\n",
        "# 1 for language model embedding\n",
        "flags_embedding = 0\n",
        "# 1 for loading from drive\n",
        "available_data = 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjTWZj-Bzebi"
      },
      "source": [
        "### Load the embeddings from drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHFMvEvzzd_3"
      },
      "outputs": [],
      "source": [
        "if available_data == 1:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    seq_tensor = np.load('/content/drive/MyDrive/seq_tensor.npy', allow_pickle=True)\n",
        "    # Load contextual embeddings here\n",
        "    # seq_tensor = np.load('/content/drive/MyDrive/Embeddings_Guo/15_amino_Word2VecEmbedder.npy', allow_pickle=True)\n",
        "\n",
        "    class_labels = np.load('/content/drive/MyDrive/class_labels.npy', allow_pickle=True)\n",
        "    seq_index1 = np.load('/content/drive/MyDrive/seq_index1.npy', allow_pickle=True)\n",
        "    seq_index2 = np.load('/content/drive/MyDrive/seq_index2.npy', allow_pickle=True)\n",
        "    # seq_tensor_physicochemical= np.load('/content/drive/MyDrive/physicochemical.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seq_tensor= tf.keras.preprocessing.sequence.pad_sequences(seq_tensor,  padding='post', dtype='float16', truncating='post', maxlen=seq_size)\n",
        "seq_tensor= tf.keras.preprocessing.sequence.pad_sequences(seq_tensor,  padding='post', dtype='float16', truncating='post', maxlen=2000)"
      ],
      "metadata": {
        "id": "qxFFnndUi4YX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "895d7c79-75a7-4b77-81bf-21616d6a416c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-aa7ebb40f9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# seq_tensor= tf.keras.preprocessing.sequence.pad_sequences(seq_tensor,  padding='post', dtype='float16', truncating='post', maxlen=seq_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mseq_tensor\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'seq_tensor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_tensor.shape"
      ],
      "metadata": {
        "id": "9BYspImh8e-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq_tensor_list = []\n",
        "# for i in range(len(seq_tensor)):\n",
        "#   seq_tensor_list.append(seq_tensor[i].astype('float16'))\n"
      ],
      "metadata": {
        "id": "T6Uk7q4j3wpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq_tensor = seq_tensor_list"
      ],
      "metadata": {
        "id": "Jn1wxgvJ9Bqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq_tensor_list = 0"
      ],
      "metadata": {
        "id": "gFCQ88bk-WFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seq_tensor[0]"
      ],
      "metadata": {
        "id": "Xgv4VV8h9FZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHCkDUohpFt8"
      },
      "outputs": [],
      "source": [
        "# seq_tensor = np.concatenate((seq_tensor, seq_tensor_physicochemical), axis=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TpKS4zsW5U8"
      },
      "source": [
        "### Use universal embedding files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkpDLs-yW5U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81191b24-fd5e-4609-9422-52834c17c856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "11188it [00:00, 62952.77it/s]\n",
            "100%|██████████| 2497/2497 [00:04<00:00, 542.53it/s]\n",
            "100%|██████████| 11187/11187 [00:00<00:00, 282054.13it/s]\n",
            "100%|██████████| 11187/11187 [00:00<00:00, 1108106.91it/s]\n"
          ]
        }
      ],
      "source": [
        "if available_data == 0:\n",
        "  id2seq_file = 'yeast_dictionary.tsv'\n",
        "  id2index = {}\n",
        "  seqs = []\n",
        "  index = 0\n",
        "  sid1_index = 0\n",
        "  sid2_index = 1\n",
        "  ds_file = 'yeast_pairs.tsv'\n",
        "  label_index = 2\n",
        "  use_emb = 'ac5_aph.txt'\n",
        "\n",
        "\n",
        "  # Create line variable as a list of protein sequences with index is the number of protein sequences\n",
        "  # id2index is a dictionary of protein id and incremental index number \n",
        "  for line in open(id2seq_file):\n",
        "      line = line.strip().split('\\t')\n",
        "      id2index[line[0]] = index\n",
        "      seqs.append(line[1])\n",
        "      index += 1\n",
        "\n",
        "  seq_array = []\n",
        "  id2_aid = {}\n",
        "  sid = 0\n",
        "\n",
        "  seq2t = s2t(use_emb)\n",
        "\n",
        "  max_data = -1\n",
        "  limit_data = max_data > 0\n",
        "  raw_data = []\n",
        "  skip_head = True\n",
        "  x = None\n",
        "  count = 0\n",
        "\n",
        "  # Create sequence array as a list of protein strings\n",
        "  for line in tqdm(open(ds_file)):\n",
        "      if skip_head:\n",
        "          skip_head = False\n",
        "          continue\n",
        "      line = line.rstrip('\\n').rstrip('\\r').split('\\t')\n",
        "      if id2index.get(line[sid1_index]) is None or id2index.get(line[sid2_index]) is None:\n",
        "          continue\n",
        "      if id2_aid.get(line[sid1_index]) is None:\n",
        "          id2_aid[line[sid1_index]] = sid\n",
        "          sid += 1\n",
        "          seq_array.append(seqs[id2index[line[sid1_index]]])\n",
        "      line[sid1_index] = id2_aid[line[sid1_index]]\n",
        "      if id2_aid.get(line[sid2_index]) is None:\n",
        "          id2_aid[line[sid2_index]] = sid\n",
        "          sid += 1\n",
        "          seq_array.append(seqs[id2index[line[sid2_index]]])\n",
        "      line[sid2_index] = id2_aid[line[sid2_index]]\n",
        "      raw_data.append(line)\n",
        "      if limit_data:\n",
        "          count += 1\n",
        "          if count >= max_data:\n",
        "              break\n",
        "\n",
        "  len_m_seq = np.array([len(line.split()) for line in seq_array])\n",
        "  avg_m_seq = int(np.average(len_m_seq)) + 1\n",
        "  max_m_seq = max(len_m_seq)\n",
        "  dim = seq2t.dim\n",
        "\n",
        "  # seq_tensor is tensor representation of dataset having shape of (number_of_sequences, padding_length, embedding_dim_of_aa)\n",
        "  # Random for distribution of class labels\n",
        "  np.random.seed(42)\n",
        "  np.random.shuffle(raw_data)\n",
        "  seq_tensor = np.array([seq2t.embed_normalized(line, seq_size) for line in tqdm(seq_array)]).astype('float16')\n",
        "\n",
        "  # Extract index of 1st and 2nd sequences in pairs\n",
        "  seq_index1 = np.array([line[sid1_index] for line in tqdm(raw_data)])\n",
        "  seq_index2 = np.array([line[sid2_index] for line in tqdm(raw_data)])\n",
        "\n",
        "  # Assign labels for pairs of sequences\n",
        "  class_map = {'0':1,'1':0}\n",
        "  class_labels = np.zeros((len(raw_data), 2))\n",
        "  for i in range(len(raw_data)):\n",
        "      class_labels[i][class_map[raw_data[i][label_index]]] = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thgXgMlTW5U9"
      },
      "source": [
        "### Use language model for embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_nzJn-AW5U9"
      },
      "outputs": [],
      "source": [
        "if flags_embedding == 1:\n",
        "    !pip install bio-embeddings[all] # Need to restart runtime for the first run \n",
        "\n",
        "    # Choose protein language model for embedder\n",
        "    from Bio import SeqIO # From Biopython library import SeqIO module to handle sequences when read and write different file formats\n",
        "\n",
        "    # Chooose language model embedder class from package bio-embeddings -> moduel embed\n",
        "    # from bio_embeddings.embed import CPCProtEmbedder, ProtTransT5XLU50Embedder, FastTextEmbedder, GloveEmbedder, PLUSRNNEmbedder, ProtTransBertBFDEmbedder, SeqVecEmbedder, UniRepEmbedder, Word2VecEmbedder, ProtTransXLNetUniRef100Embedder\n",
        "    #   from bio_embeddings.embed import ProtTransBertBFDEmbedder\n",
        "    from bio_embeddings.embed import ProtTransT5UniRef50Embedder\n",
        "    embedder = ProtTransT5UniRef50Embedder()\n",
        "\n",
        "    # Download raw sequences and create a list of sequences\n",
        "    !wget https://raw.githubusercontent.com/anhvt00/PIPR/master/yeast/preprocessed/protein_preprocessed.txt\n",
        "    with open('protein_preprocessed.txt') as file:\n",
        "        sequences = file.readlines()\n",
        "        sequences = [sequence.rstrip() for sequence in sequences]\n",
        "\n",
        "    # Install in the case of using A100 for pytorch compatibility\\\n",
        "    A100_status = !nvidia-smi | grep 'A100'\n",
        "    if A100_status:\n",
        "        !pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "    # embeddings = []\n",
        "    # for sequence in sequences:\n",
        "    #     embeddings.append(embedder.embed(sequence))\n",
        "\n",
        "    # # Start embedding \n",
        "    # # Embedding in generator form, need to iterate (flexible)\n",
        "    embeddings = embedder.embed_many(sequences)\n",
        "\n",
        "    # # Use list function to convert generator to list (true form of dataset)\n",
        "    embeddings = list(embeddings)\n",
        "\n",
        "    # # Average pooling in sequence dimension\n",
        "    # reduced_embeddings = [ProtTransBertBFDEmbedder.reduce_per_protein(e) for e in embeddings]\n",
        "\n",
        "    # # Padding to create fixed size tensor\n",
        "    seq_tensor= tf.keras.preprocessing.sequence.pad_sequences(embeddings,  padding='post', dtype='float16', truncating='post', maxlen=seq_size)\n",
        "    dim = seq_tensor.shape[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "189z3qijJ2F2"
      },
      "source": [
        "### Define custom function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcEhSLxsONax"
      },
      "outputs": [],
      "source": [
        "def leaky_relu(x, alpha = .3):\n",
        "   return tf.keras.backend.maximum(alpha*x, x)\n",
        "\n",
        "get_custom_objects().update({'leaky_relu': leaky_relu})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HyK_KJ6LUfR"
      },
      "source": [
        "### Search for optimal configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlRW8Nh71zjs"
      },
      "outputs": [],
      "source": [
        "HP_EPSILON = hp.HParam('epsilon', hp.Discrete([1e-6]))\n",
        "\n",
        "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.Discrete([1e-3]))\n",
        "\n",
        "HP_FIRST_DENSE = hp.HParam('first_dense', hp.Discrete([100]))\n",
        "\n",
        "HP_KERNEL_SIZE = hp.HParam('kernel_size', hp.Discrete([3]))\n",
        "\n",
        "HP_POOLING_KERNEL = hp.HParam('pooling_kernel', hp.Discrete([3]))\n",
        "\n",
        "HP_CONV_HIDDEN_DIM = hp.HParam('conv_hidden_dim', hp.Discrete([50]))\n",
        "HP_RNN_HIDDEN_DIM = hp.HParam('rnn_hidden_dim', hp.Discrete([50]))\n",
        "\n",
        "HP_ACTIVATION = hp.HParam('activation', hp.Discrete(['leaky_relu']))\n",
        "\n",
        "HP_ACTIVATION_CONV = hp.HParam('activation_conv', hp.Discrete(['linear']))\n",
        "\n",
        "HP_REGULARIZER = hp.HParam('regularizer', hp.Discrete([0]))\n",
        "\n",
        "HP_CONV_PADDING = hp.HParam('conv_padding', hp.Discrete(['valid']))\n",
        "\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0e-1]))\n",
        "\n",
        "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([128]))\n",
        "\n",
        "HP_LEAKY_RELU = hp.HParam('leaky_relu', hp.Discrete([3e-1]))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_EPSILON,HP_LEARNING_RATE,HP_FIRST_DENSE, HP_KERNEL_SIZE, HP_POOLING_KERNEL, HP_CONV_HIDDEN_DIM, HP_RNN_HIDDEN_DIM, HP_ACTIVATION, HP_ACTIVATION_CONV, HP_REGULARIZER, HP_CONV_PADDING, HP_DROPOUT, HP_BATCH_SIZE, HP_LEAKY_RELU],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03xD1lTqltN2"
      },
      "source": [
        "### Create dataset from generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rrgaWsfl4Op"
      },
      "outputs": [],
      "source": [
        "def generator_pair(dataset):\n",
        "  for index in dataset:\n",
        "    yield {\"seq1\": seq_tensor[seq_index1[index]], \"seq2\": seq_tensor[seq_index2[index]]}, class_labels[index]\n",
        "\n",
        "def generator_pair_predict(dataset):\n",
        "  for index in dataset:\n",
        "    yield {\"seq1\": seq_tensor[seq_index1[index]], \"seq2\": seq_tensor[seq_index2[index]]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KgZZ2JvoBLw"
      },
      "source": [
        "### Split the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### k-fold cross-validation\n",
        "from sklearn.model_selection import KFold, ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split\n",
        "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "tries = 5\n",
        "cur = 0\n",
        "recalls = []\n",
        "accuracy = []\n",
        "total = []\n",
        "total_truth = []\n",
        "train_test = []\n",
        "for train, test in kf.split(class_labels):\n",
        "    # redundant because same position\n",
        "    # if np.sum(class_labels[train], 0)[0] > 0.8 * len(train) or np.sum(class_labels[train], 0)[0] < 0.2 * len(train):\n",
        "    #     continue\n",
        "    train_test.append((train, test))\n",
        "    cur += 1\n",
        "    if cur >= tries:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "O1DkEaQYum2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G34oBACWLqbw"
      },
      "source": [
        "### Define callbacks for monitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQdf1RAsYVcA"
      },
      "outputs": [],
      "source": [
        "### Define tensorboard callback to optimize resource using of model\n",
        "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
        "                                                 histogram_freq = 1,\n",
        "                                                 profile_batch = '20, 29')\n",
        "\n",
        "### Learning rate schedule for optimization during training\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=30,\n",
        "    verbose=0,\n",
        "    mode=\"auto\",\n",
        "    min_delta=1e-2,\n",
        "    min_lr=1e-4)\n",
        "\n",
        "# Schedule early stopping\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', \n",
        "    verbose=1,\n",
        "    patience=20,\n",
        "    mode='auto',\n",
        "    restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLqkyCvrruF-"
      },
      "source": [
        "### Define performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Um2gRMVrZPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ddd4d00-6442-4d65-a4f9-e6dfdcf0a46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "METRICS = [\n",
        "      # keras.metrics.Accuracy(name='accuracy'),\n",
        "      # keras.metrics.TruePositives(name='tp'),\n",
        "      # keras.metrics.FalsePositives(name='fp'),\n",
        "      # keras.metrics.TrueNegatives(name='tn'),\n",
        "      # keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      tfa.metrics.MatthewsCorrelationCoefficient(num_classes=2, name='mcc'),\n",
        "      tfa.metrics.F1Score(num_classes=2, threshold=0.5, name='f1-score'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRvlZNzVipPt"
      },
      "source": [
        "### Original architecture PIPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnH_6e2tHjTg"
      },
      "outputs": [],
      "source": [
        "def build_model(hparams):\n",
        "    # Input of sequence tensor representations \n",
        "    seq_input1 = Input(shape=(seq_size, dim), name='seq1')\n",
        "    seq_input2 = Input(shape=(seq_size, dim), name='seq2')\n",
        "\n",
        "    # Define Conv1D and Bi-RNN (GRU/LSTM) use in architecture\n",
        "    l1=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
        "    r1=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
        "    l2=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
        "    r2=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
        "    l3=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
        "    r3=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
        "    l4=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
        "    r4=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
        "    l5=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
        "    r5=Bidirectional(GRU(hparams[HP_RNN_HIDDEN_DIM], return_sequences=True))\n",
        "    l6=Conv1D(hparams[HP_CONV_HIDDEN_DIM], hparams[HP_KERNEL_SIZE], activation=hparams[HP_ACTIVATION_CONV], padding=hparams[HP_CONV_PADDING])\n",
        "    \n",
        "    # Siamese architecture\n",
        "\n",
        "    ### 1st sibling\n",
        "\n",
        "    # 1st Block RCNN \n",
        "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l1(seq_input1))\n",
        "    s1=concatenate([r1(s1), s1])\n",
        "\n",
        "    # 2nd Block RCNN\n",
        "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l2(s1))\n",
        "    s1=concatenate([r2(s1), s1])\n",
        "\n",
        "    # 3rd Block RCNN\n",
        "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l3(s1))\n",
        "    s1=concatenate([r3(s1), s1])\n",
        "\n",
        "    # 4th Block RCNN \n",
        "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l4(s1))\n",
        "    s1=concatenate([r4(s1), s1])\n",
        "\n",
        "    # 5th Block RCNN\n",
        "    s1=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l5(s1))\n",
        "    s1=concatenate([r5(s1), s1])\n",
        "    \n",
        "    # Last convolution\n",
        "    s1=l6(s1)\n",
        "    s1=GlobalAveragePooling1D()(s1)\n",
        "\n",
        "    ### 2nd sibling\n",
        "\n",
        "    # 1st block RCNN\n",
        "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l1(seq_input2))\n",
        "    s2=concatenate([r1(s2), s2])\n",
        "\n",
        "    # 2nd block RCNN\n",
        "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l2(s2))\n",
        "    s2=concatenate([r2(s2), s2])\n",
        "\n",
        "    # 3rd block RCNN\n",
        "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l3(s2))\n",
        "    s2=concatenate([r3(s2), s2])\n",
        "\n",
        "    # 4th block RCNN\n",
        "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l4(s2))\n",
        "    s2=concatenate([r4(s2), s2])\n",
        "\n",
        "    # 5th block RCNN\n",
        "    s2=MaxPooling1D(hparams[HP_POOLING_KERNEL])(l5(s2))\n",
        "    s2=concatenate([r5(s2), s2])\n",
        "\n",
        "    # Last convolution\n",
        "    s2=l6(s2)\n",
        "    s2=GlobalAveragePooling1D()(s2)\n",
        "\n",
        "    ### Combine two siblings of siamese architecture\n",
        "    merged_text = multiply([s1, s2])\n",
        "    merged = Dense(100, activation='leaky_relu',  kernel_regularizer='l2')(merged_text)\n",
        "    merged = Dropout(.2)(merged)\n",
        " \n",
        "    merged_cos = Dense(100, activation='leaky_relu',  kernel_regularizer='l2')(tf.math.cos(math.pi*merged_text))\n",
        "    merged_cos = Dropout(.2)(merged_cos)\n",
        "    \n",
        "    merged_sin = Dense(100, activation='leaky_relu',  kernel_regularizer='l2')(tf.math.sin(math.pi*merged_text))\n",
        "    merged_sin = Dropout(.2)(merged_sin)\n",
        "    \n",
        "    merged_text = merged + merged_cos + merged_sin\n",
        "\n",
        "    #### MLP Part\n",
        "    # Set initializer\n",
        "    \n",
        "    # First dense\n",
        "    x = Dense(hparams[HP_FIRST_DENSE], activation=hparams[HP_ACTIVATION])(merged_text)\n",
        "    # x = tf.keras.layers.LeakyReLU(alpha=.3)(x)\n",
        "    x = Dropout(hparams[HP_DROPOUT])(x)\n",
        "\n",
        "    # Second dense\n",
        "    x = Dense(int((hparams[HP_CONV_HIDDEN_DIM]+7)/2), activation=hparams[HP_ACTIVATION])(x)\n",
        "    # x = tf.keras.layers.LeakyReLU(alpha=.3)(x)\n",
        "    x = Dropout(hparams[HP_DROPOUT])(x)\n",
        "\n",
        "    # Last softmax\n",
        "    main_output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    # Combine to form functional model\n",
        "    merge_model = Model(inputs=[seq_input1, seq_input2], outputs=[main_output])\n",
        "    return merge_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkG4si5QSf15"
      },
      "source": [
        "### Summary of model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wMXJo9lqd6l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "93004a6f-aec0-4fb5-f65b-ac28b9edb968"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-12e3b95290fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[1;32m    424\u001b[0m       \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0mlayer_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m       show_layer_activations=show_layer_activations)\n\u001b[0m\u001b[1;32m    427\u001b[0m   \u001b[0mto_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph, layer_range, show_layer_activations)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mnode_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ib-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minbound_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m           \u001b[0minbound_layer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/node.py\u001b[0m in \u001b[0;36minbound_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     inbound_layers = tf.nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0;32m--> 272\u001b[0;31m                                         self.call_args[0])\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/node.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     inbound_layers = tf.nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[1;32m    272\u001b[0m                                         self.call_args[0])\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[0;32m--> 442\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_history'"
          ]
        }
      ],
      "source": [
        "hparams = {\n",
        "  HP_EPSILON: EPSILON,\n",
        "  HP_LEARNING_RATE: LEARNING_RATE,\n",
        "  HP_FIRST_DENSE: 100,\n",
        "  HP_KERNEL_SIZE: 3,\n",
        "  HP_POOLING_KERNEL: 3,\n",
        "  HP_CONV_HIDDEN_DIM: 50,\n",
        "  HP_RNN_HIDDEN_DIM: 50,\n",
        "  HP_ACTIVATION: 'leaky_relu',\n",
        "  HP_ACTIVATION_CONV: 'relu',\n",
        "  HP_REGULARIZER: 0,\n",
        "  HP_CONV_PADDING: 'valid',\n",
        "  HP_DROPOUT: 3e-1,\n",
        "  HP_BATCH_SIZE: 256,\n",
        "  HP_LEAKY_RELU: 3e-1\n",
        "}\n",
        "\n",
        "model = build_model(hparams)\n",
        "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LjrzFALNxTZ"
      },
      "source": [
        "### Config Train-test process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DObbKWD68hGR"
      },
      "outputs": [],
      "source": [
        "def train_test_model(hparams):\n",
        "  training_time = 1\n",
        "  num_hit = 0.\n",
        "  num_total = 0.\n",
        "  num_pos = 0.\n",
        "  num_true_pos = 0.\n",
        "  num_false_pos = 0.\n",
        "  num_true_neg = 0.\n",
        "  num_false_neg = 0.\n",
        "  for train, test in train_test:\n",
        "      merge_model = None\n",
        "      merge_model = build_model(hparams)  \n",
        "\n",
        "\n",
        "      merge_model.compile(optimizer=Adam(learning_rate=hparams[HP_LEARNING_RATE], amsgrad=True, epsilon=hparams[HP_EPSILON]), loss='categorical_crossentropy', metrics=METRICS)\n",
        "      # Create train\n",
        "      train_dataset = tf.data.Dataset.from_generator(generator_pair, args=[train], output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
        "      train_dataset = train_dataset.shuffle(1024).repeat(N_EPOCHS).batch(hparams[HP_BATCH_SIZE])\n",
        "      train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "      # Create val\n",
        "      val_dataset = tf.data.Dataset.from_generator(generator_pair, args=[test], output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
        "      val_dataset = val_dataset.batch(hparams[HP_BATCH_SIZE])\n",
        "      val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "      # Save the best model base on val_accuracy\n",
        "      checkpoint = ModelCheckpoint(filepath=f'my_best_model_{training_time}.hdf5', monitor='val_accuracy',verbose=1, save_best_only=True, mode='max')\n",
        "      # Fit model\n",
        "      print(f'==================== Training time  {training_time} =====================')\n",
        "      # merge_model.fit(train_dataset, steps_per_epoch=len(train)//hparams[HP_BATCH_SIZE], epochs=N_EPOCHS, validation_data=val_dataset, callbacks=[early_stopping, checkpoint, reduce_lr])\n",
        "      merge_model.fit(train_dataset, steps_per_epoch=len(train)//hparams[HP_BATCH_SIZE], epochs=N_EPOCHS, validation_data=val_dataset, callbacks=[checkpoint, reduce_lr, early_stopping])\n",
        "      # merge_model.fit([seq_tensor[seq_index1[train]], seq_tensor[seq_index2[train]]], class_labels[train], batch_size = hparams[HP_BATCH_SIZE], epochs=N_EPOCHS, validation_data=([seq_tensor[seq_index1[test]], seq_tensor[seq_index2[test]]], class_labels[test]), callbacks=[checkpoint, reduce_lr])\n",
        "\n",
        "      print(f'==================End training {training_time}========================')\n",
        "      # # Create test\n",
        "      # test_dataset = tf.data.Dataset.from_generator(generator_pair, args=[test], output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}, DTYPE), output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}, (2,)) )\n",
        "      # test_dataset = test_dataset.batch(hparams[HP_BATCH_SIZE])\n",
        "      # res = merge_model.evaluate(test_dataset)\n",
        "      # Create pred\n",
        "      pred_dataset = tf.data.Dataset.from_generator(generator_pair_predict, args=[test], output_types=({\"seq1\": DTYPE, \"seq2\": DTYPE}), output_shapes = ({\"seq1\": (seq_size, dim), \"seq2\": (seq_size, dim)}) )\n",
        "      pred_dataset = pred_dataset.batch(BATCH_SIZE)\n",
        "      pred_dataset = pred_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "      pred = merge_model.predict(pred_dataset)\n",
        "\n",
        "      # Performance metrics\n",
        "      for i in range(len(class_labels[test])):\n",
        "          num_total += 1\n",
        "          if np.argmax(class_labels[test][i]) == np.argmax(pred[i]):\n",
        "              num_hit += 1\n",
        "          if class_labels[test][i][0] > 0.:\n",
        "              num_pos += 1.\n",
        "              if pred[i][0] > pred[i][1]:\n",
        "                  num_true_pos += 1\n",
        "              else:\n",
        "                  num_false_neg += 1\n",
        "          else:\n",
        "              if pred[i][0] > pred[i][1]:\n",
        "                  num_false_pos += 1\n",
        "              else:\n",
        "                  num_true_neg += 1\n",
        "      accuracy = num_hit / num_total\n",
        "      prec = num_true_pos / (num_true_pos + num_false_pos)\n",
        "      recall = num_true_pos / num_pos\n",
        "      spec = num_true_neg / (num_true_neg + num_false_neg)\n",
        "      f1 = 2. * prec * recall / (prec + recall)\n",
        "      # mcc = (num_true_pos * num_true_neg - num_false_pos * num_false_neg) / ((num_true_pos + num_true_neg) * (num_true_pos + num_false_neg) * (num_false_pos + num_true_neg) * (num_false_pos + num_false_neg)) ** 0.5\n",
        "      mcc = (num_true_pos * num_true_neg - num_false_pos * num_false_neg) / ((num_true_pos + num_false_pos) * (num_true_pos + num_false_neg) * (num_true_neg + num_false_pos) * (num_true_neg + num_false_neg)) ** 0.5\n",
        "      training_time += 1\n",
        "      print (f'accuracy: {accuracy}, precision: {prec}, recall: {recall}, specificity: {spec}, mcc: {mcc} ,f1-score: {f1}')\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hUrIncXN1vp"
      },
      "source": [
        "### Log configurations and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Frknl0rEDtm"
      },
      "outputs": [],
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ONZlF6POBUX"
      },
      "source": [
        "### Loop over all configurations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "# for i in range(1441):\n",
        "#   scaler = StandardScaler().fit(seq_tensor[i])\n",
        "\n",
        "#   # scaler = RobustScaler().fit(X)\n",
        "#   seq_tensor[i]= scaler.transform(seq_tensor[i])"
      ],
      "metadata": {
        "id": "_Rz0FeXKSNbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(class_labels==np.array([1., 0.])).sum()//2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjPqSGUmB38a",
        "outputId": "3922d72a-831a-4f67-c5ec-e58ec3e14ac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5593"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63YbvCPBGBNB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff5f623-f33f-46f8-ac92-faa9561254e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting trial: run-0\n",
            "{'epsilon': 1e-06, 'learning_rate': 0.001, 'first_dense': 100, 'kernel_size': 3, 'pooling_kernel': 3, 'conv_hidden_dim': 50, 'rnn_hidden_dim': 50, 'activation': 'leaky_relu', 'activation_conv': 'linear', 'regularizer': 0, 'conv_padding': 'valid', 'dropout': 0.0, 'batch_size': 128, 'leaky_relu': 0.3}\n",
            "==================== Training time  1 =====================\n",
            "Epoch 1/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 2.0584 - accuracy: 0.7240 - precision: 0.7240 - recall: 0.7240 - mcc: 0.4489 - f1-score: 0.7237 - auc: 0.8474 - prc: 0.8625\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.52055, saving model to my_best_model_1.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r69/69 [==============================] - 53s 355ms/step - loss: 2.0584 - accuracy: 0.7240 - precision: 0.7240 - recall: 0.7240 - mcc: 0.4489 - f1-score: 0.7237 - auc: 0.8474 - prc: 0.8625 - val_loss: 1.5263 - val_accuracy: 0.5206 - val_precision: 0.5206 - val_recall: 0.5206 - val_mcc: 0.0418 - val_f1-score: 0.4959 - val_auc: 0.5068 - val_prc: 0.5079 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 1.2376 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0123 - f1-score: 0.5054 - auc: 0.5102 - prc: 0.5092\n",
            "Epoch 00002: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 1.2376 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0123 - f1-score: 0.5054 - auc: 0.5102 - prc: 0.5092 - val_loss: 1.0165 - val_accuracy: 0.5027 - val_precision: 0.5027 - val_recall: 0.5027 - val_mcc: -0.0098 - val_f1-score: 0.3469 - val_auc: 0.5072 - val_prc: 0.5024 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.9035 - accuracy: 0.5033 - precision: 0.5033 - recall: 0.5033 - mcc: 0.0066 - f1-score: 0.5032 - auc: 0.5062 - prc: 0.5047\n",
            "Epoch 00003: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.9035 - accuracy: 0.5033 - precision: 0.5033 - recall: 0.5033 - mcc: 0.0066 - f1-score: 0.5032 - auc: 0.5062 - prc: 0.5047 - val_loss: 0.8182 - val_accuracy: 0.5040 - val_precision: 0.5040 - val_recall: 0.5040 - val_mcc: 0.0000e+00 - val_f1-score: 0.3351 - val_auc: 0.5102 - val_prc: 0.5071 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7766 - accuracy: 0.5005 - precision: 0.5005 - recall: 0.5005 - mcc: 8.7555e-04 - f1-score: 0.5002 - auc: 0.5015 - prc: 0.5006\n",
            "Epoch 00004: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.7766 - accuracy: 0.5005 - precision: 0.5005 - recall: 0.5005 - mcc: 8.7555e-04 - f1-score: 0.5002 - auc: 0.5015 - prc: 0.5006 - val_loss: 0.7438 - val_accuracy: 0.5116 - val_precision: 0.5116 - val_recall: 0.5116 - val_mcc: 0.0364 - val_f1-score: 0.4595 - val_auc: 0.5172 - val_prc: 0.5137 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7286 - accuracy: 0.5035 - precision: 0.5035 - recall: 0.5035 - mcc: 0.0071 - f1-score: 0.5028 - auc: 0.5035 - prc: 0.5001\n",
            "Epoch 00005: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.7286 - accuracy: 0.5035 - precision: 0.5035 - recall: 0.5035 - mcc: 0.0071 - f1-score: 0.5028 - auc: 0.5035 - prc: 0.5001 - val_loss: 0.7152 - val_accuracy: 0.5045 - val_precision: 0.5045 - val_recall: 0.5045 - val_mcc: 0.0051 - val_f1-score: 0.3455 - val_auc: 0.5208 - val_prc: 0.5145 - lr: 0.0010\n",
            "Epoch 6/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7095 - accuracy: 0.5045 - precision: 0.5045 - recall: 0.5045 - mcc: 0.0077 - f1-score: 0.4957 - auc: 0.5113 - prc: 0.5089\n",
            "Epoch 00006: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.7095 - accuracy: 0.5045 - precision: 0.5045 - recall: 0.5045 - mcc: 0.0077 - f1-score: 0.4957 - auc: 0.5113 - prc: 0.5089 - val_loss: 0.7054 - val_accuracy: 0.4933 - val_precision: 0.4933 - val_recall: 0.4933 - val_mcc: -0.0280 - val_f1-score: 0.3365 - val_auc: 0.4974 - val_prc: 0.4980 - lr: 0.0010\n",
            "Epoch 7/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.5086 - precision: 0.5086 - recall: 0.5086 - mcc: 0.0170 - f1-score: 0.5049 - auc: 0.5126 - prc: 0.5093\n",
            "Epoch 00007: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 261ms/step - loss: 0.7005 - accuracy: 0.5086 - precision: 0.5086 - recall: 0.5086 - mcc: 0.0170 - f1-score: 0.5049 - auc: 0.5126 - prc: 0.5093 - val_loss: 0.6979 - val_accuracy: 0.5156 - val_precision: 0.5156 - val_recall: 0.5156 - val_mcc: 0.0313 - val_f1-score: 0.4850 - val_auc: 0.5232 - val_prc: 0.5145 - lr: 0.0010\n",
            "Epoch 8/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.5092 - precision: 0.5092 - recall: 0.5092 - mcc: 0.0185 - f1-score: 0.5090 - auc: 0.5106 - prc: 0.5081\n",
            "Epoch 00008: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 262ms/step - loss: 0.6978 - accuracy: 0.5092 - precision: 0.5092 - recall: 0.5092 - mcc: 0.0185 - f1-score: 0.5090 - auc: 0.5106 - prc: 0.5081 - val_loss: 0.6988 - val_accuracy: 0.4960 - val_precision: 0.4960 - val_recall: 0.4960 - val_mcc: 0.0000e+00 - val_f1-score: 0.3315 - val_auc: 0.5007 - val_prc: 0.5010 - lr: 0.0010\n",
            "Epoch 9/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5040 - precision: 0.5040 - recall: 0.5040 - mcc: 0.0080 - f1-score: 0.5039 - auc: 0.5076 - prc: 0.5058\n",
            "Epoch 00009: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.6957 - accuracy: 0.5040 - precision: 0.5040 - recall: 0.5040 - mcc: 0.0080 - f1-score: 0.5039 - auc: 0.5076 - prc: 0.5058 - val_loss: 0.6959 - val_accuracy: 0.4960 - val_precision: 0.4960 - val_recall: 0.4960 - val_mcc: 0.0000e+00 - val_f1-score: 0.3315 - val_auc: 0.5054 - val_prc: 0.5049 - lr: 0.0010\n",
            "Epoch 10/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5127 - precision: 0.5127 - recall: 0.5127 - mcc: 0.0253 - f1-score: 0.5126 - auc: 0.5197 - prc: 0.5146\n",
            "Epoch 00010: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.6939 - accuracy: 0.5127 - precision: 0.5127 - recall: 0.5127 - mcc: 0.0253 - f1-score: 0.5126 - auc: 0.5197 - prc: 0.5146 - val_loss: 0.6948 - val_accuracy: 0.4933 - val_precision: 0.4933 - val_recall: 0.4933 - val_mcc: -0.0201 - val_f1-score: 0.3453 - val_auc: 0.5098 - val_prc: 0.5095 - lr: 0.0010\n",
            "Epoch 11/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6926 - accuracy: 0.5263 - precision: 0.5263 - recall: 0.5263 - mcc: 0.0533 - f1-score: 0.5234 - auc: 0.5320 - prc: 0.5257\n",
            "Epoch 00011: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.6926 - accuracy: 0.5263 - precision: 0.5263 - recall: 0.5263 - mcc: 0.0533 - f1-score: 0.5234 - auc: 0.5320 - prc: 0.5257 - val_loss: 0.6930 - val_accuracy: 0.5192 - val_precision: 0.5192 - val_recall: 0.5192 - val_mcc: 0.0434 - val_f1-score: 0.5067 - val_auc: 0.5273 - val_prc: 0.5230 - lr: 0.0010\n",
            "Epoch 12/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5299 - precision: 0.5299 - recall: 0.5299 - mcc: 0.0595 - f1-score: 0.5295 - auc: 0.5294 - prc: 0.5196\n",
            "Epoch 00012: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 260ms/step - loss: 0.6930 - accuracy: 0.5299 - precision: 0.5299 - recall: 0.5299 - mcc: 0.0595 - f1-score: 0.5295 - auc: 0.5294 - prc: 0.5196 - val_loss: 0.7005 - val_accuracy: 0.4951 - val_precision: 0.4951 - val_recall: 0.4951 - val_mcc: -0.0215 - val_f1-score: 0.3319 - val_auc: 0.4959 - val_prc: 0.5089 - lr: 0.0010\n",
            "Epoch 13/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.5031 - precision: 0.5031 - recall: 0.5031 - mcc: 0.0081 - f1-score: 0.4807 - auc: 0.5052 - prc: 0.5041\n",
            "Epoch 00013: val_accuracy did not improve from 0.52055\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.6946 - accuracy: 0.5031 - precision: 0.5031 - recall: 0.5031 - mcc: 0.0081 - f1-score: 0.4807 - auc: 0.5052 - prc: 0.5041 - val_loss: 0.6938 - val_accuracy: 0.4960 - val_precision: 0.4960 - val_recall: 0.4960 - val_mcc: 0.0000e+00 - val_f1-score: 0.3315 - val_auc: 0.5091 - val_prc: 0.5162 - lr: 0.0010\n",
            "Epoch 14/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5054 - precision: 0.5054 - recall: 0.5054 - mcc: 0.0109 - f1-score: 0.5054 - auc: 0.5155 - prc: 0.5165\n",
            "Epoch 00014: val_accuracy improved from 0.52055 to 0.52949, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.6934 - accuracy: 0.5054 - precision: 0.5054 - recall: 0.5054 - mcc: 0.0109 - f1-score: 0.5054 - auc: 0.5155 - prc: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5295 - val_precision: 0.5295 - val_recall: 0.5295 - val_mcc: 0.0647 - val_f1-score: 0.5184 - val_auc: 0.5349 - val_prc: 0.5285 - lr: 0.0010\n",
            "Epoch 15/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6923 - accuracy: 0.5281 - precision: 0.5281 - recall: 0.5281 - mcc: 0.0561 - f1-score: 0.5278 - auc: 0.5415 - prc: 0.5376\n",
            "Epoch 00015: val_accuracy did not improve from 0.52949\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.6923 - accuracy: 0.5281 - precision: 0.5281 - recall: 0.5281 - mcc: 0.0561 - f1-score: 0.5278 - auc: 0.5415 - prc: 0.5376 - val_loss: 0.6951 - val_accuracy: 0.4960 - val_precision: 0.4960 - val_recall: 0.4960 - val_mcc: 0.0000e+00 - val_f1-score: 0.3315 - val_auc: 0.5300 - val_prc: 0.5386 - lr: 0.0010\n",
            "Epoch 16/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6893 - accuracy: 0.5409 - precision: 0.5409 - recall: 0.5409 - mcc: 0.0881 - f1-score: 0.5262 - auc: 0.5590 - prc: 0.5542\n",
            "Epoch 00016: val_accuracy improved from 0.52949 to 0.57730, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.6893 - accuracy: 0.5409 - precision: 0.5409 - recall: 0.5409 - mcc: 0.0881 - f1-score: 0.5262 - auc: 0.5590 - prc: 0.5542 - val_loss: 0.6769 - val_accuracy: 0.5773 - val_precision: 0.5773 - val_recall: 0.5773 - val_mcc: 0.1695 - val_f1-score: 0.5534 - val_auc: 0.6040 - val_prc: 0.6053 - lr: 0.0010\n",
            "Epoch 17/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6775 - accuracy: 0.5606 - precision: 0.5606 - recall: 0.5606 - mcc: 0.1369 - f1-score: 0.5402 - auc: 0.5945 - prc: 0.5930\n",
            "Epoch 00017: val_accuracy improved from 0.57730 to 0.57864, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.6775 - accuracy: 0.5606 - precision: 0.5606 - recall: 0.5606 - mcc: 0.1369 - f1-score: 0.5402 - auc: 0.5945 - prc: 0.5930 - val_loss: 0.6713 - val_accuracy: 0.5786 - val_precision: 0.5786 - val_recall: 0.5786 - val_mcc: 0.1630 - val_f1-score: 0.5674 - val_auc: 0.6089 - val_prc: 0.6109 - lr: 0.0010\n",
            "Epoch 18/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - mcc: 0.0621 - f1-score: 0.5212 - auc: 0.5491 - prc: 0.5526\n",
            "Epoch 00018: val_accuracy did not improve from 0.57864\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.6921 - accuracy: 0.5300 - precision: 0.5300 - recall: 0.5300 - mcc: 0.0621 - f1-score: 0.5212 - auc: 0.5491 - prc: 0.5526 - val_loss: 0.7037 - val_accuracy: 0.4960 - val_precision: 0.4960 - val_recall: 0.4960 - val_mcc: 0.0000e+00 - val_f1-score: 0.3315 - val_auc: 0.4992 - val_prc: 0.5018 - lr: 0.0010\n",
            "Epoch 19/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6983 - accuracy: 0.5037 - precision: 0.5037 - recall: 0.5037 - mcc: 0.0075 - f1-score: 0.4997 - auc: 0.5073 - prc: 0.5082\n",
            "Epoch 00019: val_accuracy did not improve from 0.57864\n",
            "69/69 [==============================] - 18s 262ms/step - loss: 0.6983 - accuracy: 0.5037 - precision: 0.5037 - recall: 0.5037 - mcc: 0.0075 - f1-score: 0.4997 - auc: 0.5073 - prc: 0.5082 - val_loss: 0.6966 - val_accuracy: 0.5103 - val_precision: 0.5103 - val_recall: 0.5103 - val_mcc: 0.0195 - val_f1-score: 0.5063 - val_auc: 0.5197 - val_prc: 0.5167 - lr: 0.0010\n",
            "Epoch 20/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.5157 - precision: 0.5157 - recall: 0.5157 - mcc: 0.0313 - f1-score: 0.5148 - auc: 0.5276 - prc: 0.5240\n",
            "Epoch 00020: val_accuracy did not improve from 0.57864\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.6951 - accuracy: 0.5157 - precision: 0.5157 - recall: 0.5157 - mcc: 0.0313 - f1-score: 0.5148 - auc: 0.5276 - prc: 0.5240 - val_loss: 0.6919 - val_accuracy: 0.5483 - val_precision: 0.5483 - val_recall: 0.5483 - val_mcc: 0.0990 - val_f1-score: 0.5458 - val_auc: 0.5714 - val_prc: 0.5594 - lr: 0.0010\n",
            "Epoch 21/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.5352 - precision: 0.5352 - recall: 0.5352 - mcc: 0.0704 - f1-score: 0.5352 - auc: 0.5515 - prc: 0.5424\n",
            "Epoch 00021: val_accuracy did not improve from 0.57864\n",
            "69/69 [==============================] - 18s 262ms/step - loss: 0.6949 - accuracy: 0.5352 - precision: 0.5352 - recall: 0.5352 - mcc: 0.0704 - f1-score: 0.5352 - auc: 0.5515 - prc: 0.5424 - val_loss: 0.6997 - val_accuracy: 0.4987 - val_precision: 0.4987 - val_recall: 0.4987 - val_mcc: 0.0192 - val_f1-score: 0.3501 - val_auc: 0.5029 - val_prc: 0.5050 - lr: 0.0010\n",
            "Epoch 22/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.5159 - precision: 0.5159 - recall: 0.5159 - mcc: 0.0322 - f1-score: 0.5094 - auc: 0.5157 - prc: 0.5141\n",
            "Epoch 00022: val_accuracy did not improve from 0.57864\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.6978 - accuracy: 0.5159 - precision: 0.5159 - recall: 0.5159 - mcc: 0.0322 - f1-score: 0.5094 - auc: 0.5157 - prc: 0.5141 - val_loss: 0.6926 - val_accuracy: 0.5460 - val_precision: 0.5460 - val_recall: 0.5460 - val_mcc: 0.1107 - val_f1-score: 0.4968 - val_auc: 0.5579 - val_prc: 0.5504 - lr: 0.0010\n",
            "Epoch 23/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6895 - accuracy: 0.5388 - precision: 0.5388 - recall: 0.5388 - mcc: 0.0784 - f1-score: 0.5373 - auc: 0.5616 - prc: 0.5622\n",
            "Epoch 00023: val_accuracy improved from 0.57864 to 0.57954, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 267ms/step - loss: 0.6895 - accuracy: 0.5388 - precision: 0.5388 - recall: 0.5388 - mcc: 0.0784 - f1-score: 0.5373 - auc: 0.5616 - prc: 0.5622 - val_loss: 0.6738 - val_accuracy: 0.5795 - val_precision: 0.5795 - val_recall: 0.5795 - val_mcc: 0.1818 - val_f1-score: 0.5476 - val_auc: 0.6084 - val_prc: 0.6115 - lr: 0.0010\n",
            "Epoch 24/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6850 - accuracy: 0.5624 - precision: 0.5624 - recall: 0.5624 - mcc: 0.1331 - f1-score: 0.5484 - auc: 0.5832 - prc: 0.5819\n",
            "Epoch 00024: val_accuracy did not improve from 0.57954\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.6850 - accuracy: 0.5624 - precision: 0.5624 - recall: 0.5624 - mcc: 0.1331 - f1-score: 0.5484 - auc: 0.5832 - prc: 0.5819 - val_loss: 0.7029 - val_accuracy: 0.5094 - val_precision: 0.5094 - val_recall: 0.5094 - val_mcc: 0.0418 - val_f1-score: 0.4187 - val_auc: 0.5063 - val_prc: 0.5039 - lr: 0.0010\n",
            "Epoch 25/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.5671 - precision: 0.5671 - recall: 0.5671 - mcc: 0.1448 - f1-score: 0.5545 - auc: 0.5969 - prc: 0.5956\n",
            "Epoch 00025: val_accuracy did not improve from 0.57954\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.6813 - accuracy: 0.5671 - precision: 0.5671 - recall: 0.5671 - mcc: 0.1448 - f1-score: 0.5545 - auc: 0.5969 - prc: 0.5956 - val_loss: 0.6859 - val_accuracy: 0.5581 - val_precision: 0.5581 - val_recall: 0.5581 - val_mcc: 0.1213 - val_f1-score: 0.5525 - val_auc: 0.5875 - val_prc: 0.5980 - lr: 0.0010\n",
            "Epoch 26/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - mcc: 0.2336 - f1-score: 0.5900 - auc: 0.6504 - prc: 0.6496\n",
            "Epoch 00026: val_accuracy improved from 0.57954 to 0.60634, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.6565 - accuracy: 0.6071 - precision: 0.6071 - recall: 0.6071 - mcc: 0.2336 - f1-score: 0.5900 - auc: 0.6504 - prc: 0.6496 - val_loss: 0.6689 - val_accuracy: 0.6063 - val_precision: 0.6063 - val_recall: 0.6063 - val_mcc: 0.2168 - val_f1-score: 0.6006 - val_auc: 0.6516 - val_prc: 0.6544 - lr: 0.0010\n",
            "Epoch 27/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6415 - accuracy: 0.6267 - precision: 0.6267 - recall: 0.6267 - mcc: 0.2690 - f1-score: 0.6170 - auc: 0.6802 - prc: 0.6780\n",
            "Epoch 00027: val_accuracy improved from 0.60634 to 0.64835, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.6415 - accuracy: 0.6267 - precision: 0.6267 - recall: 0.6267 - mcc: 0.2690 - f1-score: 0.6170 - auc: 0.6802 - prc: 0.6780 - val_loss: 0.6396 - val_accuracy: 0.6483 - val_precision: 0.6483 - val_recall: 0.6483 - val_mcc: 0.3255 - val_f1-score: 0.6303 - val_auc: 0.7013 - val_prc: 0.6991 - lr: 0.0010\n",
            "Epoch 28/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6049 - accuracy: 0.6684 - precision: 0.6684 - recall: 0.6684 - mcc: 0.3530 - f1-score: 0.6615 - auc: 0.7300 - prc: 0.7299\n",
            "Epoch 00028: val_accuracy improved from 0.64835 to 0.68275, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.6049 - accuracy: 0.6684 - precision: 0.6684 - recall: 0.6684 - mcc: 0.3530 - f1-score: 0.6615 - auc: 0.7300 - prc: 0.7299 - val_loss: 0.5910 - val_accuracy: 0.6828 - val_precision: 0.6828 - val_recall: 0.6828 - val_mcc: 0.4063 - val_f1-score: 0.6648 - val_auc: 0.7613 - val_prc: 0.7599 - lr: 0.0010\n",
            "Epoch 29/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.7194 - precision: 0.7194 - recall: 0.7194 - mcc: 0.4514 - f1-score: 0.7156 - auc: 0.7955 - prc: 0.7946\n",
            "Epoch 00029: val_accuracy improved from 0.68275 to 0.74754, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.5481 - accuracy: 0.7194 - precision: 0.7194 - recall: 0.7194 - mcc: 0.4514 - f1-score: 0.7156 - auc: 0.7955 - prc: 0.7946 - val_loss: 0.5507 - val_accuracy: 0.7475 - val_precision: 0.7475 - val_recall: 0.7475 - val_mcc: 0.4979 - val_f1-score: 0.7464 - val_auc: 0.8143 - val_prc: 0.8098 - lr: 0.0010\n",
            "Epoch 30/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.7930 - precision: 0.7930 - recall: 0.7930 - mcc: 0.5920 - f1-score: 0.7920 - auc: 0.8707 - prc: 0.8689\n",
            "Epoch 00030: val_accuracy improved from 0.74754 to 0.80518, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.4540 - accuracy: 0.7930 - precision: 0.7930 - recall: 0.7930 - mcc: 0.5920 - f1-score: 0.7920 - auc: 0.8707 - prc: 0.8689 - val_loss: 0.4293 - val_accuracy: 0.8052 - val_precision: 0.8052 - val_recall: 0.8052 - val_mcc: 0.6221 - val_f1-score: 0.8029 - val_auc: 0.8880 - val_prc: 0.8877 - lr: 0.0010\n",
            "Epoch 31/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.3518 - accuracy: 0.8516 - precision: 0.8516 - recall: 0.8516 - mcc: 0.7041 - f1-score: 0.8515 - auc: 0.9255 - prc: 0.9245\n",
            "Epoch 00031: val_accuracy improved from 0.80518 to 0.86416, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 0.3518 - accuracy: 0.8516 - precision: 0.8516 - recall: 0.8516 - mcc: 0.7041 - f1-score: 0.8515 - auc: 0.9255 - prc: 0.9245 - val_loss: 0.3201 - val_accuracy: 0.8642 - val_precision: 0.8642 - val_recall: 0.8642 - val_mcc: 0.7283 - val_f1-score: 0.8641 - val_auc: 0.9391 - val_prc: 0.9377 - lr: 0.0010\n",
            "Epoch 32/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.8975 - precision: 0.8975 - recall: 0.8975 - mcc: 0.7951 - f1-score: 0.8975 - auc: 0.9648 - prc: 0.9649\n",
            "Epoch 00032: val_accuracy improved from 0.86416 to 0.89410, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 267ms/step - loss: 0.2451 - accuracy: 0.8975 - precision: 0.8975 - recall: 0.8975 - mcc: 0.7951 - f1-score: 0.8975 - auc: 0.9648 - prc: 0.9649 - val_loss: 0.2517 - val_accuracy: 0.8941 - val_precision: 0.8941 - val_recall: 0.8941 - val_mcc: 0.7884 - val_f1-score: 0.8941 - val_auc: 0.9646 - val_prc: 0.9633 - lr: 0.0010\n",
            "Epoch 33/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.9147 - precision: 0.9147 - recall: 0.9147 - mcc: 0.8300 - f1-score: 0.9147 - auc: 0.9786 - prc: 0.9787\n",
            "Epoch 00033: val_accuracy improved from 0.89410 to 0.92895, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.1906 - accuracy: 0.9147 - precision: 0.9147 - recall: 0.9147 - mcc: 0.8300 - f1-score: 0.9147 - auc: 0.9786 - prc: 0.9787 - val_loss: 0.1774 - val_accuracy: 0.9290 - val_precision: 0.9290 - val_recall: 0.9290 - val_mcc: 0.8579 - val_f1-score: 0.9290 - val_auc: 0.9810 - val_prc: 0.9800 - lr: 0.0010\n",
            "Epoch 34/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9327 - precision: 0.9327 - recall: 0.9327 - mcc: 0.8661 - f1-score: 0.9327 - auc: 0.9857 - prc: 0.9855\n",
            "Epoch 00034: val_accuracy improved from 0.92895 to 0.93119, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.1540 - accuracy: 0.9327 - precision: 0.9327 - recall: 0.9327 - mcc: 0.8661 - f1-score: 0.9327 - auc: 0.9857 - prc: 0.9855 - val_loss: 0.1638 - val_accuracy: 0.9312 - val_precision: 0.9312 - val_recall: 0.9312 - val_mcc: 0.8657 - val_f1-score: 0.9311 - val_auc: 0.9841 - val_prc: 0.9832 - lr: 0.0010\n",
            "Epoch 35/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.9424 - precision: 0.9424 - recall: 0.9424 - mcc: 0.8857 - f1-score: 0.9423 - auc: 0.9898 - prc: 0.9895\n",
            "Epoch 00035: val_accuracy did not improve from 0.93119\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.1305 - accuracy: 0.9424 - precision: 0.9424 - recall: 0.9424 - mcc: 0.8857 - f1-score: 0.9423 - auc: 0.9898 - prc: 0.9895 - val_loss: 0.1954 - val_accuracy: 0.9294 - val_precision: 0.9294 - val_recall: 0.9294 - val_mcc: 0.8594 - val_f1-score: 0.9294 - val_auc: 0.9785 - val_prc: 0.9756 - lr: 0.0010\n",
            "Epoch 36/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.9541 - precision: 0.9541 - recall: 0.9541 - mcc: 0.9083 - f1-score: 0.9541 - auc: 0.9929 - prc: 0.9924\n",
            "Epoch 00036: val_accuracy improved from 0.93119 to 0.94549, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.1057 - accuracy: 0.9541 - precision: 0.9541 - recall: 0.9541 - mcc: 0.9083 - f1-score: 0.9541 - auc: 0.9929 - prc: 0.9924 - val_loss: 0.1282 - val_accuracy: 0.9455 - val_precision: 0.9455 - val_recall: 0.9455 - val_mcc: 0.8910 - val_f1-score: 0.9455 - val_auc: 0.9889 - val_prc: 0.9878 - lr: 0.0010\n",
            "Epoch 37/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9510 - precision: 0.9510 - recall: 0.9510 - mcc: 0.9022 - f1-score: 0.9510 - auc: 0.9926 - prc: 0.9924\n",
            "Epoch 00037: val_accuracy improved from 0.94549 to 0.95130, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.1093 - accuracy: 0.9510 - precision: 0.9510 - recall: 0.9510 - mcc: 0.9022 - f1-score: 0.9510 - auc: 0.9926 - prc: 0.9924 - val_loss: 0.1118 - val_accuracy: 0.9513 - val_precision: 0.9513 - val_recall: 0.9513 - val_mcc: 0.9032 - val_f1-score: 0.9513 - val_auc: 0.9922 - val_prc: 0.9920 - lr: 0.0010\n",
            "Epoch 38/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9635 - precision: 0.9635 - recall: 0.9635 - mcc: 0.9271 - f1-score: 0.9635 - auc: 0.9954 - prc: 0.9953\n",
            "Epoch 00038: val_accuracy did not improve from 0.95130\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.0872 - accuracy: 0.9635 - precision: 0.9635 - recall: 0.9635 - mcc: 0.9271 - f1-score: 0.9635 - auc: 0.9954 - prc: 0.9953 - val_loss: 0.1201 - val_accuracy: 0.9513 - val_precision: 0.9513 - val_recall: 0.9513 - val_mcc: 0.9040 - val_f1-score: 0.9513 - val_auc: 0.9906 - val_prc: 0.9897 - lr: 0.0010\n",
            "Epoch 39/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.9622 - precision: 0.9622 - recall: 0.9622 - mcc: 0.9244 - f1-score: 0.9622 - auc: 0.9959 - prc: 0.9957\n",
            "Epoch 00039: val_accuracy improved from 0.95130 to 0.95398, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.0815 - accuracy: 0.9622 - precision: 0.9622 - recall: 0.9622 - mcc: 0.9244 - f1-score: 0.9622 - auc: 0.9959 - prc: 0.9957 - val_loss: 0.1049 - val_accuracy: 0.9540 - val_precision: 0.9540 - val_recall: 0.9540 - val_mcc: 0.9085 - val_f1-score: 0.9540 - val_auc: 0.9928 - val_prc: 0.9921 - lr: 0.0010\n",
            "Epoch 40/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9735 - precision: 0.9735 - recall: 0.9735 - mcc: 0.9470 - f1-score: 0.9735 - auc: 0.9977 - prc: 0.9977\n",
            "Epoch 00040: val_accuracy improved from 0.95398 to 0.95710, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.0619 - accuracy: 0.9735 - precision: 0.9735 - recall: 0.9735 - mcc: 0.9470 - f1-score: 0.9735 - auc: 0.9977 - prc: 0.9977 - val_loss: 0.1005 - val_accuracy: 0.9571 - val_precision: 0.9571 - val_recall: 0.9571 - val_mcc: 0.9143 - val_f1-score: 0.9571 - val_auc: 0.9935 - val_prc: 0.9928 - lr: 0.0010\n",
            "Epoch 41/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9720 - precision: 0.9720 - recall: 0.9720 - mcc: 0.9441 - f1-score: 0.9720 - auc: 0.9965 - prc: 0.9960\n",
            "Epoch 00041: val_accuracy did not improve from 0.95710\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.0689 - accuracy: 0.9720 - precision: 0.9720 - recall: 0.9720 - mcc: 0.9441 - f1-score: 0.9720 - auc: 0.9965 - prc: 0.9960 - val_loss: 0.1297 - val_accuracy: 0.9482 - val_precision: 0.9482 - val_recall: 0.9482 - val_mcc: 0.8971 - val_f1-score: 0.9482 - val_auc: 0.9893 - val_prc: 0.9878 - lr: 0.0010\n",
            "Epoch 42/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 0.9676 - precision: 0.9676 - recall: 0.9676 - mcc: 0.9352 - f1-score: 0.9676 - auc: 0.9959 - prc: 0.9957\n",
            "Epoch 00042: val_accuracy did not improve from 0.95710\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.0822 - accuracy: 0.9676 - precision: 0.9676 - recall: 0.9676 - mcc: 0.9352 - f1-score: 0.9676 - auc: 0.9959 - prc: 0.9957 - val_loss: 0.1470 - val_accuracy: 0.9446 - val_precision: 0.9446 - val_recall: 0.9446 - val_mcc: 0.8894 - val_f1-score: 0.9446 - val_auc: 0.9881 - val_prc: 0.9875 - lr: 0.0010\n",
            "Epoch 43/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.9667 - precision: 0.9667 - recall: 0.9667 - mcc: 0.9335 - f1-score: 0.9667 - auc: 0.9956 - prc: 0.9954\n",
            "Epoch 00043: val_accuracy improved from 0.95710 to 0.95755, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 267ms/step - loss: 0.0857 - accuracy: 0.9667 - precision: 0.9667 - recall: 0.9667 - mcc: 0.9335 - f1-score: 0.9667 - auc: 0.9956 - prc: 0.9954 - val_loss: 0.1080 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_mcc: 0.9153 - val_f1-score: 0.9576 - val_auc: 0.9930 - val_prc: 0.9924 - lr: 0.0010\n",
            "Epoch 44/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9748 - precision: 0.9748 - recall: 0.9748 - mcc: 0.9495 - f1-score: 0.9748 - auc: 0.9975 - prc: 0.9974\n",
            "Epoch 00044: val_accuracy improved from 0.95755 to 0.95934, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 267ms/step - loss: 0.0630 - accuracy: 0.9748 - precision: 0.9748 - recall: 0.9748 - mcc: 0.9495 - f1-score: 0.9748 - auc: 0.9975 - prc: 0.9974 - val_loss: 0.1147 - val_accuracy: 0.9593 - val_precision: 0.9593 - val_recall: 0.9593 - val_mcc: 0.9189 - val_f1-score: 0.9593 - val_auc: 0.9919 - val_prc: 0.9909 - lr: 0.0010\n",
            "Epoch 45/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9795 - precision: 0.9795 - recall: 0.9795 - mcc: 0.9590 - f1-score: 0.9795 - auc: 0.9983 - prc: 0.9981\n",
            "Epoch 00045: val_accuracy did not improve from 0.95934\n",
            "69/69 [==============================] - 18s 262ms/step - loss: 0.0511 - accuracy: 0.9795 - precision: 0.9795 - recall: 0.9795 - mcc: 0.9590 - f1-score: 0.9795 - auc: 0.9983 - prc: 0.9981 - val_loss: 0.2007 - val_accuracy: 0.9397 - val_precision: 0.9397 - val_recall: 0.9397 - val_mcc: 0.8800 - val_f1-score: 0.9396 - val_auc: 0.9823 - val_prc: 0.9794 - lr: 0.0010\n",
            "Epoch 46/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9789 - precision: 0.9789 - recall: 0.9789 - mcc: 0.9579 - f1-score: 0.9789 - auc: 0.9978 - prc: 0.9978\n",
            "Epoch 00046: val_accuracy did not improve from 0.95934\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.0595 - accuracy: 0.9789 - precision: 0.9789 - recall: 0.9789 - mcc: 0.9579 - f1-score: 0.9789 - auc: 0.9978 - prc: 0.9978 - val_loss: 0.1068 - val_accuracy: 0.9589 - val_precision: 0.9589 - val_recall: 0.9589 - val_mcc: 0.9178 - val_f1-score: 0.9589 - val_auc: 0.9927 - val_prc: 0.9916 - lr: 0.0010\n",
            "Epoch 47/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9847 - precision: 0.9847 - recall: 0.9847 - mcc: 0.9694 - f1-score: 0.9847 - auc: 0.9989 - prc: 0.9988\n",
            "Epoch 00047: val_accuracy improved from 0.95934 to 0.96023, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 265ms/step - loss: 0.0419 - accuracy: 0.9847 - precision: 0.9847 - recall: 0.9847 - mcc: 0.9694 - f1-score: 0.9847 - auc: 0.9989 - prc: 0.9988 - val_loss: 0.1024 - val_accuracy: 0.9602 - val_precision: 0.9602 - val_recall: 0.9602 - val_mcc: 0.9205 - val_f1-score: 0.9602 - val_auc: 0.9937 - val_prc: 0.9930 - lr: 0.0010\n",
            "Epoch 48/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9887 - precision: 0.9887 - recall: 0.9887 - mcc: 0.9774 - f1-score: 0.9887 - auc: 0.9995 - prc: 0.9994\n",
            "Epoch 00048: val_accuracy improved from 0.96023 to 0.96783, saving model to my_best_model_1.hdf5\n",
            "69/69 [==============================] - 18s 267ms/step - loss: 0.0305 - accuracy: 0.9887 - precision: 0.9887 - recall: 0.9887 - mcc: 0.9774 - f1-score: 0.9887 - auc: 0.9995 - prc: 0.9994 - val_loss: 0.1100 - val_accuracy: 0.9678 - val_precision: 0.9678 - val_recall: 0.9678 - val_mcc: 0.9357 - val_f1-score: 0.9678 - val_auc: 0.9932 - val_prc: 0.9919 - lr: 0.0010\n",
            "Epoch 49/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9916 - precision: 0.9916 - recall: 0.9916 - mcc: 0.9832 - f1-score: 0.9916 - auc: 0.9992 - prc: 0.9991\n",
            "Epoch 00049: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.0264 - accuracy: 0.9916 - precision: 0.9916 - recall: 0.9916 - mcc: 0.9832 - f1-score: 0.9916 - auc: 0.9992 - prc: 0.9991 - val_loss: 0.1151 - val_accuracy: 0.9669 - val_precision: 0.9669 - val_recall: 0.9669 - val_mcc: 0.9339 - val_f1-score: 0.9669 - val_auc: 0.9926 - val_prc: 0.9912 - lr: 0.0010\n",
            "Epoch 50/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - mcc: 0.9873 - f1-score: 0.9937 - auc: 0.9998 - prc: 0.9998\n",
            "Epoch 00050: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.0195 - accuracy: 0.9937 - precision: 0.9937 - recall: 0.9937 - mcc: 0.9873 - f1-score: 0.9937 - auc: 0.9998 - prc: 0.9998 - val_loss: 0.1281 - val_accuracy: 0.9611 - val_precision: 0.9611 - val_recall: 0.9611 - val_mcc: 0.9223 - val_f1-score: 0.9611 - val_auc: 0.9926 - val_prc: 0.9913 - lr: 0.0010\n",
            "Epoch 51/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9935 - precision: 0.9935 - recall: 0.9935 - mcc: 0.9871 - f1-score: 0.9935 - auc: 0.9996 - prc: 0.9995\n",
            "Epoch 00051: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 262ms/step - loss: 0.0202 - accuracy: 0.9935 - precision: 0.9935 - recall: 0.9935 - mcc: 0.9871 - f1-score: 0.9935 - auc: 0.9996 - prc: 0.9995 - val_loss: 0.1363 - val_accuracy: 0.9660 - val_precision: 0.9660 - val_recall: 0.9660 - val_mcc: 0.9322 - val_f1-score: 0.9660 - val_auc: 0.9904 - val_prc: 0.9880 - lr: 0.0010\n",
            "Epoch 52/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - mcc: 0.9860 - f1-score: 0.9930 - auc: 0.9995 - prc: 0.9994\n",
            "Epoch 00052: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 262ms/step - loss: 0.0213 - accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - mcc: 0.9860 - f1-score: 0.9930 - auc: 0.9995 - prc: 0.9994 - val_loss: 0.1222 - val_accuracy: 0.9660 - val_precision: 0.9660 - val_recall: 0.9660 - val_mcc: 0.9321 - val_f1-score: 0.9660 - val_auc: 0.9916 - val_prc: 0.9897 - lr: 0.0010\n",
            "Epoch 53/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - mcc: 0.9875 - f1-score: 0.9938 - auc: 0.9996 - prc: 0.9995\n",
            "Epoch 00053: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.0190 - accuracy: 0.9938 - precision: 0.9938 - recall: 0.9938 - mcc: 0.9875 - f1-score: 0.9938 - auc: 0.9996 - prc: 0.9995 - val_loss: 0.1568 - val_accuracy: 0.9562 - val_precision: 0.9562 - val_recall: 0.9562 - val_mcc: 0.9124 - val_f1-score: 0.9562 - val_auc: 0.9874 - val_prc: 0.9847 - lr: 0.0010\n",
            "Epoch 54/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9753 - precision: 0.9753 - recall: 0.9753 - mcc: 0.9506 - f1-score: 0.9753 - auc: 0.9960 - prc: 0.9954\n",
            "Epoch 00054: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.0735 - accuracy: 0.9753 - precision: 0.9753 - recall: 0.9753 - mcc: 0.9506 - f1-score: 0.9753 - auc: 0.9960 - prc: 0.9954 - val_loss: 0.1207 - val_accuracy: 0.9495 - val_precision: 0.9495 - val_recall: 0.9495 - val_mcc: 0.8991 - val_f1-score: 0.9495 - val_auc: 0.9920 - val_prc: 0.9921 - lr: 0.0010\n",
            "Epoch 55/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9779 - mcc: 0.9558 - f1-score: 0.9779 - auc: 0.9980 - prc: 0.9979\n",
            "Epoch 00055: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.0568 - accuracy: 0.9779 - precision: 0.9779 - recall: 0.9779 - mcc: 0.9558 - f1-score: 0.9779 - auc: 0.9980 - prc: 0.9979 - val_loss: 0.1047 - val_accuracy: 0.9656 - val_precision: 0.9656 - val_recall: 0.9656 - val_mcc: 0.9312 - val_f1-score: 0.9656 - val_auc: 0.9947 - val_prc: 0.9941 - lr: 0.0010\n",
            "Epoch 56/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9918 - precision: 0.9918 - recall: 0.9918 - mcc: 0.9837 - f1-score: 0.9918 - auc: 0.9997 - prc: 0.9997\n",
            "Epoch 00056: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.0254 - accuracy: 0.9918 - precision: 0.9918 - recall: 0.9918 - mcc: 0.9837 - f1-score: 0.9918 - auc: 0.9997 - prc: 0.9997 - val_loss: 0.1204 - val_accuracy: 0.9643 - val_precision: 0.9643 - val_recall: 0.9643 - val_mcc: 0.9286 - val_f1-score: 0.9643 - val_auc: 0.9923 - val_prc: 0.9907 - lr: 0.0010\n",
            "Epoch 57/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 0.9921 - precision: 0.9921 - recall: 0.9921 - mcc: 0.9842 - f1-score: 0.9921 - auc: 0.9998 - prc: 0.9998\n",
            "Epoch 00057: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 263ms/step - loss: 0.0213 - accuracy: 0.9921 - precision: 0.9921 - recall: 0.9921 - mcc: 0.9842 - f1-score: 0.9921 - auc: 0.9998 - prc: 0.9998 - val_loss: 0.1218 - val_accuracy: 0.9660 - val_precision: 0.9660 - val_recall: 0.9660 - val_mcc: 0.9321 - val_f1-score: 0.9660 - val_auc: 0.9925 - val_prc: 0.9909 - lr: 0.0010\n",
            "Epoch 58/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9922 - precision: 0.9922 - recall: 0.9922 - mcc: 0.9844 - f1-score: 0.9922 - auc: 0.9995 - prc: 0.9994\n",
            "Epoch 00058: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 262ms/step - loss: 0.0230 - accuracy: 0.9922 - precision: 0.9922 - recall: 0.9922 - mcc: 0.9844 - f1-score: 0.9922 - auc: 0.9995 - prc: 0.9994 - val_loss: 0.1474 - val_accuracy: 0.9625 - val_precision: 0.9625 - val_recall: 0.9625 - val_mcc: 0.9252 - val_f1-score: 0.9625 - val_auc: 0.9862 - val_prc: 0.9828 - lr: 0.0010\n",
            "Epoch 59/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9898 - precision: 0.9898 - recall: 0.9898 - mcc: 0.9796 - f1-score: 0.9898 - auc: 0.9986 - prc: 0.9983\n",
            "Epoch 00059: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 18s 266ms/step - loss: 0.0357 - accuracy: 0.9898 - precision: 0.9898 - recall: 0.9898 - mcc: 0.9796 - f1-score: 0.9898 - auc: 0.9986 - prc: 0.9983 - val_loss: 0.1577 - val_accuracy: 0.9558 - val_precision: 0.9558 - val_recall: 0.9558 - val_mcc: 0.9117 - val_f1-score: 0.9558 - val_auc: 0.9876 - val_prc: 0.9851 - lr: 0.0010\n",
            "Epoch 60/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9909 - precision: 0.9909 - recall: 0.9909 - mcc: 0.9819 - f1-score: 0.9909 - auc: 0.9995 - prc: 0.9994\n",
            "Epoch 00060: val_accuracy did not improve from 0.96783\n",
            "Restoring model weights from the end of the best epoch: 40.\n",
            "69/69 [==============================] - 18s 264ms/step - loss: 0.0247 - accuracy: 0.9909 - precision: 0.9909 - recall: 0.9909 - mcc: 0.9819 - f1-score: 0.9909 - auc: 0.9995 - prc: 0.9994 - val_loss: 0.1276 - val_accuracy: 0.9651 - val_precision: 0.9651 - val_recall: 0.9651 - val_mcc: 0.9303 - val_f1-score: 0.9651 - val_auc: 0.9910 - val_prc: 0.9889 - lr: 0.0010\n",
            "Epoch 00060: early stopping\n",
            "==================End training 1========================\n",
            "accuracy: 0.9571045576407506, precision: 0.9623655913978495, recall: 0.9521276595744681, specificity: 0.9518716577540107, mcc: 0.9142635350663622 ,f1-score: 0.9572192513368984\n",
            "==================== Training time  2 =====================\n",
            "Epoch 1/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 2.0624 - accuracy: 0.5922 - precision: 0.5922 - recall: 0.5922 - mcc: 0.1852 - f1-score: 0.5914 - auc: 0.6682 - prc: 0.6976\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.49687, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 53s 361ms/step - loss: 2.0624 - accuracy: 0.5922 - precision: 0.5922 - recall: 0.5922 - mcc: 0.1852 - f1-score: 0.5914 - auc: 0.6682 - prc: 0.6976 - val_loss: 1.5314 - val_accuracy: 0.4969 - val_precision: 0.4969 - val_recall: 0.4969 - val_mcc: -0.0210 - val_f1-score: 0.4240 - val_auc: 0.5108 - val_prc: 0.5087 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 1.2535 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - mcc: 0.0197 - f1-score: 0.5068 - auc: 0.5095 - prc: 0.5036\n",
            "Epoch 00002: val_accuracy improved from 0.49687 to 0.50134, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 1.2535 - accuracy: 0.5100 - precision: 0.5100 - recall: 0.5100 - mcc: 0.0197 - f1-score: 0.5068 - auc: 0.5095 - prc: 0.5036 - val_loss: 1.0267 - val_accuracy: 0.5013 - val_precision: 0.5013 - val_recall: 0.5013 - val_mcc: 0.0031 - val_f1-score: 0.5013 - val_auc: 0.5080 - val_prc: 0.5072 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.9263 - accuracy: 0.5024 - precision: 0.5024 - recall: 0.5024 - mcc: 0.0048 - f1-score: 0.5022 - auc: 0.5037 - prc: 0.5015\n",
            "Epoch 00003: val_accuracy improved from 0.50134 to 0.51698, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.9263 - accuracy: 0.5024 - precision: 0.5024 - recall: 0.5024 - mcc: 0.0048 - f1-score: 0.5022 - auc: 0.5037 - prc: 0.5015 - val_loss: 0.8306 - val_accuracy: 0.5170 - val_precision: 0.5170 - val_recall: 0.5170 - val_mcc: 0.0321 - val_f1-score: 0.5113 - val_auc: 0.5268 - val_prc: 0.5226 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7863 - accuracy: 0.5139 - precision: 0.5139 - recall: 0.5139 - mcc: 0.0275 - f1-score: 0.5119 - auc: 0.5185 - prc: 0.5142\n",
            "Epoch 00004: val_accuracy improved from 0.51698 to 0.51787, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.7863 - accuracy: 0.5139 - precision: 0.5139 - recall: 0.5139 - mcc: 0.0275 - f1-score: 0.5119 - auc: 0.5185 - prc: 0.5142 - val_loss: 0.7517 - val_accuracy: 0.5179 - val_precision: 0.5179 - val_recall: 0.5179 - val_mcc: 0.0349 - val_f1-score: 0.5170 - val_auc: 0.5272 - val_prc: 0.5227 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7347 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - mcc: 0.0349 - f1-score: 0.5174 - auc: 0.5207 - prc: 0.5144\n",
            "Epoch 00005: val_accuracy did not improve from 0.51787\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.7347 - accuracy: 0.5175 - precision: 0.5175 - recall: 0.5175 - mcc: 0.0349 - f1-score: 0.5174 - auc: 0.5207 - prc: 0.5144 - val_loss: 0.7214 - val_accuracy: 0.5089 - val_precision: 0.5089 - val_recall: 0.5089 - val_mcc: 0.0438 - val_f1-score: 0.4250 - val_auc: 0.5108 - val_prc: 0.5083 - lr: 0.0010\n",
            "Epoch 6/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7133 - accuracy: 0.5094 - precision: 0.5094 - recall: 0.5094 - mcc: 0.0189 - f1-score: 0.5093 - auc: 0.5176 - prc: 0.5145\n",
            "Epoch 00006: val_accuracy did not improve from 0.51787\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.7133 - accuracy: 0.5094 - precision: 0.5094 - recall: 0.5094 - mcc: 0.0189 - f1-score: 0.5093 - auc: 0.5176 - prc: 0.5145 - val_loss: 0.7097 - val_accuracy: 0.4937 - val_precision: 0.4937 - val_recall: 0.4937 - val_mcc: 0.0000e+00 - val_f1-score: 0.3305 - val_auc: 0.5068 - val_prc: 0.5051 - lr: 0.0010\n",
            "Epoch 7/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.5148 - precision: 0.5148 - recall: 0.5148 - mcc: 0.0297 - f1-score: 0.5111 - auc: 0.5184 - prc: 0.5113\n",
            "Epoch 00007: val_accuracy improved from 0.51787 to 0.52189, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.7050 - accuracy: 0.5148 - precision: 0.5148 - recall: 0.5148 - mcc: 0.0297 - f1-score: 0.5111 - auc: 0.5184 - prc: 0.5113 - val_loss: 0.7014 - val_accuracy: 0.5219 - val_precision: 0.5219 - val_recall: 0.5219 - val_mcc: 0.0424 - val_f1-score: 0.5000 - val_auc: 0.5292 - val_prc: 0.5244 - lr: 0.0010\n",
            "Epoch 8/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7002 - accuracy: 0.5288 - precision: 0.5288 - recall: 0.5288 - mcc: 0.0578 - f1-score: 0.5253 - auc: 0.5267 - prc: 0.5200\n",
            "Epoch 00008: val_accuracy improved from 0.52189 to 0.52324, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.7002 - accuracy: 0.5288 - precision: 0.5288 - recall: 0.5288 - mcc: 0.0578 - f1-score: 0.5253 - auc: 0.5267 - prc: 0.5200 - val_loss: 0.6985 - val_accuracy: 0.5232 - val_precision: 0.5232 - val_recall: 0.5232 - val_mcc: 0.0502 - val_f1-score: 0.5186 - val_auc: 0.5308 - val_prc: 0.5206 - lr: 0.0010\n",
            "Epoch 9/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.5286 - precision: 0.5286 - recall: 0.5286 - mcc: 0.0575 - f1-score: 0.5281 - auc: 0.5386 - prc: 0.5290\n",
            "Epoch 00009: val_accuracy did not improve from 0.52324\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6969 - accuracy: 0.5286 - precision: 0.5286 - recall: 0.5286 - mcc: 0.0575 - f1-score: 0.5281 - auc: 0.5386 - prc: 0.5290 - val_loss: 0.6980 - val_accuracy: 0.5049 - val_precision: 0.5049 - val_recall: 0.5049 - val_mcc: -0.0167 - val_f1-score: 0.3395 - val_auc: 0.5180 - val_prc: 0.5191 - lr: 0.0010\n",
            "Epoch 10/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.5109 - precision: 0.5109 - recall: 0.5109 - mcc: 0.0218 - f1-score: 0.5109 - auc: 0.5107 - prc: 0.5086\n",
            "Epoch 00010: val_accuracy improved from 0.52324 to 0.52860, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6981 - accuracy: 0.5109 - precision: 0.5109 - recall: 0.5109 - mcc: 0.0218 - f1-score: 0.5109 - auc: 0.5107 - prc: 0.5086 - val_loss: 0.6959 - val_accuracy: 0.5286 - val_precision: 0.5286 - val_recall: 0.5286 - val_mcc: 0.0871 - val_f1-score: 0.4226 - val_auc: 0.5388 - val_prc: 0.5354 - lr: 0.0010\n",
            "Epoch 11/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6962 - accuracy: 0.5246 - precision: 0.5246 - recall: 0.5246 - mcc: 0.0493 - f1-score: 0.5216 - auc: 0.5337 - prc: 0.5309\n",
            "Epoch 00011: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.6962 - accuracy: 0.5246 - precision: 0.5246 - recall: 0.5246 - mcc: 0.0493 - f1-score: 0.5216 - auc: 0.5337 - prc: 0.5309 - val_loss: 0.6991 - val_accuracy: 0.4937 - val_precision: 0.4937 - val_recall: 0.4937 - val_mcc: 0.0000e+00 - val_f1-score: 0.3305 - val_auc: 0.4881 - val_prc: 0.4870 - lr: 0.0010\n",
            "Epoch 12/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.5054 - precision: 0.5054 - recall: 0.5054 - mcc: 0.0103 - f1-score: 0.5020 - auc: 0.5077 - prc: 0.5052\n",
            "Epoch 00012: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 18s 267ms/step - loss: 0.6969 - accuracy: 0.5054 - precision: 0.5054 - recall: 0.5054 - mcc: 0.0103 - f1-score: 0.5020 - auc: 0.5077 - prc: 0.5052 - val_loss: 0.6962 - val_accuracy: 0.5040 - val_precision: 0.5040 - val_recall: 0.5040 - val_mcc: 0.0342 - val_f1-score: 0.4016 - val_auc: 0.5101 - val_prc: 0.5089 - lr: 0.0010\n",
            "Epoch 13/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.5142 - precision: 0.5142 - recall: 0.5142 - mcc: 0.0284 - f1-score: 0.5071 - auc: 0.5155 - prc: 0.5096\n",
            "Epoch 00013: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 0.6955 - accuracy: 0.5142 - precision: 0.5142 - recall: 0.5142 - mcc: 0.0284 - f1-score: 0.5071 - auc: 0.5155 - prc: 0.5096 - val_loss: 0.6949 - val_accuracy: 0.5134 - val_precision: 0.5134 - val_recall: 0.5134 - val_mcc: 0.0346 - val_f1-score: 0.4948 - val_auc: 0.5236 - val_prc: 0.5200 - lr: 0.0010\n",
            "Epoch 14/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5204 - precision: 0.5204 - recall: 0.5204 - mcc: 0.0407 - f1-score: 0.5200 - auc: 0.5230 - prc: 0.5150\n",
            "Epoch 00014: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.6948 - accuracy: 0.5204 - precision: 0.5204 - recall: 0.5204 - mcc: 0.0407 - f1-score: 0.5200 - auc: 0.5230 - prc: 0.5150 - val_loss: 0.6956 - val_accuracy: 0.5080 - val_precision: 0.5080 - val_recall: 0.5080 - val_mcc: 0.0369 - val_f1-score: 0.4354 - val_auc: 0.5048 - val_prc: 0.5021 - lr: 0.0010\n",
            "Epoch 15/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.5049 - precision: 0.5049 - recall: 0.5049 - mcc: 0.0096 - f1-score: 0.5047 - auc: 0.5073 - prc: 0.5027\n",
            "Epoch 00015: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6956 - accuracy: 0.5049 - precision: 0.5049 - recall: 0.5049 - mcc: 0.0096 - f1-score: 0.5047 - auc: 0.5073 - prc: 0.5027 - val_loss: 0.6950 - val_accuracy: 0.5147 - val_precision: 0.5147 - val_recall: 0.5147 - val_mcc: 0.0593 - val_f1-score: 0.4374 - val_auc: 0.5157 - val_prc: 0.5113 - lr: 0.0010\n",
            "Epoch 16/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5103 - precision: 0.5103 - recall: 0.5103 - mcc: 0.0202 - f1-score: 0.5098 - auc: 0.5157 - prc: 0.5133\n",
            "Epoch 00016: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6953 - accuracy: 0.5103 - precision: 0.5103 - recall: 0.5103 - mcc: 0.0202 - f1-score: 0.5098 - auc: 0.5157 - prc: 0.5133 - val_loss: 0.6968 - val_accuracy: 0.4946 - val_precision: 0.4946 - val_recall: 0.4946 - val_mcc: 0.0049 - val_f1-score: 0.3474 - val_auc: 0.5064 - val_prc: 0.5054 - lr: 0.0010\n",
            "Epoch 17/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5172 - precision: 0.5172 - recall: 0.5172 - mcc: 0.0345 - f1-score: 0.5167 - auc: 0.5170 - prc: 0.5097\n",
            "Epoch 00017: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 18s 267ms/step - loss: 0.6947 - accuracy: 0.5172 - precision: 0.5172 - recall: 0.5172 - mcc: 0.0345 - f1-score: 0.5167 - auc: 0.5170 - prc: 0.5097 - val_loss: 0.6951 - val_accuracy: 0.5094 - val_precision: 0.5094 - val_recall: 0.5094 - val_mcc: 0.0440 - val_f1-score: 0.4285 - val_auc: 0.5116 - val_prc: 0.5092 - lr: 0.0010\n",
            "Epoch 18/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.5208 - precision: 0.5208 - recall: 0.5208 - mcc: 0.0417 - f1-score: 0.5208 - auc: 0.5220 - prc: 0.5135\n",
            "Epoch 00018: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6943 - accuracy: 0.5208 - precision: 0.5208 - recall: 0.5208 - mcc: 0.0417 - f1-score: 0.5208 - auc: 0.5220 - prc: 0.5135 - val_loss: 0.6960 - val_accuracy: 0.4937 - val_precision: 0.4937 - val_recall: 0.4937 - val_mcc: -3.7421e-04 - val_f1-score: 0.3313 - val_auc: 0.5058 - val_prc: 0.5039 - lr: 0.0010\n",
            "Epoch 19/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5196 - precision: 0.5196 - recall: 0.5196 - mcc: 0.0394 - f1-score: 0.5181 - auc: 0.5189 - prc: 0.5137\n",
            "Epoch 00019: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6948 - accuracy: 0.5196 - precision: 0.5196 - recall: 0.5196 - mcc: 0.0394 - f1-score: 0.5181 - auc: 0.5189 - prc: 0.5137 - val_loss: 0.6945 - val_accuracy: 0.5223 - val_precision: 0.5223 - val_recall: 0.5223 - val_mcc: 0.0451 - val_f1-score: 0.5223 - val_auc: 0.5180 - val_prc: 0.5084 - lr: 0.0010\n",
            "Epoch 20/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5271 - precision: 0.5271 - recall: 0.5271 - mcc: 0.0540 - f1-score: 0.5261 - auc: 0.5241 - prc: 0.5177\n",
            "Epoch 00020: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6940 - accuracy: 0.5271 - precision: 0.5271 - recall: 0.5271 - mcc: 0.0540 - f1-score: 0.5261 - auc: 0.5241 - prc: 0.5177 - val_loss: 0.6934 - val_accuracy: 0.5286 - val_precision: 0.5286 - val_recall: 0.5286 - val_mcc: 0.0599 - val_f1-score: 0.5262 - val_auc: 0.5305 - val_prc: 0.5223 - lr: 0.0010\n",
            "Epoch 21/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5130 - precision: 0.5130 - recall: 0.5130 - mcc: 0.0259 - f1-score: 0.5127 - auc: 0.5168 - prc: 0.5124\n",
            "Epoch 00021: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.6948 - accuracy: 0.5130 - precision: 0.5130 - recall: 0.5130 - mcc: 0.0259 - f1-score: 0.5127 - auc: 0.5168 - prc: 0.5124 - val_loss: 0.6939 - val_accuracy: 0.5206 - val_precision: 0.5206 - val_recall: 0.5206 - val_mcc: 0.0393 - val_f1-score: 0.5004 - val_auc: 0.5289 - val_prc: 0.5236 - lr: 0.0010\n",
            "Epoch 22/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5136 - precision: 0.5136 - recall: 0.5136 - mcc: 0.0261 - f1-score: 0.5120 - auc: 0.5247 - prc: 0.5211\n",
            "Epoch 00022: val_accuracy did not improve from 0.52860\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.6937 - accuracy: 0.5136 - precision: 0.5136 - recall: 0.5136 - mcc: 0.0261 - f1-score: 0.5120 - auc: 0.5247 - prc: 0.5211 - val_loss: 0.6935 - val_accuracy: 0.5161 - val_precision: 0.5161 - val_recall: 0.5161 - val_mcc: 0.0412 - val_f1-score: 0.4954 - val_auc: 0.5276 - val_prc: 0.5210 - lr: 0.0010\n",
            "Epoch 23/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.5380 - precision: 0.5380 - recall: 0.5379 - mcc: 0.0760 - f1-score: 0.5377 - auc: 0.5435 - prc: 0.5372\n",
            "Epoch 00023: val_accuracy improved from 0.52860 to 0.56166, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.6917 - accuracy: 0.5380 - precision: 0.5380 - recall: 0.5379 - mcc: 0.0760 - f1-score: 0.5377 - auc: 0.5435 - prc: 0.5372 - val_loss: 0.6853 - val_accuracy: 0.5617 - val_precision: 0.5617 - val_recall: 0.5617 - val_mcc: 0.1279 - val_f1-score: 0.5448 - val_auc: 0.5842 - val_prc: 0.5596 - lr: 0.0010\n",
            "Epoch 24/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.5084 - precision: 0.5084 - recall: 0.5084 - mcc: 0.0174 - f1-score: 0.5040 - auc: 0.5112 - prc: 0.5115\n",
            "Epoch 00024: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6961 - accuracy: 0.5084 - precision: 0.5084 - recall: 0.5084 - mcc: 0.0174 - f1-score: 0.5040 - auc: 0.5112 - prc: 0.5115 - val_loss: 0.6966 - val_accuracy: 0.5018 - val_precision: 0.5018 - val_recall: 0.5018 - val_mcc: 0.0115 - val_f1-score: 0.4691 - val_auc: 0.5071 - val_prc: 0.5017 - lr: 0.0010\n",
            "Epoch 25/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.5061 - precision: 0.5061 - recall: 0.5061 - mcc: 0.0111 - f1-score: 0.5027 - auc: 0.5153 - prc: 0.5129\n",
            "Epoch 00025: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.6951 - accuracy: 0.5061 - precision: 0.5061 - recall: 0.5061 - mcc: 0.0111 - f1-score: 0.5027 - auc: 0.5153 - prc: 0.5129 - val_loss: 0.6948 - val_accuracy: 0.5107 - val_precision: 0.5107 - val_recall: 0.5107 - val_mcc: 0.0454 - val_f1-score: 0.4368 - val_auc: 0.5084 - val_prc: 0.5059 - lr: 0.0010\n",
            "Epoch 26/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.5126 - precision: 0.5126 - recall: 0.5126 - mcc: 0.0270 - f1-score: 0.5009 - auc: 0.5135 - prc: 0.5092\n",
            "Epoch 00026: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6949 - accuracy: 0.5126 - precision: 0.5126 - recall: 0.5126 - mcc: 0.0270 - f1-score: 0.5009 - auc: 0.5135 - prc: 0.5092 - val_loss: 0.6947 - val_accuracy: 0.4978 - val_precision: 0.4978 - val_recall: 0.4978 - val_mcc: 0.0101 - val_f1-score: 0.3998 - val_auc: 0.5002 - val_prc: 0.5036 - lr: 0.0010\n",
            "Epoch 27/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5196 - precision: 0.5196 - recall: 0.5196 - mcc: 0.0375 - f1-score: 0.5114 - auc: 0.5265 - prc: 0.5188\n",
            "Epoch 00027: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6937 - accuracy: 0.5196 - precision: 0.5196 - recall: 0.5196 - mcc: 0.0375 - f1-score: 0.5114 - auc: 0.5265 - prc: 0.5188 - val_loss: 0.6969 - val_accuracy: 0.5076 - val_precision: 0.5076 - val_recall: 0.5076 - val_mcc: 0.0325 - val_f1-score: 0.4453 - val_auc: 0.5072 - val_prc: 0.5020 - lr: 0.0010\n",
            "Epoch 28/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6943 - accuracy: 0.5091 - precision: 0.5091 - recall: 0.5091 - mcc: 0.0172 - f1-score: 0.5036 - auc: 0.5176 - prc: 0.5135\n",
            "Epoch 00028: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 0.6943 - accuracy: 0.5091 - precision: 0.5091 - recall: 0.5091 - mcc: 0.0172 - f1-score: 0.5036 - auc: 0.5176 - prc: 0.5135 - val_loss: 0.6938 - val_accuracy: 0.5152 - val_precision: 0.5152 - val_recall: 0.5152 - val_mcc: 0.0334 - val_f1-score: 0.5112 - val_auc: 0.5163 - val_prc: 0.5123 - lr: 0.0010\n",
            "Epoch 29/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5203 - precision: 0.5203 - recall: 0.5203 - mcc: 0.0399 - f1-score: 0.5172 - auc: 0.5287 - prc: 0.5228\n",
            "Epoch 00029: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.6930 - accuracy: 0.5203 - precision: 0.5203 - recall: 0.5203 - mcc: 0.0399 - f1-score: 0.5172 - auc: 0.5287 - prc: 0.5228 - val_loss: 0.6931 - val_accuracy: 0.5139 - val_precision: 0.5139 - val_recall: 0.5139 - val_mcc: 0.0416 - val_f1-score: 0.4754 - val_auc: 0.5307 - val_prc: 0.5268 - lr: 0.0010\n",
            "Epoch 30/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - mcc: 0.1047 - f1-score: 0.5517 - auc: 0.5647 - prc: 0.5562\n",
            "Epoch 00030: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.6884 - accuracy: 0.5522 - precision: 0.5522 - recall: 0.5522 - mcc: 0.1047 - f1-score: 0.5517 - auc: 0.5647 - prc: 0.5562 - val_loss: 0.7022 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 0.5000 - val_mcc: 0.0217 - val_f1-score: 0.3887 - val_auc: 0.5042 - val_prc: 0.5038 - lr: 0.0010\n",
            "Epoch 31/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.5105 - precision: 0.5105 - recall: 0.5105 - mcc: 0.0212 - f1-score: 0.5105 - auc: 0.5150 - prc: 0.5110\n",
            "Epoch 00031: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6973 - accuracy: 0.5105 - precision: 0.5105 - recall: 0.5105 - mcc: 0.0212 - f1-score: 0.5105 - auc: 0.5150 - prc: 0.5110 - val_loss: 0.6961 - val_accuracy: 0.5223 - val_precision: 0.5223 - val_recall: 0.5223 - val_mcc: 0.0630 - val_f1-score: 0.4822 - val_auc: 0.5213 - val_prc: 0.5187 - lr: 0.0010\n",
            "Epoch 32/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.5179 - precision: 0.5179 - recall: 0.5179 - mcc: 0.0361 - f1-score: 0.5054 - auc: 0.5205 - prc: 0.5160\n",
            "Epoch 00032: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.6952 - accuracy: 0.5179 - precision: 0.5179 - recall: 0.5179 - mcc: 0.0361 - f1-score: 0.5054 - auc: 0.5205 - prc: 0.5160 - val_loss: 0.6947 - val_accuracy: 0.5125 - val_precision: 0.5125 - val_recall: 0.5125 - val_mcc: 0.0540 - val_f1-score: 0.4315 - val_auc: 0.5208 - val_prc: 0.5219 - lr: 0.0010\n",
            "Epoch 33/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6905 - accuracy: 0.5343 - precision: 0.5343 - recall: 0.5343 - mcc: 0.0687 - f1-score: 0.5342 - auc: 0.5515 - prc: 0.5476\n",
            "Epoch 00033: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6905 - accuracy: 0.5343 - precision: 0.5343 - recall: 0.5343 - mcc: 0.0687 - f1-score: 0.5342 - auc: 0.5515 - prc: 0.5476 - val_loss: 0.6883 - val_accuracy: 0.5536 - val_precision: 0.5536 - val_recall: 0.5536 - val_mcc: 0.1548 - val_f1-score: 0.4713 - val_auc: 0.5885 - val_prc: 0.5812 - lr: 0.0010\n",
            "Epoch 34/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6867 - accuracy: 0.5500 - precision: 0.5500 - recall: 0.5500 - mcc: 0.1082 - f1-score: 0.5398 - auc: 0.5706 - prc: 0.5713\n",
            "Epoch 00034: val_accuracy did not improve from 0.56166\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.6867 - accuracy: 0.5500 - precision: 0.5500 - recall: 0.5500 - mcc: 0.1082 - f1-score: 0.5398 - auc: 0.5706 - prc: 0.5713 - val_loss: 0.6970 - val_accuracy: 0.5353 - val_precision: 0.5353 - val_recall: 0.5353 - val_mcc: 0.0853 - val_f1-score: 0.4707 - val_auc: 0.5453 - val_prc: 0.5351 - lr: 0.0010\n",
            "Epoch 35/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.5399 - precision: 0.5399 - recall: 0.5399 - mcc: 0.0804 - f1-score: 0.5378 - auc: 0.5570 - prc: 0.5533\n",
            "Epoch 00035: val_accuracy improved from 0.56166 to 0.58803, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6921 - accuracy: 0.5399 - precision: 0.5399 - recall: 0.5399 - mcc: 0.0804 - f1-score: 0.5378 - auc: 0.5570 - prc: 0.5533 - val_loss: 0.6750 - val_accuracy: 0.5880 - val_precision: 0.5880 - val_recall: 0.5880 - val_mcc: 0.1846 - val_f1-score: 0.5722 - val_auc: 0.6196 - val_prc: 0.6149 - lr: 0.0010\n",
            "Epoch 36/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6667 - accuracy: 0.5849 - precision: 0.5849 - recall: 0.5849 - mcc: 0.1836 - f1-score: 0.5715 - auc: 0.6265 - prc: 0.6254\n",
            "Epoch 00036: val_accuracy did not improve from 0.58803\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.6667 - accuracy: 0.5849 - precision: 0.5849 - recall: 0.5849 - mcc: 0.1836 - f1-score: 0.5715 - auc: 0.6265 - prc: 0.6254 - val_loss: 0.6662 - val_accuracy: 0.5845 - val_precision: 0.5845 - val_recall: 0.5845 - val_mcc: 0.2176 - val_f1-score: 0.5287 - val_auc: 0.6306 - val_prc: 0.6312 - lr: 0.0010\n",
            "Epoch 37/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6640 - accuracy: 0.5861 - precision: 0.5861 - recall: 0.5861 - mcc: 0.1799 - f1-score: 0.5798 - auc: 0.6272 - prc: 0.6287\n",
            "Epoch 00037: val_accuracy improved from 0.58803 to 0.59830, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6640 - accuracy: 0.5861 - precision: 0.5861 - recall: 0.5861 - mcc: 0.1799 - f1-score: 0.5798 - auc: 0.6272 - prc: 0.6287 - val_loss: 0.6651 - val_accuracy: 0.5983 - val_precision: 0.5983 - val_recall: 0.5983 - val_mcc: 0.2083 - val_f1-score: 0.5813 - val_auc: 0.6530 - val_prc: 0.6509 - lr: 0.0010\n",
            "Epoch 38/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6427 - accuracy: 0.6192 - precision: 0.6192 - recall: 0.6192 - mcc: 0.2615 - f1-score: 0.6033 - auc: 0.6681 - prc: 0.6702\n",
            "Epoch 00038: val_accuracy did not improve from 0.59830\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6427 - accuracy: 0.6192 - precision: 0.6192 - recall: 0.6192 - mcc: 0.2615 - f1-score: 0.6033 - auc: 0.6681 - prc: 0.6702 - val_loss: 0.7150 - val_accuracy: 0.5777 - val_precision: 0.5777 - val_recall: 0.5777 - val_mcc: 0.1771 - val_f1-score: 0.5595 - val_auc: 0.6066 - val_prc: 0.6148 - lr: 0.0010\n",
            "Epoch 39/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6295 - accuracy: 0.6334 - precision: 0.6334 - recall: 0.6334 - mcc: 0.2951 - f1-score: 0.6154 - auc: 0.6915 - prc: 0.6927\n",
            "Epoch 00039: val_accuracy improved from 0.59830 to 0.60858, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6295 - accuracy: 0.6334 - precision: 0.6334 - recall: 0.6334 - mcc: 0.2951 - f1-score: 0.6154 - auc: 0.6915 - prc: 0.6927 - val_loss: 0.6457 - val_accuracy: 0.6086 - val_precision: 0.6086 - val_recall: 0.6086 - val_mcc: 0.2461 - val_f1-score: 0.5791 - val_auc: 0.6709 - val_prc: 0.6712 - lr: 0.0010\n",
            "Epoch 40/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5933 - accuracy: 0.6703 - precision: 0.6703 - recall: 0.6703 - mcc: 0.3602 - f1-score: 0.6624 - auc: 0.7410 - prc: 0.7431\n",
            "Epoch 00040: val_accuracy improved from 0.60858 to 0.68275, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.5933 - accuracy: 0.6703 - precision: 0.6703 - recall: 0.6703 - mcc: 0.3602 - f1-score: 0.6624 - auc: 0.7410 - prc: 0.7431 - val_loss: 0.5848 - val_accuracy: 0.6828 - val_precision: 0.6828 - val_recall: 0.6828 - val_mcc: 0.4174 - val_f1-score: 0.6596 - val_auc: 0.7577 - val_prc: 0.7563 - lr: 0.0010\n",
            "Epoch 41/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.7210 - precision: 0.7210 - recall: 0.7210 - mcc: 0.4547 - f1-score: 0.7176 - auc: 0.7998 - prc: 0.8005\n",
            "Epoch 00041: val_accuracy improved from 0.68275 to 0.73101, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.5412 - accuracy: 0.7210 - precision: 0.7210 - recall: 0.7210 - mcc: 0.4547 - f1-score: 0.7176 - auc: 0.7998 - prc: 0.8005 - val_loss: 0.5415 - val_accuracy: 0.7310 - val_precision: 0.7310 - val_recall: 0.7310 - val_mcc: 0.4620 - val_f1-score: 0.7307 - val_auc: 0.8111 - val_prc: 0.8068 - lr: 0.0010\n",
            "Epoch 42/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5799 - accuracy: 0.6946 - precision: 0.6946 - recall: 0.6946 - mcc: 0.3895 - f1-score: 0.6945 - auc: 0.7675 - prc: 0.7666\n",
            "Epoch 00042: val_accuracy did not improve from 0.73101\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.5799 - accuracy: 0.6946 - precision: 0.6946 - recall: 0.6946 - mcc: 0.3895 - f1-score: 0.6945 - auc: 0.7675 - prc: 0.7666 - val_loss: 0.6821 - val_accuracy: 0.6130 - val_precision: 0.6130 - val_recall: 0.6130 - val_mcc: 0.3261 - val_f1-score: 0.5478 - val_auc: 0.7189 - val_prc: 0.7199 - lr: 0.0010\n",
            "Epoch 43/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.7671 - precision: 0.7671 - recall: 0.7671 - mcc: 0.5486 - f1-score: 0.7641 - auc: 0.8444 - prc: 0.8413\n",
            "Epoch 00043: val_accuracy improved from 0.73101 to 0.78374, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.4991 - accuracy: 0.7671 - precision: 0.7671 - recall: 0.7671 - mcc: 0.5486 - f1-score: 0.7641 - auc: 0.8444 - prc: 0.8413 - val_loss: 0.4725 - val_accuracy: 0.7837 - val_precision: 0.7837 - val_recall: 0.7837 - val_mcc: 0.5955 - val_f1-score: 0.7775 - val_auc: 0.8675 - val_prc: 0.8652 - lr: 0.0010\n",
            "Epoch 44/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.8593 - precision: 0.8593 - recall: 0.8593 - mcc: 0.7193 - f1-score: 0.8592 - auc: 0.9348 - prc: 0.9350\n",
            "Epoch 00044: val_accuracy improved from 0.78374 to 0.87712, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.3323 - accuracy: 0.8593 - precision: 0.8593 - recall: 0.8593 - mcc: 0.7193 - f1-score: 0.8592 - auc: 0.9348 - prc: 0.9350 - val_loss: 0.3090 - val_accuracy: 0.8771 - val_precision: 0.8771 - val_recall: 0.8771 - val_mcc: 0.7559 - val_f1-score: 0.8768 - val_auc: 0.9463 - val_prc: 0.9413 - lr: 0.0010\n",
            "Epoch 45/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9010 - precision: 0.9010 - recall: 0.9010 - mcc: 0.8023 - f1-score: 0.9010 - auc: 0.9671 - prc: 0.9666\n",
            "Epoch 00045: val_accuracy improved from 0.87712 to 0.92761, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.2377 - accuracy: 0.9010 - precision: 0.9010 - recall: 0.9010 - mcc: 0.8023 - f1-score: 0.9010 - auc: 0.9671 - prc: 0.9666 - val_loss: 0.1994 - val_accuracy: 0.9276 - val_precision: 0.9276 - val_recall: 0.9276 - val_mcc: 0.8562 - val_f1-score: 0.9276 - val_auc: 0.9758 - val_prc: 0.9744 - lr: 0.0010\n",
            "Epoch 46/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9350 - precision: 0.9350 - recall: 0.9350 - mcc: 0.8711 - f1-score: 0.9350 - auc: 0.9850 - prc: 0.9842\n",
            "Epoch 00046: val_accuracy did not improve from 0.92761\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 0.1569 - accuracy: 0.9350 - precision: 0.9350 - recall: 0.9350 - mcc: 0.8711 - f1-score: 0.9350 - auc: 0.9850 - prc: 0.9842 - val_loss: 0.1973 - val_accuracy: 0.9272 - val_precision: 0.9272 - val_recall: 0.9272 - val_mcc: 0.8546 - val_f1-score: 0.9272 - val_auc: 0.9764 - val_prc: 0.9751 - lr: 0.0010\n",
            "Epoch 47/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9392 - precision: 0.9392 - recall: 0.9392 - mcc: 0.8797 - f1-score: 0.9391 - auc: 0.9885 - prc: 0.9882\n",
            "Epoch 00047: val_accuracy improved from 0.92761 to 0.94951, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.1353 - accuracy: 0.9392 - precision: 0.9392 - recall: 0.9392 - mcc: 0.8797 - f1-score: 0.9391 - auc: 0.9885 - prc: 0.9882 - val_loss: 0.1172 - val_accuracy: 0.9495 - val_precision: 0.9495 - val_recall: 0.9495 - val_mcc: 0.8996 - val_f1-score: 0.9495 - val_auc: 0.9918 - val_prc: 0.9916 - lr: 0.0010\n",
            "Epoch 48/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9454 - precision: 0.9454 - recall: 0.9454 - mcc: 0.8919 - f1-score: 0.9454 - auc: 0.9911 - prc: 0.9909\n",
            "Epoch 00048: val_accuracy did not improve from 0.94951\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.1188 - accuracy: 0.9454 - precision: 0.9454 - recall: 0.9454 - mcc: 0.8919 - f1-score: 0.9454 - auc: 0.9911 - prc: 0.9909 - val_loss: 0.1450 - val_accuracy: 0.9468 - val_precision: 0.9468 - val_recall: 0.9468 - val_mcc: 0.8952 - val_f1-score: 0.9468 - val_auc: 0.9869 - val_prc: 0.9859 - lr: 0.0010\n",
            "Epoch 49/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9514 - precision: 0.9514 - recall: 0.9514 - mcc: 0.9034 - f1-score: 0.9514 - auc: 0.9931 - prc: 0.9928\n",
            "Epoch 00049: val_accuracy did not improve from 0.94951\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.1030 - accuracy: 0.9514 - precision: 0.9514 - recall: 0.9514 - mcc: 0.9034 - f1-score: 0.9514 - auc: 0.9931 - prc: 0.9928 - val_loss: 0.2705 - val_accuracy: 0.9267 - val_precision: 0.9267 - val_recall: 0.9267 - val_mcc: 0.8535 - val_f1-score: 0.9267 - val_auc: 0.9716 - val_prc: 0.9663 - lr: 0.0010\n",
            "Epoch 50/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1486 - accuracy: 0.9335 - precision: 0.9335 - recall: 0.9335 - mcc: 0.8673 - f1-score: 0.9335 - auc: 0.9864 - prc: 0.9860\n",
            "Epoch 00050: val_accuracy improved from 0.94951 to 0.95264, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.1486 - accuracy: 0.9335 - precision: 0.9335 - recall: 0.9335 - mcc: 0.8673 - f1-score: 0.9335 - auc: 0.9864 - prc: 0.9860 - val_loss: 0.1141 - val_accuracy: 0.9526 - val_precision: 0.9526 - val_recall: 0.9526 - val_mcc: 0.9074 - val_f1-score: 0.9526 - val_auc: 0.9917 - val_prc: 0.9915 - lr: 0.0010\n",
            "Epoch 51/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.9581 - precision: 0.9581 - recall: 0.9581 - mcc: 0.9170 - f1-score: 0.9581 - auc: 0.9953 - prc: 0.9954\n",
            "Epoch 00051: val_accuracy improved from 0.95264 to 0.95755, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0866 - accuracy: 0.9581 - precision: 0.9581 - recall: 0.9581 - mcc: 0.9170 - f1-score: 0.9581 - auc: 0.9953 - prc: 0.9954 - val_loss: 0.1029 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_mcc: 0.9162 - val_f1-score: 0.9575 - val_auc: 0.9937 - val_prc: 0.9933 - lr: 0.0010\n",
            "Epoch 52/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9673 - precision: 0.9673 - recall: 0.9673 - mcc: 0.9348 - f1-score: 0.9673 - auc: 0.9970 - prc: 0.9971\n",
            "Epoch 00052: val_accuracy improved from 0.95755 to 0.96247, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.0710 - accuracy: 0.9673 - precision: 0.9673 - recall: 0.9673 - mcc: 0.9348 - f1-score: 0.9673 - auc: 0.9970 - prc: 0.9971 - val_loss: 0.1016 - val_accuracy: 0.9625 - val_precision: 0.9625 - val_recall: 0.9625 - val_mcc: 0.9267 - val_f1-score: 0.9625 - val_auc: 0.9938 - val_prc: 0.9933 - lr: 0.0010\n",
            "Epoch 53/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9718 - precision: 0.9718 - recall: 0.9718 - mcc: 0.9437 - f1-score: 0.9718 - auc: 0.9976 - prc: 0.9976\n",
            "Epoch 00053: val_accuracy did not improve from 0.96247\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0622 - accuracy: 0.9718 - precision: 0.9718 - recall: 0.9718 - mcc: 0.9437 - f1-score: 0.9718 - auc: 0.9976 - prc: 0.9976 - val_loss: 0.1084 - val_accuracy: 0.9522 - val_precision: 0.9522 - val_recall: 0.9522 - val_mcc: 0.9048 - val_f1-score: 0.9522 - val_auc: 0.9922 - val_prc: 0.9914 - lr: 0.0010\n",
            "Epoch 54/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9562 - precision: 0.9562 - recall: 0.9562 - mcc: 0.9125 - f1-score: 0.9562 - auc: 0.9940 - prc: 0.9939\n",
            "Epoch 00054: val_accuracy did not improve from 0.96247\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.1001 - accuracy: 0.9562 - precision: 0.9562 - recall: 0.9562 - mcc: 0.9125 - f1-score: 0.9562 - auc: 0.9940 - prc: 0.9939 - val_loss: 0.1241 - val_accuracy: 0.9526 - val_precision: 0.9526 - val_recall: 0.9526 - val_mcc: 0.9054 - val_f1-score: 0.9526 - val_auc: 0.9904 - val_prc: 0.9894 - lr: 0.0010\n",
            "Epoch 55/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - mcc: 0.9302 - f1-score: 0.9650 - auc: 0.9963 - prc: 0.9963\n",
            "Epoch 00055: val_accuracy did not improve from 0.96247\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.0791 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - mcc: 0.9302 - f1-score: 0.9650 - auc: 0.9963 - prc: 0.9963 - val_loss: 0.1124 - val_accuracy: 0.9540 - val_precision: 0.9540 - val_recall: 0.9540 - val_mcc: 0.9096 - val_f1-score: 0.9540 - val_auc: 0.9924 - val_prc: 0.9916 - lr: 0.0010\n",
            "Epoch 56/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9708 - precision: 0.9708 - recall: 0.9708 - mcc: 0.9416 - f1-score: 0.9708 - auc: 0.9970 - prc: 0.9968\n",
            "Epoch 00056: val_accuracy improved from 0.96247 to 0.96381, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.0686 - accuracy: 0.9708 - precision: 0.9708 - recall: 0.9708 - mcc: 0.9416 - f1-score: 0.9708 - auc: 0.9970 - prc: 0.9968 - val_loss: 0.1017 - val_accuracy: 0.9638 - val_precision: 0.9638 - val_recall: 0.9638 - val_mcc: 0.9278 - val_f1-score: 0.9638 - val_auc: 0.9934 - val_prc: 0.9925 - lr: 0.0010\n",
            "Epoch 57/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9797 - precision: 0.9797 - recall: 0.9797 - mcc: 0.9595 - f1-score: 0.9797 - auc: 0.9988 - prc: 0.9988\n",
            "Epoch 00057: val_accuracy did not improve from 0.96381\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.0476 - accuracy: 0.9797 - precision: 0.9797 - recall: 0.9797 - mcc: 0.9595 - f1-score: 0.9797 - auc: 0.9988 - prc: 0.9988 - val_loss: 0.1025 - val_accuracy: 0.9638 - val_precision: 0.9638 - val_recall: 0.9638 - val_mcc: 0.9280 - val_f1-score: 0.9638 - val_auc: 0.9942 - val_prc: 0.9933 - lr: 0.0010\n",
            "Epoch 58/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - mcc: 0.9613 - f1-score: 0.9806 - auc: 0.9990 - prc: 0.9990\n",
            "Epoch 00058: val_accuracy improved from 0.96381 to 0.96425, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0440 - accuracy: 0.9806 - precision: 0.9806 - recall: 0.9806 - mcc: 0.9613 - f1-score: 0.9806 - auc: 0.9990 - prc: 0.9990 - val_loss: 0.0997 - val_accuracy: 0.9643 - val_precision: 0.9643 - val_recall: 0.9643 - val_mcc: 0.9288 - val_f1-score: 0.9643 - val_auc: 0.9938 - val_prc: 0.9928 - lr: 0.0010\n",
            "Epoch 59/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - mcc: 0.9651 - f1-score: 0.9826 - auc: 0.9990 - prc: 0.9990\n",
            "Epoch 00059: val_accuracy improved from 0.96425 to 0.96515, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.0415 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - mcc: 0.9651 - f1-score: 0.9826 - auc: 0.9990 - prc: 0.9990 - val_loss: 0.1246 - val_accuracy: 0.9651 - val_precision: 0.9651 - val_recall: 0.9651 - val_mcc: 0.9306 - val_f1-score: 0.9651 - val_auc: 0.9904 - val_prc: 0.9883 - lr: 0.0010\n",
            "Epoch 60/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.9836 - precision: 0.9836 - recall: 0.9836 - mcc: 0.9672 - f1-score: 0.9836 - auc: 0.9989 - prc: 0.9989\n",
            "Epoch 00060: val_accuracy did not improve from 0.96515\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 0.0423 - accuracy: 0.9836 - precision: 0.9836 - recall: 0.9836 - mcc: 0.9672 - f1-score: 0.9836 - auc: 0.9989 - prc: 0.9989 - val_loss: 0.1372 - val_accuracy: 0.9625 - val_precision: 0.9625 - val_recall: 0.9625 - val_mcc: 0.9250 - val_f1-score: 0.9625 - val_auc: 0.9899 - val_prc: 0.9875 - lr: 0.0010\n",
            "Epoch 61/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 0.9838 - precision: 0.9838 - recall: 0.9838 - mcc: 0.9676 - f1-score: 0.9838 - auc: 0.9980 - prc: 0.9977\n",
            "Epoch 00061: val_accuracy did not improve from 0.96515\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0481 - accuracy: 0.9838 - precision: 0.9838 - recall: 0.9838 - mcc: 0.9676 - f1-score: 0.9838 - auc: 0.9980 - prc: 0.9977 - val_loss: 0.1568 - val_accuracy: 0.9401 - val_precision: 0.9401 - val_recall: 0.9401 - val_mcc: 0.8803 - val_f1-score: 0.9401 - val_auc: 0.9858 - val_prc: 0.9845 - lr: 0.0010\n",
            "Epoch 62/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9759 - precision: 0.9759 - recall: 0.9759 - mcc: 0.9518 - f1-score: 0.9759 - auc: 0.9976 - prc: 0.9976\n",
            "Epoch 00062: val_accuracy did not improve from 0.96515\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.0623 - accuracy: 0.9759 - precision: 0.9759 - recall: 0.9759 - mcc: 0.9518 - f1-score: 0.9759 - auc: 0.9976 - prc: 0.9976 - val_loss: 0.1236 - val_accuracy: 0.9625 - val_precision: 0.9625 - val_recall: 0.9625 - val_mcc: 0.9251 - val_f1-score: 0.9625 - val_auc: 0.9902 - val_prc: 0.9881 - lr: 0.0010\n",
            "Epoch 63/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0952 - accuracy: 0.9651 - precision: 0.9651 - recall: 0.9651 - mcc: 0.9303 - f1-score: 0.9651 - auc: 0.9939 - prc: 0.9934\n",
            "Epoch 00063: val_accuracy did not improve from 0.96515\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.0952 - accuracy: 0.9651 - precision: 0.9651 - recall: 0.9651 - mcc: 0.9303 - f1-score: 0.9651 - auc: 0.9939 - prc: 0.9934 - val_loss: 0.1470 - val_accuracy: 0.9441 - val_precision: 0.9441 - val_recall: 0.9441 - val_mcc: 0.8883 - val_f1-score: 0.9441 - val_auc: 0.9887 - val_prc: 0.9881 - lr: 0.0010\n",
            "Epoch 64/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 0.9788 - precision: 0.9788 - recall: 0.9788 - mcc: 0.9577 - f1-score: 0.9788 - auc: 0.9984 - prc: 0.9983\n",
            "Epoch 00064: val_accuracy did not improve from 0.96515\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0519 - accuracy: 0.9788 - precision: 0.9788 - recall: 0.9788 - mcc: 0.9577 - f1-score: 0.9788 - auc: 0.9984 - prc: 0.9983 - val_loss: 0.1219 - val_accuracy: 0.9571 - val_precision: 0.9571 - val_recall: 0.9571 - val_mcc: 0.9144 - val_f1-score: 0.9571 - val_auc: 0.9910 - val_prc: 0.9894 - lr: 0.0010\n",
            "Epoch 65/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.9855 - precision: 0.9855 - recall: 0.9855 - mcc: 0.9710 - f1-score: 0.9855 - auc: 0.9992 - prc: 0.9992\n",
            "Epoch 00065: val_accuracy did not improve from 0.96515\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0361 - accuracy: 0.9855 - precision: 0.9855 - recall: 0.9855 - mcc: 0.9710 - f1-score: 0.9855 - auc: 0.9992 - prc: 0.9992 - val_loss: 0.1139 - val_accuracy: 0.9651 - val_precision: 0.9651 - val_recall: 0.9651 - val_mcc: 0.9303 - val_f1-score: 0.9651 - val_auc: 0.9924 - val_prc: 0.9913 - lr: 0.0010\n",
            "Epoch 66/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9904 - precision: 0.9904 - recall: 0.9904 - mcc: 0.9808 - f1-score: 0.9904 - auc: 0.9994 - prc: 0.9993\n",
            "Epoch 00066: val_accuracy improved from 0.96515 to 0.96783, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0295 - accuracy: 0.9904 - precision: 0.9904 - recall: 0.9904 - mcc: 0.9808 - f1-score: 0.9904 - auc: 0.9994 - prc: 0.9993 - val_loss: 0.1264 - val_accuracy: 0.9678 - val_precision: 0.9678 - val_recall: 0.9678 - val_mcc: 0.9356 - val_f1-score: 0.9678 - val_auc: 0.9908 - val_prc: 0.9886 - lr: 0.0010\n",
            "Epoch 67/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9916 - precision: 0.9916 - recall: 0.9916 - mcc: 0.9832 - f1-score: 0.9916 - auc: 0.9995 - prc: 0.9993\n",
            "Epoch 00067: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.0222 - accuracy: 0.9916 - precision: 0.9916 - recall: 0.9916 - mcc: 0.9832 - f1-score: 0.9916 - auc: 0.9995 - prc: 0.9993 - val_loss: 0.1442 - val_accuracy: 0.9634 - val_precision: 0.9634 - val_recall: 0.9634 - val_mcc: 0.9267 - val_f1-score: 0.9634 - val_auc: 0.9889 - val_prc: 0.9865 - lr: 0.0010\n",
            "Epoch 68/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0261 - accuracy: 0.9904 - precision: 0.9904 - recall: 0.9904 - mcc: 0.9808 - f1-score: 0.9904 - auc: 0.9997 - prc: 0.9997\n",
            "Epoch 00068: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0261 - accuracy: 0.9904 - precision: 0.9904 - recall: 0.9904 - mcc: 0.9808 - f1-score: 0.9904 - auc: 0.9997 - prc: 0.9997 - val_loss: 0.1440 - val_accuracy: 0.9620 - val_precision: 0.9620 - val_recall: 0.9620 - val_mcc: 0.9240 - val_f1-score: 0.9620 - val_auc: 0.9885 - val_prc: 0.9856 - lr: 0.0010\n",
            "Epoch 69/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - mcc: 0.9860 - f1-score: 0.9930 - auc: 0.9997 - prc: 0.9997\n",
            "Epoch 00069: val_accuracy did not improve from 0.96783\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.0200 - accuracy: 0.9930 - precision: 0.9930 - recall: 0.9930 - mcc: 0.9860 - f1-score: 0.9930 - auc: 0.9997 - prc: 0.9997 - val_loss: 0.1754 - val_accuracy: 0.9647 - val_precision: 0.9647 - val_recall: 0.9647 - val_mcc: 0.9294 - val_f1-score: 0.9647 - val_auc: 0.9856 - val_prc: 0.9818 - lr: 0.0010\n",
            "Epoch 70/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9933 - precision: 0.9933 - recall: 0.9933 - mcc: 0.9866 - f1-score: 0.9933 - auc: 0.9997 - prc: 0.9997\n",
            "Epoch 00070: val_accuracy improved from 0.96783 to 0.96872, saving model to my_best_model_2.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0200 - accuracy: 0.9933 - precision: 0.9933 - recall: 0.9933 - mcc: 0.9866 - f1-score: 0.9933 - auc: 0.9997 - prc: 0.9997 - val_loss: 0.1457 - val_accuracy: 0.9687 - val_precision: 0.9687 - val_recall: 0.9687 - val_mcc: 0.9375 - val_f1-score: 0.9687 - val_auc: 0.9871 - val_prc: 0.9836 - lr: 0.0010\n",
            "Epoch 71/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - mcc: 0.9692 - f1-score: 0.9846 - auc: 0.9979 - prc: 0.9975\n",
            "Epoch 00071: val_accuracy did not improve from 0.96872\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0474 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - mcc: 0.9692 - f1-score: 0.9846 - auc: 0.9979 - prc: 0.9975 - val_loss: 0.1371 - val_accuracy: 0.9562 - val_precision: 0.9562 - val_recall: 0.9562 - val_mcc: 0.9125 - val_f1-score: 0.9562 - val_auc: 0.9882 - val_prc: 0.9861 - lr: 0.0010\n",
            "Epoch 72/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.9868 - precision: 0.9868 - recall: 0.9868 - mcc: 0.9735 - f1-score: 0.9868 - auc: 0.9990 - prc: 0.9990\n",
            "Epoch 00072: val_accuracy did not improve from 0.96872\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.0407 - accuracy: 0.9868 - precision: 0.9868 - recall: 0.9868 - mcc: 0.9735 - f1-score: 0.9868 - auc: 0.9990 - prc: 0.9990 - val_loss: 0.1576 - val_accuracy: 0.9620 - val_precision: 0.9620 - val_recall: 0.9620 - val_mcc: 0.9241 - val_f1-score: 0.9620 - val_auc: 0.9869 - val_prc: 0.9836 - lr: 0.0010\n",
            "Epoch 73/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9885 - auc: 0.9990 - prc: 0.9988\n",
            "Epoch 00073: val_accuracy did not improve from 0.96872\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.0341 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9885 - auc: 0.9990 - prc: 0.9988 - val_loss: 0.1427 - val_accuracy: 0.9665 - val_precision: 0.9665 - val_recall: 0.9665 - val_mcc: 0.9330 - val_f1-score: 0.9665 - val_auc: 0.9892 - val_prc: 0.9865 - lr: 0.0010\n",
            "Epoch 74/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - mcc: 0.9851 - f1-score: 0.9925 - auc: 0.9998 - prc: 0.9998\n",
            "Epoch 00074: val_accuracy did not improve from 0.96872\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0203 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - mcc: 0.9851 - f1-score: 0.9925 - auc: 0.9998 - prc: 0.9998 - val_loss: 0.1687 - val_accuracy: 0.9656 - val_precision: 0.9656 - val_recall: 0.9656 - val_mcc: 0.9312 - val_f1-score: 0.9656 - val_auc: 0.9857 - val_prc: 0.9819 - lr: 0.0010\n",
            "Epoch 75/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - mcc: 0.9851 - f1-score: 0.9925 - auc: 0.9997 - prc: 0.9997\n",
            "Epoch 00075: val_accuracy did not improve from 0.96872\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.0230 - accuracy: 0.9925 - precision: 0.9925 - recall: 0.9925 - mcc: 0.9851 - f1-score: 0.9925 - auc: 0.9997 - prc: 0.9997 - val_loss: 0.1726 - val_accuracy: 0.9660 - val_precision: 0.9660 - val_recall: 0.9660 - val_mcc: 0.9321 - val_f1-score: 0.9660 - val_auc: 0.9825 - val_prc: 0.9776 - lr: 0.0010\n",
            "Epoch 76/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 0.9909 - precision: 0.9909 - recall: 0.9909 - mcc: 0.9819 - f1-score: 0.9909 - auc: 0.9994 - prc: 0.9994\n",
            "Epoch 00076: val_accuracy did not improve from 0.96872\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.0273 - accuracy: 0.9909 - precision: 0.9909 - recall: 0.9909 - mcc: 0.9819 - f1-score: 0.9909 - auc: 0.9994 - prc: 0.9994 - val_loss: 0.1446 - val_accuracy: 0.9598 - val_precision: 0.9598 - val_recall: 0.9598 - val_mcc: 0.9196 - val_f1-score: 0.9598 - val_auc: 0.9878 - val_prc: 0.9852 - lr: 0.0010\n",
            "Epoch 77/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - mcc: 0.9701 - f1-score: 0.9851 - auc: 0.9990 - prc: 0.9989\n",
            "Epoch 00077: val_accuracy did not improve from 0.96872\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.0387 - accuracy: 0.9851 - precision: 0.9851 - recall: 0.9851 - mcc: 0.9701 - f1-score: 0.9851 - auc: 0.9990 - prc: 0.9989 - val_loss: 0.1453 - val_accuracy: 0.9665 - val_precision: 0.9665 - val_recall: 0.9665 - val_mcc: 0.9331 - val_f1-score: 0.9665 - val_auc: 0.9866 - val_prc: 0.9831 - lr: 0.0010\n",
            "Epoch 78/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - mcc: 0.9760 - f1-score: 0.9880 - auc: 0.9989 - prc: 0.9987\n",
            "Epoch 00078: val_accuracy did not improve from 0.96872\n",
            "Restoring model weights from the end of the best epoch: 58.\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.0346 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - mcc: 0.9760 - f1-score: 0.9880 - auc: 0.9989 - prc: 0.9987 - val_loss: 0.1878 - val_accuracy: 0.9576 - val_precision: 0.9576 - val_recall: 0.9576 - val_mcc: 0.9151 - val_f1-score: 0.9575 - val_auc: 0.9829 - val_prc: 0.9785 - lr: 0.0010\n",
            "Epoch 00078: early stopping\n",
            "==================End training 2========================\n",
            "accuracy: 0.9606791778373548, precision: 0.9693831607384061, recall: 0.952233524988943, specificity: 0.9521064301552107, mcc: 0.9215116705435737 ,f1-score: 0.9607318161535029\n",
            "==================== Training time  3 =====================\n",
            "Epoch 1/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 2.0499 - accuracy: 0.5936 - precision: 0.5936 - recall: 0.5936 - mcc: 0.1874 - f1-score: 0.5935 - auc: 0.6699 - prc: 0.6979\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.54850, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 53s 360ms/step - loss: 2.0499 - accuracy: 0.5936 - precision: 0.5936 - recall: 0.5936 - mcc: 0.1874 - f1-score: 0.5935 - auc: 0.6699 - prc: 0.6979 - val_loss: 1.5180 - val_accuracy: 0.5485 - val_precision: 0.5485 - val_recall: 0.5485 - val_mcc: 0.0996 - val_f1-score: 0.5477 - val_auc: 0.5379 - val_prc: 0.5306 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 1.2298 - accuracy: 0.4955 - precision: 0.4955 - recall: 0.4955 - mcc: -0.0091 - f1-score: 0.4954 - auc: 0.5017 - prc: 0.5022\n",
            "Epoch 00002: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 1.2298 - accuracy: 0.4955 - precision: 0.4955 - recall: 0.4955 - mcc: -0.0091 - f1-score: 0.4954 - auc: 0.5017 - prc: 0.5022 - val_loss: 1.0100 - val_accuracy: 0.5011 - val_precision: 0.5011 - val_recall: 0.5011 - val_mcc: -0.0040 - val_f1-score: 0.4870 - val_auc: 0.4914 - val_prc: 0.4920 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.8974 - accuracy: 0.5077 - precision: 0.5077 - recall: 0.5077 - mcc: 0.0140 - f1-score: 0.5034 - auc: 0.5033 - prc: 0.5004\n",
            "Epoch 00003: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 270ms/step - loss: 0.8974 - accuracy: 0.5077 - precision: 0.5077 - recall: 0.5077 - mcc: 0.0140 - f1-score: 0.5034 - auc: 0.5033 - prc: 0.5004 - val_loss: 0.8126 - val_accuracy: 0.5087 - val_precision: 0.5087 - val_recall: 0.5087 - val_mcc: -0.0023 - val_f1-score: 0.3594 - val_auc: 0.5335 - val_prc: 0.5289 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7726 - accuracy: 0.5051 - precision: 0.5051 - recall: 0.5051 - mcc: 0.0113 - f1-score: 0.5031 - auc: 0.5086 - prc: 0.5076\n",
            "Epoch 00004: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 18s 268ms/step - loss: 0.7726 - accuracy: 0.5051 - precision: 0.5051 - recall: 0.5051 - mcc: 0.0113 - f1-score: 0.5031 - auc: 0.5086 - prc: 0.5076 - val_loss: 0.7413 - val_accuracy: 0.5199 - val_precision: 0.5199 - val_recall: 0.5199 - val_mcc: 0.0390 - val_f1-score: 0.4322 - val_auc: 0.5253 - val_prc: 0.5165 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.5113 - precision: 0.5113 - recall: 0.5113 - mcc: 0.0227 - f1-score: 0.5111 - auc: 0.5128 - prc: 0.5078\n",
            "Epoch 00005: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 0.7261 - accuracy: 0.5113 - precision: 0.5113 - recall: 0.5113 - mcc: 0.0227 - f1-score: 0.5111 - auc: 0.5128 - prc: 0.5078 - val_loss: 0.7137 - val_accuracy: 0.5145 - val_precision: 0.5145 - val_recall: 0.5145 - val_mcc: 0.0237 - val_f1-score: 0.4052 - val_auc: 0.5290 - val_prc: 0.5190 - lr: 0.0010\n",
            "Epoch 6/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7083 - accuracy: 0.5091 - precision: 0.5091 - recall: 0.5091 - mcc: 0.0180 - f1-score: 0.5089 - auc: 0.5109 - prc: 0.5060\n",
            "Epoch 00006: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.7083 - accuracy: 0.5091 - precision: 0.5091 - recall: 0.5091 - mcc: 0.0180 - f1-score: 0.5089 - auc: 0.5109 - prc: 0.5060 - val_loss: 0.7024 - val_accuracy: 0.5467 - val_precision: 0.5467 - val_recall: 0.5467 - val_mcc: 0.0962 - val_f1-score: 0.5458 - val_auc: 0.5441 - val_prc: 0.5306 - lr: 0.0010\n",
            "Epoch 7/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.5053 - precision: 0.5053 - recall: 0.5053 - mcc: 0.0114 - f1-score: 0.5045 - auc: 0.5079 - prc: 0.5075\n",
            "Epoch 00007: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.7015 - accuracy: 0.5053 - precision: 0.5053 - recall: 0.5053 - mcc: 0.0114 - f1-score: 0.5045 - auc: 0.5079 - prc: 0.5075 - val_loss: 0.6987 - val_accuracy: 0.5096 - val_precision: 0.5096 - val_recall: 0.5096 - val_mcc: 0.0000e+00 - val_f1-score: 0.3376 - val_auc: 0.5240 - val_prc: 0.5229 - lr: 0.0010\n",
            "Epoch 8/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6977 - accuracy: 0.5067 - precision: 0.5067 - recall: 0.5067 - mcc: 0.0134 - f1-score: 0.5062 - auc: 0.5119 - prc: 0.5101\n",
            "Epoch 00008: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 269ms/step - loss: 0.6977 - accuracy: 0.5067 - precision: 0.5067 - recall: 0.5067 - mcc: 0.0134 - f1-score: 0.5062 - auc: 0.5119 - prc: 0.5101 - val_loss: 0.6960 - val_accuracy: 0.5074 - val_precision: 0.5074 - val_recall: 0.5074 - val_mcc: -0.0241 - val_f1-score: 0.3414 - val_auc: 0.5348 - val_prc: 0.5305 - lr: 0.0010\n",
            "Epoch 9/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.5115 - precision: 0.5115 - recall: 0.5115 - mcc: 0.0223 - f1-score: 0.5068 - auc: 0.5099 - prc: 0.5070\n",
            "Epoch 00009: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6957 - accuracy: 0.5115 - precision: 0.5115 - recall: 0.5115 - mcc: 0.0223 - f1-score: 0.5068 - auc: 0.5099 - prc: 0.5070 - val_loss: 0.6943 - val_accuracy: 0.5114 - val_precision: 0.5114 - val_recall: 0.5114 - val_mcc: 0.0128 - val_f1-score: 0.3767 - val_auc: 0.5327 - val_prc: 0.5274 - lr: 0.0010\n",
            "Epoch 10/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.5063 - precision: 0.5063 - recall: 0.5063 - mcc: 0.0122 - f1-score: 0.5030 - auc: 0.5101 - prc: 0.5078\n",
            "Epoch 00010: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6951 - accuracy: 0.5063 - precision: 0.5063 - recall: 0.5063 - mcc: 0.0122 - f1-score: 0.5030 - auc: 0.5101 - prc: 0.5078 - val_loss: 0.6940 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: -0.0240 - val_f1-score: 0.3435 - val_auc: 0.5331 - val_prc: 0.5280 - lr: 0.0010\n",
            "Epoch 11/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.5114 - precision: 0.5114 - recall: 0.5114 - mcc: 0.0232 - f1-score: 0.5114 - auc: 0.5167 - prc: 0.5111\n",
            "Epoch 00011: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6946 - accuracy: 0.5114 - precision: 0.5114 - recall: 0.5114 - mcc: 0.0232 - f1-score: 0.5114 - auc: 0.5167 - prc: 0.5111 - val_loss: 0.6932 - val_accuracy: 0.5105 - val_precision: 0.5105 - val_recall: 0.5105 - val_mcc: 0.0085 - val_f1-score: 0.3742 - val_auc: 0.5346 - val_prc: 0.5290 - lr: 0.0010\n",
            "Epoch 12/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5164 - precision: 0.5164 - recall: 0.5164 - mcc: 0.0330 - f1-score: 0.5163 - auc: 0.5246 - prc: 0.5189\n",
            "Epoch 00012: val_accuracy did not improve from 0.54850\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6932 - accuracy: 0.5164 - precision: 0.5164 - recall: 0.5164 - mcc: 0.0330 - f1-score: 0.5163 - auc: 0.5246 - prc: 0.5189 - val_loss: 0.6933 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078 - val_mcc: -0.0113 - val_f1-score: 0.3501 - val_auc: 0.5315 - val_prc: 0.5273 - lr: 0.0010\n",
            "Epoch 13/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5104 - precision: 0.5104 - recall: 0.5104 - mcc: 0.0205 - f1-score: 0.5102 - auc: 0.5179 - prc: 0.5158\n",
            "Epoch 00013: val_accuracy improved from 0.54850 to 0.55208, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6933 - accuracy: 0.5104 - precision: 0.5104 - recall: 0.5104 - mcc: 0.0205 - f1-score: 0.5102 - auc: 0.5179 - prc: 0.5158 - val_loss: 0.6904 - val_accuracy: 0.5521 - val_precision: 0.5521 - val_recall: 0.5521 - val_mcc: 0.1027 - val_f1-score: 0.5502 - val_auc: 0.5561 - val_prc: 0.5375 - lr: 0.0010\n",
            "Epoch 14/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5212 - precision: 0.5212 - recall: 0.5212 - mcc: 0.0424 - f1-score: 0.5211 - auc: 0.5254 - prc: 0.5193\n",
            "Epoch 00014: val_accuracy improved from 0.55208 to 0.55342, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6930 - accuracy: 0.5212 - precision: 0.5212 - recall: 0.5212 - mcc: 0.0424 - f1-score: 0.5211 - auc: 0.5254 - prc: 0.5193 - val_loss: 0.6906 - val_accuracy: 0.5534 - val_precision: 0.5534 - val_recall: 0.5534 - val_mcc: 0.1081 - val_f1-score: 0.5332 - val_auc: 0.5645 - val_prc: 0.5508 - lr: 0.0010\n",
            "Epoch 15/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5128 - precision: 0.5128 - recall: 0.5128 - mcc: 0.0252 - f1-score: 0.5122 - auc: 0.5184 - prc: 0.5131\n",
            "Epoch 00015: val_accuracy did not improve from 0.55342\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6937 - accuracy: 0.5128 - precision: 0.5128 - recall: 0.5128 - mcc: 0.0252 - f1-score: 0.5122 - auc: 0.5184 - prc: 0.5131 - val_loss: 0.6912 - val_accuracy: 0.5498 - val_precision: 0.5498 - val_recall: 0.5498 - val_mcc: 0.0982 - val_f1-score: 0.5398 - val_auc: 0.5579 - val_prc: 0.5397 - lr: 0.0010\n",
            "Epoch 16/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6930 - accuracy: 0.5205 - precision: 0.5205 - recall: 0.5205 - mcc: 0.0410 - f1-score: 0.5204 - auc: 0.5310 - prc: 0.5244\n",
            "Epoch 00016: val_accuracy improved from 0.55342 to 0.56236, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6930 - accuracy: 0.5205 - precision: 0.5205 - recall: 0.5205 - mcc: 0.0410 - f1-score: 0.5204 - auc: 0.5310 - prc: 0.5244 - val_loss: 0.6891 - val_accuracy: 0.5624 - val_precision: 0.5624 - val_recall: 0.5624 - val_mcc: 0.1233 - val_f1-score: 0.5598 - val_auc: 0.5821 - val_prc: 0.5692 - lr: 0.0010\n",
            "Epoch 17/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5393 - precision: 0.5393 - recall: 0.5393 - mcc: 0.0795 - f1-score: 0.5387 - auc: 0.5475 - prc: 0.5392\n",
            "Epoch 00017: val_accuracy did not improve from 0.56236\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6936 - accuracy: 0.5393 - precision: 0.5393 - recall: 0.5393 - mcc: 0.0795 - f1-score: 0.5387 - auc: 0.5475 - prc: 0.5392 - val_loss: 0.6993 - val_accuracy: 0.5074 - val_precision: 0.5074 - val_recall: 0.5074 - val_mcc: -0.0306 - val_f1-score: 0.3390 - val_auc: 0.5168 - val_prc: 0.5158 - lr: 0.0010\n",
            "Epoch 18/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - mcc: 0.0203 - f1-score: 0.5087 - auc: 0.5178 - prc: 0.5132\n",
            "Epoch 00018: val_accuracy did not improve from 0.56236\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6955 - accuracy: 0.5106 - precision: 0.5106 - recall: 0.5106 - mcc: 0.0203 - f1-score: 0.5087 - auc: 0.5178 - prc: 0.5132 - val_loss: 0.6944 - val_accuracy: 0.5096 - val_precision: 0.5096 - val_recall: 0.5096 - val_mcc: 0.0020 - val_f1-score: 0.3471 - val_auc: 0.5157 - val_prc: 0.5121 - lr: 0.0010\n",
            "Epoch 19/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6837 - accuracy: 0.5650 - precision: 0.5650 - recall: 0.5650 - mcc: 0.1302 - f1-score: 0.5639 - auc: 0.5845 - prc: 0.5767\n",
            "Epoch 00019: val_accuracy improved from 0.56236 to 0.57130, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6837 - accuracy: 0.5650 - precision: 0.5650 - recall: 0.5650 - mcc: 0.1302 - f1-score: 0.5639 - auc: 0.5845 - prc: 0.5767 - val_loss: 0.6820 - val_accuracy: 0.5713 - val_precision: 0.5713 - val_recall: 0.5713 - val_mcc: 0.1705 - val_f1-score: 0.5495 - val_auc: 0.6118 - val_prc: 0.6045 - lr: 0.0010\n",
            "Epoch 20/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.5495 - precision: 0.5495 - recall: 0.5495 - mcc: 0.1016 - f1-score: 0.5414 - auc: 0.5694 - prc: 0.5648\n",
            "Epoch 00020: val_accuracy did not improve from 0.57130\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6916 - accuracy: 0.5495 - precision: 0.5495 - recall: 0.5495 - mcc: 0.1016 - f1-score: 0.5414 - auc: 0.5694 - prc: 0.5648 - val_loss: 0.6834 - val_accuracy: 0.5628 - val_precision: 0.5628 - val_recall: 0.5628 - val_mcc: 0.1511 - val_f1-score: 0.5409 - val_auc: 0.5769 - val_prc: 0.5804 - lr: 0.0010\n",
            "Epoch 21/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6892 - accuracy: 0.5419 - precision: 0.5419 - recall: 0.5419 - mcc: 0.0880 - f1-score: 0.5256 - auc: 0.5599 - prc: 0.5597\n",
            "Epoch 00021: val_accuracy did not improve from 0.57130\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6892 - accuracy: 0.5419 - precision: 0.5419 - recall: 0.5419 - mcc: 0.0880 - f1-score: 0.5256 - auc: 0.5599 - prc: 0.5597 - val_loss: 0.6963 - val_accuracy: 0.5096 - val_precision: 0.5096 - val_recall: 0.5096 - val_mcc: 0.0000e+00 - val_f1-score: 0.3376 - val_auc: 0.5352 - val_prc: 0.5374 - lr: 0.0010\n",
            "Epoch 22/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6788 - accuracy: 0.5712 - precision: 0.5712 - recall: 0.5712 - mcc: 0.1431 - f1-score: 0.5689 - auc: 0.5957 - prc: 0.5928\n",
            "Epoch 00022: val_accuracy improved from 0.57130 to 0.58382, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6788 - accuracy: 0.5712 - precision: 0.5712 - recall: 0.5712 - mcc: 0.1431 - f1-score: 0.5689 - auc: 0.5957 - prc: 0.5928 - val_loss: 0.6685 - val_accuracy: 0.5838 - val_precision: 0.5838 - val_recall: 0.5838 - val_mcc: 0.2303 - val_f1-score: 0.5417 - val_auc: 0.6230 - val_prc: 0.6223 - lr: 0.0010\n",
            "Epoch 23/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6700 - accuracy: 0.5868 - precision: 0.5868 - recall: 0.5868 - mcc: 0.2041 - f1-score: 0.5535 - auc: 0.6187 - prc: 0.6148\n",
            "Epoch 00023: val_accuracy did not improve from 0.58382\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6700 - accuracy: 0.5868 - precision: 0.5868 - recall: 0.5868 - mcc: 0.2041 - f1-score: 0.5535 - auc: 0.6187 - prc: 0.6148 - val_loss: 0.6724 - val_accuracy: 0.5624 - val_precision: 0.5624 - val_recall: 0.5624 - val_mcc: 0.1998 - val_f1-score: 0.5011 - val_auc: 0.6149 - val_prc: 0.6188 - lr: 0.0010\n",
            "Epoch 24/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6797 - accuracy: 0.5704 - precision: 0.5704 - recall: 0.5704 - mcc: 0.1584 - f1-score: 0.5438 - auc: 0.6045 - prc: 0.5956\n",
            "Epoch 00024: val_accuracy improved from 0.58382 to 0.59678, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6797 - accuracy: 0.5704 - precision: 0.5704 - recall: 0.5704 - mcc: 0.1584 - f1-score: 0.5438 - auc: 0.6045 - prc: 0.5956 - val_loss: 0.6595 - val_accuracy: 0.5968 - val_precision: 0.5968 - val_recall: 0.5968 - val_mcc: 0.2333 - val_f1-score: 0.5729 - val_auc: 0.6528 - val_prc: 0.6491 - lr: 0.0010\n",
            "Epoch 25/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.6041 - precision: 0.6041 - recall: 0.6041 - mcc: 0.2360 - f1-score: 0.5750 - auc: 0.6491 - prc: 0.6491\n",
            "Epoch 00025: val_accuracy did not improve from 0.59678\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6543 - accuracy: 0.6041 - precision: 0.6041 - recall: 0.6041 - mcc: 0.2360 - f1-score: 0.5750 - auc: 0.6491 - prc: 0.6491 - val_loss: 0.6580 - val_accuracy: 0.5771 - val_precision: 0.5771 - val_recall: 0.5771 - val_mcc: 0.2433 - val_f1-score: 0.5174 - val_auc: 0.6419 - val_prc: 0.6468 - lr: 0.0010\n",
            "Epoch 26/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6454 - accuracy: 0.6089 - precision: 0.6089 - recall: 0.6089 - mcc: 0.2700 - f1-score: 0.5702 - auc: 0.6633 - prc: 0.6640\n",
            "Epoch 00026: val_accuracy improved from 0.59678 to 0.62494, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.6454 - accuracy: 0.6089 - precision: 0.6089 - recall: 0.6089 - mcc: 0.2700 - f1-score: 0.5702 - auc: 0.6633 - prc: 0.6640 - val_loss: 0.6260 - val_accuracy: 0.6249 - val_precision: 0.6249 - val_recall: 0.6249 - val_mcc: 0.2944 - val_f1-score: 0.6044 - val_auc: 0.6987 - val_prc: 0.7025 - lr: 0.0010\n",
            "Epoch 27/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6172 - accuracy: 0.6495 - precision: 0.6495 - recall: 0.6495 - mcc: 0.3299 - f1-score: 0.6311 - auc: 0.7105 - prc: 0.7101\n",
            "Epoch 00027: val_accuracy improved from 0.62494 to 0.65847, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6172 - accuracy: 0.6495 - precision: 0.6495 - recall: 0.6495 - mcc: 0.3299 - f1-score: 0.6311 - auc: 0.7105 - prc: 0.7101 - val_loss: 0.6278 - val_accuracy: 0.6585 - val_precision: 0.6585 - val_recall: 0.6585 - val_mcc: 0.3186 - val_f1-score: 0.6583 - val_auc: 0.7094 - val_prc: 0.7031 - lr: 0.0010\n",
            "Epoch 28/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5909 - accuracy: 0.6755 - precision: 0.6755 - recall: 0.6755 - mcc: 0.3737 - f1-score: 0.6665 - auc: 0.7463 - prc: 0.7469\n",
            "Epoch 00028: val_accuracy improved from 0.65847 to 0.71122, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.5909 - accuracy: 0.6755 - precision: 0.6755 - recall: 0.6755 - mcc: 0.3737 - f1-score: 0.6665 - auc: 0.7463 - prc: 0.7469 - val_loss: 0.5699 - val_accuracy: 0.7112 - val_precision: 0.7112 - val_recall: 0.7112 - val_mcc: 0.4419 - val_f1-score: 0.7072 - val_auc: 0.7771 - val_prc: 0.7743 - lr: 0.0010\n",
            "Epoch 29/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.7331 - precision: 0.7331 - recall: 0.7331 - mcc: 0.4751 - f1-score: 0.7297 - auc: 0.8118 - prc: 0.8107\n",
            "Epoch 00029: val_accuracy improved from 0.71122 to 0.76218, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.5303 - accuracy: 0.7331 - precision: 0.7331 - recall: 0.7331 - mcc: 0.4751 - f1-score: 0.7297 - auc: 0.8118 - prc: 0.8107 - val_loss: 0.4999 - val_accuracy: 0.7622 - val_precision: 0.7622 - val_recall: 0.7622 - val_mcc: 0.5264 - val_f1-score: 0.7621 - val_auc: 0.8402 - val_prc: 0.8370 - lr: 0.0010\n",
            "Epoch 30/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8106 - precision: 0.8106 - recall: 0.8106 - mcc: 0.6225 - f1-score: 0.8103 - auc: 0.8924 - prc: 0.8916\n",
            "Epoch 00030: val_accuracy improved from 0.76218 to 0.81582, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.4173 - accuracy: 0.8106 - precision: 0.8106 - recall: 0.8106 - mcc: 0.6225 - f1-score: 0.8103 - auc: 0.8924 - prc: 0.8916 - val_loss: 0.4311 - val_accuracy: 0.8158 - val_precision: 0.8158 - val_recall: 0.8158 - val_mcc: 0.6315 - val_f1-score: 0.8157 - val_auc: 0.8920 - val_prc: 0.8849 - lr: 0.0010\n",
            "Epoch 31/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.3087 - accuracy: 0.8678 - precision: 0.8678 - recall: 0.8678 - mcc: 0.7356 - f1-score: 0.8678 - auc: 0.9437 - prc: 0.9434\n",
            "Epoch 00031: val_accuracy improved from 0.81582 to 0.89316, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.3087 - accuracy: 0.8678 - precision: 0.8678 - recall: 0.8678 - mcc: 0.7356 - f1-score: 0.8678 - auc: 0.9437 - prc: 0.9434 - val_loss: 0.2734 - val_accuracy: 0.8932 - val_precision: 0.8932 - val_recall: 0.8932 - val_mcc: 0.7863 - val_f1-score: 0.8931 - val_auc: 0.9583 - val_prc: 0.9557 - lr: 0.0010\n",
            "Epoch 32/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.9195 - precision: 0.9195 - recall: 0.9195 - mcc: 0.8397 - f1-score: 0.9195 - auc: 0.9760 - prc: 0.9752\n",
            "Epoch 00032: val_accuracy improved from 0.89316 to 0.89808, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.2039 - accuracy: 0.9195 - precision: 0.9195 - recall: 0.9195 - mcc: 0.8397 - f1-score: 0.9195 - auc: 0.9760 - prc: 0.9752 - val_loss: 0.2786 - val_accuracy: 0.8981 - val_precision: 0.8981 - val_recall: 0.8981 - val_mcc: 0.7977 - val_f1-score: 0.8981 - val_auc: 0.9646 - val_prc: 0.9607 - lr: 0.0010\n",
            "Epoch 33/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9331 - precision: 0.9331 - recall: 0.9331 - mcc: 0.8664 - f1-score: 0.9331 - auc: 0.9863 - prc: 0.9858\n",
            "Epoch 00033: val_accuracy improved from 0.89808 to 0.92803, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.1513 - accuracy: 0.9331 - precision: 0.9331 - recall: 0.9331 - mcc: 0.8664 - f1-score: 0.9331 - auc: 0.9863 - prc: 0.9858 - val_loss: 0.1821 - val_accuracy: 0.9280 - val_precision: 0.9280 - val_recall: 0.9280 - val_mcc: 0.8561 - val_f1-score: 0.9280 - val_auc: 0.9811 - val_prc: 0.9796 - lr: 0.0010\n",
            "Epoch 34/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - mcc: 0.8952 - f1-score: 0.9476 - auc: 0.9911 - prc: 0.9908\n",
            "Epoch 00034: val_accuracy improved from 0.92803 to 0.94636, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.1224 - accuracy: 0.9476 - precision: 0.9476 - recall: 0.9476 - mcc: 0.8952 - f1-score: 0.9476 - auc: 0.9911 - prc: 0.9908 - val_loss: 0.1302 - val_accuracy: 0.9464 - val_precision: 0.9464 - val_recall: 0.9464 - val_mcc: 0.8927 - val_f1-score: 0.9463 - val_auc: 0.9887 - val_prc: 0.9873 - lr: 0.0010\n",
            "Epoch 35/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1248 - accuracy: 0.9443 - precision: 0.9443 - recall: 0.9443 - mcc: 0.8886 - f1-score: 0.9443 - auc: 0.9903 - prc: 0.9900\n",
            "Epoch 00035: val_accuracy did not improve from 0.94636\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.1248 - accuracy: 0.9443 - precision: 0.9443 - recall: 0.9443 - mcc: 0.8886 - f1-score: 0.9443 - auc: 0.9903 - prc: 0.9900 - val_loss: 0.1402 - val_accuracy: 0.9423 - val_precision: 0.9423 - val_recall: 0.9423 - val_mcc: 0.8850 - val_f1-score: 0.9423 - val_auc: 0.9891 - val_prc: 0.9891 - lr: 0.0010\n",
            "Epoch 36/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.9550 - precision: 0.9550 - recall: 0.9550 - mcc: 0.9101 - f1-score: 0.9550 - auc: 0.9938 - prc: 0.9937\n",
            "Epoch 00036: val_accuracy improved from 0.94636 to 0.95262, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.1017 - accuracy: 0.9550 - precision: 0.9550 - recall: 0.9550 - mcc: 0.9101 - f1-score: 0.9550 - auc: 0.9938 - prc: 0.9937 - val_loss: 0.1058 - val_accuracy: 0.9526 - val_precision: 0.9526 - val_recall: 0.9526 - val_mcc: 0.9052 - val_f1-score: 0.9526 - val_auc: 0.9940 - val_prc: 0.9940 - lr: 0.0010\n",
            "Epoch 37/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.9623 - precision: 0.9623 - recall: 0.9623 - mcc: 0.9246 - f1-score: 0.9623 - auc: 0.9956 - prc: 0.9955\n",
            "Epoch 00037: val_accuracy improved from 0.95262 to 0.95530, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0859 - accuracy: 0.9623 - precision: 0.9623 - recall: 0.9623 - mcc: 0.9246 - f1-score: 0.9623 - auc: 0.9956 - prc: 0.9955 - val_loss: 0.1076 - val_accuracy: 0.9553 - val_precision: 0.9553 - val_recall: 0.9553 - val_mcc: 0.9106 - val_f1-score: 0.9553 - val_auc: 0.9930 - val_prc: 0.9927 - lr: 0.0010\n",
            "Epoch 38/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9673 - precision: 0.9673 - recall: 0.9673 - mcc: 0.9345 - f1-score: 0.9673 - auc: 0.9968 - prc: 0.9968\n",
            "Epoch 00038: val_accuracy improved from 0.95530 to 0.96647, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0738 - accuracy: 0.9673 - precision: 0.9673 - recall: 0.9673 - mcc: 0.9345 - f1-score: 0.9673 - auc: 0.9968 - prc: 0.9968 - val_loss: 0.0761 - val_accuracy: 0.9665 - val_precision: 0.9665 - val_recall: 0.9665 - val_mcc: 0.9330 - val_f1-score: 0.9665 - val_auc: 0.9965 - val_prc: 0.9964 - lr: 0.0010\n",
            "Epoch 39/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9758 - precision: 0.9758 - recall: 0.9758 - mcc: 0.9515 - f1-score: 0.9758 - auc: 0.9980 - prc: 0.9981\n",
            "Epoch 00039: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.0595 - accuracy: 0.9758 - precision: 0.9758 - recall: 0.9758 - mcc: 0.9515 - f1-score: 0.9758 - auc: 0.9980 - prc: 0.9981 - val_loss: 0.1036 - val_accuracy: 0.9557 - val_precision: 0.9557 - val_recall: 0.9557 - val_mcc: 0.9118 - val_f1-score: 0.9557 - val_auc: 0.9935 - val_prc: 0.9928 - lr: 0.0010\n",
            "Epoch 40/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - mcc: 0.9574 - f1-score: 0.9787 - auc: 0.9984 - prc: 0.9984\n",
            "Epoch 00040: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0539 - accuracy: 0.9787 - precision: 0.9787 - recall: 0.9787 - mcc: 0.9574 - f1-score: 0.9787 - auc: 0.9984 - prc: 0.9984 - val_loss: 0.1058 - val_accuracy: 0.9544 - val_precision: 0.9544 - val_recall: 0.9544 - val_mcc: 0.9090 - val_f1-score: 0.9544 - val_auc: 0.9934 - val_prc: 0.9929 - lr: 0.0010\n",
            "Epoch 41/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9691 - precision: 0.9691 - recall: 0.9691 - mcc: 0.9382 - f1-score: 0.9691 - auc: 0.9961 - prc: 0.9959\n",
            "Epoch 00041: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.0787 - accuracy: 0.9691 - precision: 0.9691 - recall: 0.9691 - mcc: 0.9382 - f1-score: 0.9691 - auc: 0.9961 - prc: 0.9959 - val_loss: 0.1242 - val_accuracy: 0.9464 - val_precision: 0.9464 - val_recall: 0.9464 - val_mcc: 0.8927 - val_f1-score: 0.9463 - val_auc: 0.9911 - val_prc: 0.9914 - lr: 0.0010\n",
            "Epoch 42/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0791 - accuracy: 0.9680 - precision: 0.9680 - recall: 0.9680 - mcc: 0.9359 - f1-score: 0.9680 - auc: 0.9964 - prc: 0.9963\n",
            "Epoch 00042: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0791 - accuracy: 0.9680 - precision: 0.9680 - recall: 0.9680 - mcc: 0.9359 - f1-score: 0.9680 - auc: 0.9964 - prc: 0.9963 - val_loss: 0.1596 - val_accuracy: 0.9473 - val_precision: 0.9473 - val_recall: 0.9473 - val_mcc: 0.8945 - val_f1-score: 0.9472 - val_auc: 0.9856 - val_prc: 0.9836 - lr: 0.0010\n",
            "Epoch 43/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9731 - precision: 0.9731 - recall: 0.9731 - mcc: 0.9461 - f1-score: 0.9731 - auc: 0.9972 - prc: 0.9971\n",
            "Epoch 00043: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0674 - accuracy: 0.9731 - precision: 0.9731 - recall: 0.9731 - mcc: 0.9461 - f1-score: 0.9731 - auc: 0.9972 - prc: 0.9971 - val_loss: 0.1165 - val_accuracy: 0.9602 - val_precision: 0.9602 - val_recall: 0.9602 - val_mcc: 0.9204 - val_f1-score: 0.9602 - val_auc: 0.9926 - val_prc: 0.9919 - lr: 0.0010\n",
            "Epoch 44/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9827 - precision: 0.9827 - recall: 0.9827 - mcc: 0.9654 - f1-score: 0.9827 - auc: 0.9989 - prc: 0.9988\n",
            "Epoch 00044: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0444 - accuracy: 0.9827 - precision: 0.9827 - recall: 0.9827 - mcc: 0.9654 - f1-score: 0.9827 - auc: 0.9989 - prc: 0.9988 - val_loss: 0.0927 - val_accuracy: 0.9656 - val_precision: 0.9656 - val_recall: 0.9656 - val_mcc: 0.9312 - val_f1-score: 0.9656 - val_auc: 0.9954 - val_prc: 0.9948 - lr: 0.0010\n",
            "Epoch 45/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.9815 - precision: 0.9815 - recall: 0.9815 - mcc: 0.9631 - f1-score: 0.9815 - auc: 0.9974 - prc: 0.9970\n",
            "Epoch 00045: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0557 - accuracy: 0.9815 - precision: 0.9815 - recall: 0.9815 - mcc: 0.9631 - f1-score: 0.9815 - auc: 0.9974 - prc: 0.9970 - val_loss: 0.1022 - val_accuracy: 0.9589 - val_precision: 0.9589 - val_recall: 0.9589 - val_mcc: 0.9182 - val_f1-score: 0.9589 - val_auc: 0.9948 - val_prc: 0.9946 - lr: 0.0010\n",
            "Epoch 46/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9852 - precision: 0.9852 - recall: 0.9852 - mcc: 0.9704 - f1-score: 0.9852 - auc: 0.9992 - prc: 0.9992\n",
            "Epoch 00046: val_accuracy did not improve from 0.96647\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0388 - accuracy: 0.9852 - precision: 0.9852 - recall: 0.9852 - mcc: 0.9704 - f1-score: 0.9852 - auc: 0.9992 - prc: 0.9992 - val_loss: 0.1149 - val_accuracy: 0.9624 - val_precision: 0.9624 - val_recall: 0.9624 - val_mcc: 0.9250 - val_f1-score: 0.9624 - val_auc: 0.9931 - val_prc: 0.9919 - lr: 0.0010\n",
            "Epoch 47/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0621 - accuracy: 0.9804 - precision: 0.9804 - recall: 0.9804 - mcc: 0.9608 - f1-score: 0.9804 - auc: 0.9970 - prc: 0.9965\n",
            "Epoch 00047: val_accuracy improved from 0.96647 to 0.96692, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0621 - accuracy: 0.9804 - precision: 0.9804 - recall: 0.9804 - mcc: 0.9608 - f1-score: 0.9804 - auc: 0.9970 - prc: 0.9965 - val_loss: 0.1013 - val_accuracy: 0.9669 - val_precision: 0.9669 - val_recall: 0.9669 - val_mcc: 0.9339 - val_f1-score: 0.9669 - val_auc: 0.9946 - val_prc: 0.9939 - lr: 0.0010\n",
            "Epoch 48/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - mcc: 0.9724 - f1-score: 0.9862 - auc: 0.9986 - prc: 0.9984\n",
            "Epoch 00048: val_accuracy did not improve from 0.96692\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0405 - accuracy: 0.9862 - precision: 0.9862 - recall: 0.9862 - mcc: 0.9724 - f1-score: 0.9862 - auc: 0.9986 - prc: 0.9984 - val_loss: 0.0895 - val_accuracy: 0.9665 - val_precision: 0.9665 - val_recall: 0.9665 - val_mcc: 0.9329 - val_f1-score: 0.9665 - val_auc: 0.9959 - val_prc: 0.9956 - lr: 0.0010\n",
            "Epoch 49/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9829 - precision: 0.9829 - recall: 0.9829 - mcc: 0.9658 - f1-score: 0.9829 - auc: 0.9985 - prc: 0.9984\n",
            "Epoch 00049: val_accuracy did not improve from 0.96692\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0486 - accuracy: 0.9829 - precision: 0.9829 - recall: 0.9829 - mcc: 0.9658 - f1-score: 0.9829 - auc: 0.9985 - prc: 0.9984 - val_loss: 0.1060 - val_accuracy: 0.9638 - val_precision: 0.9638 - val_recall: 0.9638 - val_mcc: 0.9283 - val_f1-score: 0.9638 - val_auc: 0.9940 - val_prc: 0.9931 - lr: 0.0010\n",
            "Epoch 50/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9883 - precision: 0.9883 - recall: 0.9883 - mcc: 0.9767 - f1-score: 0.9883 - auc: 0.9994 - prc: 0.9993\n",
            "Epoch 00050: val_accuracy improved from 0.96692 to 0.97005, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0318 - accuracy: 0.9883 - precision: 0.9883 - recall: 0.9883 - mcc: 0.9767 - f1-score: 0.9883 - auc: 0.9994 - prc: 0.9993 - val_loss: 0.0873 - val_accuracy: 0.9700 - val_precision: 0.9700 - val_recall: 0.9700 - val_mcc: 0.9402 - val_f1-score: 0.9700 - val_auc: 0.9951 - val_prc: 0.9942 - lr: 0.0010\n",
            "Epoch 51/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - mcc: 0.9692 - f1-score: 0.9846 - auc: 0.9980 - prc: 0.9977\n",
            "Epoch 00051: val_accuracy did not improve from 0.97005\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.0460 - accuracy: 0.9846 - precision: 0.9846 - recall: 0.9846 - mcc: 0.9692 - f1-score: 0.9846 - auc: 0.9980 - prc: 0.9977 - val_loss: 0.1069 - val_accuracy: 0.9616 - val_precision: 0.9616 - val_recall: 0.9616 - val_mcc: 0.9234 - val_f1-score: 0.9616 - val_auc: 0.9942 - val_prc: 0.9936 - lr: 0.0010\n",
            "Epoch 52/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9884 - auc: 0.9996 - prc: 0.9996\n",
            "Epoch 00052: val_accuracy improved from 0.97005 to 0.97184, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.0296 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9884 - auc: 0.9996 - prc: 0.9996 - val_loss: 0.0949 - val_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_mcc: 0.9437 - val_f1-score: 0.9718 - val_auc: 0.9940 - val_prc: 0.9927 - lr: 0.0010\n",
            "Epoch 53/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - mcc: 0.9651 - f1-score: 0.9826 - auc: 0.9979 - prc: 0.9977\n",
            "Epoch 00053: val_accuracy did not improve from 0.97184\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0526 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - mcc: 0.9651 - f1-score: 0.9826 - auc: 0.9979 - prc: 0.9977 - val_loss: 0.1131 - val_accuracy: 0.9589 - val_precision: 0.9589 - val_recall: 0.9589 - val_mcc: 0.9186 - val_f1-score: 0.9589 - val_auc: 0.9917 - val_prc: 0.9911 - lr: 0.0010\n",
            "Epoch 54/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 0.9822 - precision: 0.9822 - recall: 0.9822 - mcc: 0.9645 - f1-score: 0.9822 - auc: 0.9979 - prc: 0.9976\n",
            "Epoch 00054: val_accuracy did not improve from 0.97184\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.0521 - accuracy: 0.9822 - precision: 0.9822 - recall: 0.9822 - mcc: 0.9645 - f1-score: 0.9822 - auc: 0.9979 - prc: 0.9976 - val_loss: 0.1532 - val_accuracy: 0.9450 - val_precision: 0.9450 - val_recall: 0.9450 - val_mcc: 0.8901 - val_f1-score: 0.9450 - val_auc: 0.9876 - val_prc: 0.9878 - lr: 0.0010\n",
            "Epoch 55/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - mcc: 0.9649 - f1-score: 0.9824 - auc: 0.9984 - prc: 0.9983\n",
            "Epoch 00055: val_accuracy did not improve from 0.97184\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.0487 - accuracy: 0.9825 - precision: 0.9825 - recall: 0.9825 - mcc: 0.9649 - f1-score: 0.9824 - auc: 0.9984 - prc: 0.9983 - val_loss: 0.0901 - val_accuracy: 0.9692 - val_precision: 0.9692 - val_recall: 0.9692 - val_mcc: 0.9383 - val_f1-score: 0.9691 - val_auc: 0.9952 - val_prc: 0.9946 - lr: 0.0010\n",
            "Epoch 56/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9922 - precision: 0.9922 - recall: 0.9922 - mcc: 0.9844 - f1-score: 0.9922 - auc: 0.9994 - prc: 0.9993\n",
            "Epoch 00056: val_accuracy did not improve from 0.97184\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.0245 - accuracy: 0.9922 - precision: 0.9922 - recall: 0.9922 - mcc: 0.9844 - f1-score: 0.9922 - auc: 0.9994 - prc: 0.9993 - val_loss: 0.1063 - val_accuracy: 0.9692 - val_precision: 0.9692 - val_recall: 0.9692 - val_mcc: 0.9388 - val_f1-score: 0.9692 - val_auc: 0.9929 - val_prc: 0.9914 - lr: 0.0010\n",
            "Epoch 57/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947 - precision: 0.9947 - recall: 0.9947 - mcc: 0.9894 - f1-score: 0.9947 - auc: 0.9996 - prc: 0.9996\n",
            "Epoch 00057: val_accuracy improved from 0.97184 to 0.97228, saving model to my_best_model_3.hdf5\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.0176 - accuracy: 0.9947 - precision: 0.9947 - recall: 0.9947 - mcc: 0.9894 - f1-score: 0.9947 - auc: 0.9996 - prc: 0.9996 - val_loss: 0.1064 - val_accuracy: 0.9723 - val_precision: 0.9723 - val_recall: 0.9723 - val_mcc: 0.9447 - val_f1-score: 0.9723 - val_auc: 0.9934 - val_prc: 0.9918 - lr: 0.0010\n",
            "Epoch 58/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9939 - precision: 0.9939 - recall: 0.9939 - mcc: 0.9878 - f1-score: 0.9939 - auc: 0.9999 - prc: 0.9999\n",
            "Epoch 00058: val_accuracy did not improve from 0.97228\n",
            "Restoring model weights from the end of the best epoch: 38.\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0173 - accuracy: 0.9939 - precision: 0.9939 - recall: 0.9939 - mcc: 0.9878 - f1-score: 0.9939 - auc: 0.9999 - prc: 0.9999 - val_loss: 0.1003 - val_accuracy: 0.9714 - val_precision: 0.9714 - val_recall: 0.9714 - val_mcc: 0.9430 - val_f1-score: 0.9714 - val_auc: 0.9931 - val_prc: 0.9914 - lr: 0.0010\n",
            "Epoch 00058: early stopping\n",
            "==================End training 3========================\n",
            "accuracy: 0.9626098614628333, precision: 0.9658170914542729, recall: 0.9592019058963669, specificity: 0.9594434576672587, mcc: 0.9252416595068892 ,f1-score: 0.9624981323771105\n",
            "==================== Training time  4 =====================\n",
            "Epoch 1/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 2.0528 - accuracy: 0.6006 - precision: 0.6006 - recall: 0.6006 - mcc: 0.2016 - f1-score: 0.5998 - auc: 0.6750 - prc: 0.7032\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.49307, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 54s 369ms/step - loss: 2.0528 - accuracy: 0.6006 - precision: 0.6006 - recall: 0.6006 - mcc: 0.2016 - f1-score: 0.5998 - auc: 0.6750 - prc: 0.7032 - val_loss: 1.5285 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.4888 - val_prc: 0.4883 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 1.2433 - accuracy: 0.5052 - precision: 0.5052 - recall: 0.5052 - mcc: 0.0097 - f1-score: 0.5019 - auc: 0.5071 - prc: 0.5063\n",
            "Epoch 00002: val_accuracy improved from 0.49307 to 0.51095, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 1.2433 - accuracy: 0.5052 - precision: 0.5052 - recall: 0.5052 - mcc: 0.0097 - f1-score: 0.5019 - auc: 0.5071 - prc: 0.5063 - val_loss: 1.0231 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_mcc: 0.0386 - val_f1-score: 0.4623 - val_auc: 0.5111 - val_prc: 0.5080 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.9091 - accuracy: 0.5121 - precision: 0.5121 - recall: 0.5121 - mcc: 0.0239 - f1-score: 0.5110 - auc: 0.5128 - prc: 0.5104\n",
            "Epoch 00003: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.9091 - accuracy: 0.5121 - precision: 0.5121 - recall: 0.5121 - mcc: 0.0239 - f1-score: 0.5110 - auc: 0.5128 - prc: 0.5104 - val_loss: 0.8254 - val_accuracy: 0.4940 - val_precision: 0.4940 - val_recall: 0.4940 - val_mcc: 0.0295 - val_f1-score: 0.3322 - val_auc: 0.5044 - val_prc: 0.5052 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7804 - accuracy: 0.5139 - precision: 0.5139 - recall: 0.5139 - mcc: 0.0275 - f1-score: 0.5119 - auc: 0.5197 - prc: 0.5161\n",
            "Epoch 00004: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.7804 - accuracy: 0.5139 - precision: 0.5139 - recall: 0.5139 - mcc: 0.0275 - f1-score: 0.5119 - auc: 0.5197 - prc: 0.5161 - val_loss: 0.7493 - val_accuracy: 0.5002 - val_precision: 0.5002 - val_recall: 0.5002 - val_mcc: 0.0309 - val_f1-score: 0.3757 - val_auc: 0.5072 - val_prc: 0.5070 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7329 - accuracy: 0.5086 - precision: 0.5086 - recall: 0.5086 - mcc: 0.0177 - f1-score: 0.5066 - auc: 0.5130 - prc: 0.5088\n",
            "Epoch 00005: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.7329 - accuracy: 0.5086 - precision: 0.5086 - recall: 0.5086 - mcc: 0.0177 - f1-score: 0.5066 - auc: 0.5130 - prc: 0.5088 - val_loss: 0.7214 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: -5.8657e-04 - val_f1-score: 0.3318 - val_auc: 0.5078 - val_prc: 0.5088 - lr: 0.0010\n",
            "Epoch 6/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7140 - accuracy: 0.5097 - precision: 0.5097 - recall: 0.5097 - mcc: 0.0197 - f1-score: 0.5087 - auc: 0.5118 - prc: 0.5090\n",
            "Epoch 00006: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.7140 - accuracy: 0.5097 - precision: 0.5097 - recall: 0.5097 - mcc: 0.0197 - f1-score: 0.5087 - auc: 0.5118 - prc: 0.5090 - val_loss: 0.7115 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.4986 - val_prc: 0.5014 - lr: 0.0010\n",
            "Epoch 7/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.5063 - precision: 0.5063 - recall: 0.5063 - mcc: 0.0112 - f1-score: 0.4959 - auc: 0.5110 - prc: 0.5099\n",
            "Epoch 00007: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.7061 - accuracy: 0.5063 - precision: 0.5063 - recall: 0.5063 - mcc: 0.0112 - f1-score: 0.4959 - auc: 0.5110 - prc: 0.5099 - val_loss: 0.7032 - val_accuracy: 0.5038 - val_precision: 0.5038 - val_recall: 0.5038 - val_mcc: 0.0306 - val_f1-score: 0.4147 - val_auc: 0.5063 - val_prc: 0.5071 - lr: 0.0010\n",
            "Epoch 8/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7019 - accuracy: 0.5027 - precision: 0.5027 - recall: 0.5027 - mcc: 0.0054 - f1-score: 0.4986 - auc: 0.5020 - prc: 0.5013\n",
            "Epoch 00008: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.7019 - accuracy: 0.5027 - precision: 0.5027 - recall: 0.5027 - mcc: 0.0054 - f1-score: 0.4986 - auc: 0.5020 - prc: 0.5013 - val_loss: 0.7013 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.5094 - val_prc: 0.5095 - lr: 0.0010\n",
            "Epoch 9/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6989 - accuracy: 0.5087 - precision: 0.5087 - recall: 0.5087 - mcc: 0.0162 - f1-score: 0.5010 - auc: 0.5096 - prc: 0.5073\n",
            "Epoch 00009: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6989 - accuracy: 0.5087 - precision: 0.5087 - recall: 0.5087 - mcc: 0.0162 - f1-score: 0.5010 - auc: 0.5096 - prc: 0.5073 - val_loss: 0.6996 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.5013 - val_prc: 0.5021 - lr: 0.0010\n",
            "Epoch 10/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6975 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0120 - f1-score: 0.5014 - auc: 0.5098 - prc: 0.5087\n",
            "Epoch 00010: val_accuracy did not improve from 0.51095\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6975 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0120 - f1-score: 0.5014 - auc: 0.5098 - prc: 0.5087 - val_loss: 0.6970 - val_accuracy: 0.4958 - val_precision: 0.4958 - val_recall: 0.4958 - val_mcc: 0.0114 - val_f1-score: 0.3637 - val_auc: 0.5128 - val_prc: 0.5111 - lr: 0.0010\n",
            "Epoch 11/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6964 - accuracy: 0.5096 - precision: 0.5096 - recall: 0.5096 - mcc: 0.0193 - f1-score: 0.5087 - auc: 0.5105 - prc: 0.5108\n",
            "Epoch 00011: val_accuracy improved from 0.51095 to 0.52526, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.6964 - accuracy: 0.5096 - precision: 0.5096 - recall: 0.5096 - mcc: 0.0193 - f1-score: 0.5087 - auc: 0.5105 - prc: 0.5108 - val_loss: 0.6956 - val_accuracy: 0.5253 - val_precision: 0.5253 - val_recall: 0.5253 - val_mcc: 0.0516 - val_f1-score: 0.5249 - val_auc: 0.5284 - val_prc: 0.5191 - lr: 0.0010\n",
            "Epoch 12/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6959 - accuracy: 0.5112 - precision: 0.5112 - recall: 0.5112 - mcc: 0.0220 - f1-score: 0.5104 - auc: 0.5144 - prc: 0.5112\n",
            "Epoch 00012: val_accuracy did not improve from 0.52526\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6959 - accuracy: 0.5112 - precision: 0.5112 - recall: 0.5112 - mcc: 0.0220 - f1-score: 0.5104 - auc: 0.5144 - prc: 0.5112 - val_loss: 0.6954 - val_accuracy: 0.5096 - val_precision: 0.5096 - val_recall: 0.5096 - val_mcc: 0.0362 - val_f1-score: 0.4574 - val_auc: 0.5172 - val_prc: 0.5121 - lr: 0.0010\n",
            "Epoch 13/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.5148 - precision: 0.5148 - recall: 0.5148 - mcc: 0.0297 - f1-score: 0.5132 - auc: 0.5242 - prc: 0.5199\n",
            "Epoch 00013: val_accuracy improved from 0.52526 to 0.53196, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6951 - accuracy: 0.5148 - precision: 0.5148 - recall: 0.5148 - mcc: 0.0297 - f1-score: 0.5132 - auc: 0.5242 - prc: 0.5199 - val_loss: 0.6941 - val_accuracy: 0.5320 - val_precision: 0.5320 - val_recall: 0.5320 - val_mcc: 0.0715 - val_f1-score: 0.5219 - val_auc: 0.5347 - val_prc: 0.5244 - lr: 0.0010\n",
            "Epoch 14/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5348 - precision: 0.5348 - recall: 0.5348 - mcc: 0.0694 - f1-score: 0.5335 - auc: 0.5423 - prc: 0.5312\n",
            "Epoch 00014: val_accuracy improved from 0.53196 to 0.53867, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.6936 - accuracy: 0.5348 - precision: 0.5348 - recall: 0.5348 - mcc: 0.0694 - f1-score: 0.5335 - auc: 0.5423 - prc: 0.5312 - val_loss: 0.6940 - val_accuracy: 0.5387 - val_precision: 0.5387 - val_recall: 0.5387 - val_mcc: 0.0776 - val_f1-score: 0.5387 - val_auc: 0.5529 - val_prc: 0.5448 - lr: 0.0010\n",
            "Epoch 15/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - mcc: 0.0476 - f1-score: 0.5237 - auc: 0.5325 - prc: 0.5237\n",
            "Epoch 00015: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6955 - accuracy: 0.5238 - precision: 0.5238 - recall: 0.5238 - mcc: 0.0476 - f1-score: 0.5237 - auc: 0.5325 - prc: 0.5237 - val_loss: 0.7004 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.4916 - val_prc: 0.4933 - lr: 0.0010\n",
            "Epoch 16/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6956 - accuracy: 0.5194 - precision: 0.5194 - recall: 0.5194 - mcc: 0.0382 - f1-score: 0.5117 - auc: 0.5185 - prc: 0.5109\n",
            "Epoch 00016: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6956 - accuracy: 0.5194 - precision: 0.5194 - recall: 0.5194 - mcc: 0.0382 - f1-score: 0.5117 - auc: 0.5185 - prc: 0.5109 - val_loss: 0.6962 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.5020 - val_prc: 0.5005 - lr: 0.0010\n",
            "Epoch 17/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6945 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - mcc: 0.0310 - f1-score: 0.5044 - auc: 0.5216 - prc: 0.5190\n",
            "Epoch 00017: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 271ms/step - loss: 0.6945 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - mcc: 0.0310 - f1-score: 0.5044 - auc: 0.5216 - prc: 0.5190 - val_loss: 0.6968 - val_accuracy: 0.4926 - val_precision: 0.4926 - val_recall: 0.4926 - val_mcc: -0.0101 - val_f1-score: 0.3316 - val_auc: 0.5078 - val_prc: 0.5073 - lr: 0.0010\n",
            "Epoch 18/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5043 - precision: 0.5043 - recall: 0.5043 - mcc: 0.0082 - f1-score: 0.5030 - auc: 0.5033 - prc: 0.5024\n",
            "Epoch 00018: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.6953 - accuracy: 0.5043 - precision: 0.5043 - recall: 0.5043 - mcc: 0.0082 - f1-score: 0.5030 - auc: 0.5033 - prc: 0.5024 - val_loss: 0.6946 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.5029 - val_prc: 0.5031 - lr: 0.0010\n",
            "Epoch 19/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5127 - precision: 0.5127 - recall: 0.5127 - mcc: 0.0260 - f1-score: 0.5026 - auc: 0.5189 - prc: 0.5121\n",
            "Epoch 00019: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6939 - accuracy: 0.5127 - precision: 0.5127 - recall: 0.5127 - mcc: 0.0260 - f1-score: 0.5026 - auc: 0.5189 - prc: 0.5121 - val_loss: 0.6938 - val_accuracy: 0.5150 - val_precision: 0.5150 - val_recall: 0.5150 - val_mcc: 0.0404 - val_f1-score: 0.4912 - val_auc: 0.5181 - val_prc: 0.5155 - lr: 0.0010\n",
            "Epoch 20/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6947 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - mcc: 0.0250 - f1-score: 0.4942 - auc: 0.5158 - prc: 0.5107\n",
            "Epoch 00020: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6947 - accuracy: 0.5125 - precision: 0.5125 - recall: 0.5125 - mcc: 0.0250 - f1-score: 0.4942 - auc: 0.5158 - prc: 0.5107 - val_loss: 0.6960 - val_accuracy: 0.4980 - val_precision: 0.4980 - val_recall: 0.4980 - val_mcc: 0.0302 - val_f1-score: 0.3561 - val_auc: 0.5007 - val_prc: 0.5012 - lr: 0.0010\n",
            "Epoch 21/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.5048 - precision: 0.5048 - recall: 0.5048 - mcc: 0.0100 - f1-score: 0.4932 - auc: 0.5042 - prc: 0.5004\n",
            "Epoch 00021: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6952 - accuracy: 0.5048 - precision: 0.5048 - recall: 0.5048 - mcc: 0.0100 - f1-score: 0.4932 - auc: 0.5042 - prc: 0.5004 - val_loss: 0.6939 - val_accuracy: 0.5029 - val_precision: 0.5029 - val_recall: 0.5029 - val_mcc: 0.0229 - val_f1-score: 0.4315 - val_auc: 0.5108 - val_prc: 0.5086 - lr: 0.0010\n",
            "Epoch 22/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5129 - precision: 0.5129 - recall: 0.5129 - mcc: 0.0259 - f1-score: 0.5114 - auc: 0.5180 - prc: 0.5128\n",
            "Epoch 00022: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6935 - accuracy: 0.5129 - precision: 0.5129 - recall: 0.5129 - mcc: 0.0259 - f1-score: 0.5114 - auc: 0.5180 - prc: 0.5128 - val_loss: 0.6929 - val_accuracy: 0.5150 - val_precision: 0.5150 - val_recall: 0.5150 - val_mcc: 0.0266 - val_f1-score: 0.4805 - val_auc: 0.5216 - val_prc: 0.5187 - lr: 0.0010\n",
            "Epoch 23/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6944 - accuracy: 0.5049 - precision: 0.5049 - recall: 0.5049 - mcc: 0.0111 - f1-score: 0.5033 - auc: 0.5043 - prc: 0.5017\n",
            "Epoch 00023: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6944 - accuracy: 0.5049 - precision: 0.5049 - recall: 0.5049 - mcc: 0.0111 - f1-score: 0.5033 - auc: 0.5043 - prc: 0.5017 - val_loss: 0.6943 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0000e+00 - val_f1-score: 0.3302 - val_auc: 0.4966 - val_prc: 0.4977 - lr: 0.0010\n",
            "Epoch 24/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6937 - accuracy: 0.5035 - precision: 0.5035 - recall: 0.5035 - mcc: 0.0073 - f1-score: 0.5002 - auc: 0.5029 - prc: 0.5026\n",
            "Epoch 00024: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6937 - accuracy: 0.5035 - precision: 0.5035 - recall: 0.5035 - mcc: 0.0073 - f1-score: 0.5002 - auc: 0.5029 - prc: 0.5026 - val_loss: 0.6935 - val_accuracy: 0.5016 - val_precision: 0.5016 - val_recall: 0.5016 - val_mcc: 0.0199 - val_f1-score: 0.4259 - val_auc: 0.5124 - val_prc: 0.5089 - lr: 0.0010\n",
            "Epoch 25/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5088 - precision: 0.5088 - recall: 0.5088 - mcc: 0.0188 - f1-score: 0.4999 - auc: 0.5099 - prc: 0.5062\n",
            "Epoch 00025: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6936 - accuracy: 0.5088 - precision: 0.5088 - recall: 0.5088 - mcc: 0.0188 - f1-score: 0.4999 - auc: 0.5099 - prc: 0.5062 - val_loss: 0.6935 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5185 - val_prc: 0.5153 - lr: 0.0010\n",
            "Epoch 26/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5118 - precision: 0.5118 - recall: 0.5118 - mcc: 0.0235 - f1-score: 0.5118 - auc: 0.5089 - prc: 0.5049\n",
            "Epoch 00026: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6938 - accuracy: 0.5118 - precision: 0.5118 - recall: 0.5118 - mcc: 0.0235 - f1-score: 0.5118 - auc: 0.5089 - prc: 0.5049 - val_loss: 0.6933 - val_accuracy: 0.5083 - val_precision: 0.5083 - val_recall: 0.5083 - val_mcc: 0.0324 - val_f1-score: 0.4574 - val_auc: 0.5154 - val_prc: 0.5169 - lr: 0.0010\n",
            "Epoch 27/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0119 - f1-score: 0.4904 - auc: 0.5048 - prc: 0.5009\n",
            "Epoch 00027: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.6936 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0119 - f1-score: 0.4904 - auc: 0.5048 - prc: 0.5009 - val_loss: 0.6930 - val_accuracy: 0.5186 - val_precision: 0.5186 - val_recall: 0.5186 - val_mcc: 0.0392 - val_f1-score: 0.5169 - val_auc: 0.5303 - val_prc: 0.5222 - lr: 0.0010\n",
            "Epoch 28/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.5088 - precision: 0.5088 - recall: 0.5088 - mcc: 0.0176 - f1-score: 0.5074 - auc: 0.5125 - prc: 0.5069\n",
            "Epoch 00028: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6934 - accuracy: 0.5088 - precision: 0.5088 - recall: 0.5088 - mcc: 0.0176 - f1-score: 0.5074 - auc: 0.5125 - prc: 0.5069 - val_loss: 0.6930 - val_accuracy: 0.5105 - val_precision: 0.5105 - val_recall: 0.5105 - val_mcc: 0.0310 - val_f1-score: 0.3544 - val_auc: 0.5173 - val_prc: 0.5127 - lr: 0.0010\n",
            "Epoch 29/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.5043 - precision: 0.5043 - recall: 0.5043 - mcc: 0.0082 - f1-score: 0.5035 - auc: 0.5048 - prc: 0.5030\n",
            "Epoch 00029: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6939 - accuracy: 0.5043 - precision: 0.5043 - recall: 0.5043 - mcc: 0.0082 - f1-score: 0.5035 - auc: 0.5048 - prc: 0.5030 - val_loss: 0.6941 - val_accuracy: 0.5051 - val_precision: 0.5051 - val_recall: 0.5051 - val_mcc: -0.0023 - val_f1-score: 0.3968 - val_auc: 0.5098 - val_prc: 0.5014 - lr: 0.0010\n",
            "Epoch 30/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.5104 - precision: 0.5104 - recall: 0.5104 - mcc: 0.0205 - f1-score: 0.5097 - auc: 0.5103 - prc: 0.5089\n",
            "Epoch 00030: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 272ms/step - loss: 0.6950 - accuracy: 0.5104 - precision: 0.5104 - recall: 0.5104 - mcc: 0.0205 - f1-score: 0.5097 - auc: 0.5103 - prc: 0.5089 - val_loss: 0.6944 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5153 - val_prc: 0.5148 - lr: 0.0010\n",
            "Epoch 31/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.5038 - precision: 0.5038 - recall: 0.5038 - mcc: 0.0081 - f1-score: 0.4991 - auc: 0.5044 - prc: 0.5006\n",
            "Epoch 00031: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.6940 - accuracy: 0.5038 - precision: 0.5038 - recall: 0.5038 - mcc: 0.0081 - f1-score: 0.4991 - auc: 0.5044 - prc: 0.5006 - val_loss: 0.6934 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5069 - val_prc: 0.5048 - lr: 0.0010\n",
            "Epoch 32/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5055 - precision: 0.5055 - recall: 0.5055 - mcc: 0.0101 - f1-score: 0.4883 - auc: 0.4994 - prc: 0.4976\n",
            "Epoch 00032: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6935 - accuracy: 0.5055 - precision: 0.5055 - recall: 0.5055 - mcc: 0.0101 - f1-score: 0.4883 - auc: 0.4994 - prc: 0.4976 - val_loss: 0.6932 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5069 - val_prc: 0.5048 - lr: 0.0010\n",
            "Epoch 33/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5046 - precision: 0.5046 - recall: 0.5046 - mcc: 0.0096 - f1-score: 0.5025 - auc: 0.4979 - prc: 0.4982\n",
            "Epoch 00033: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6935 - accuracy: 0.5046 - precision: 0.5046 - recall: 0.5046 - mcc: 0.0096 - f1-score: 0.5025 - auc: 0.4979 - prc: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5152 - val_prc: 0.5129 - lr: 0.0010\n",
            "Epoch 34/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.4991 - precision: 0.4991 - recall: 0.4991 - mcc: -0.0021 - f1-score: 0.4987 - auc: 0.5042 - prc: 0.5016\n",
            "Epoch 00034: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6935 - accuracy: 0.4991 - precision: 0.4991 - recall: 0.4991 - mcc: -0.0021 - f1-score: 0.4987 - auc: 0.5042 - prc: 0.5016 - val_loss: 0.6932 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5070 - val_prc: 0.5049 - lr: 0.0010\n",
            "Epoch 35/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6936 - accuracy: 0.4981 - precision: 0.4981 - recall: 0.4981 - mcc: -0.0026 - f1-score: 0.4914 - auc: 0.4985 - prc: 0.4998    \n",
            "Epoch 00035: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6936 - accuracy: 0.4981 - precision: 0.4981 - recall: 0.4981 - mcc: -0.0026 - f1-score: 0.4914 - auc: 0.4985 - prc: 0.4998 - val_loss: 0.6931 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5206 - val_prc: 0.5174 - lr: 0.0010\n",
            "Epoch 36/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5115 - precision: 0.5115 - recall: 0.5115 - mcc: 0.0231 - f1-score: 0.5115 - auc: 0.5107 - prc: 0.5077\n",
            "Epoch 00036: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6933 - accuracy: 0.5115 - precision: 0.5115 - recall: 0.5115 - mcc: 0.0231 - f1-score: 0.5115 - auc: 0.5107 - prc: 0.5077 - val_loss: 0.6932 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5187 - val_prc: 0.5141 - lr: 0.0010\n",
            "Epoch 37/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6935 - accuracy: 0.5087 - precision: 0.5087 - recall: 0.5087 - mcc: 0.0169 - f1-score: 0.4951 - auc: 0.5062 - prc: 0.5043\n",
            "Epoch 00037: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6935 - accuracy: 0.5087 - precision: 0.5087 - recall: 0.5087 - mcc: 0.0169 - f1-score: 0.4951 - auc: 0.5062 - prc: 0.5043 - val_loss: 0.6935 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5169 - val_prc: 0.5144 - lr: 0.0010\n",
            "Epoch 38/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.5205 - precision: 0.5205 - recall: 0.5205 - mcc: 0.0409 - f1-score: 0.5202 - auc: 0.5223 - prc: 0.5165\n",
            "Epoch 00038: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6933 - accuracy: 0.5205 - precision: 0.5205 - recall: 0.5205 - mcc: 0.0409 - f1-score: 0.5202 - auc: 0.5223 - prc: 0.5165 - val_loss: 0.6960 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5194 - val_prc: 0.5177 - lr: 0.0010\n",
            "Epoch 39/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.5101 - precision: 0.5101 - recall: 0.5101 - mcc: 0.0200 - f1-score: 0.5087 - auc: 0.5121 - prc: 0.5076\n",
            "Epoch 00039: val_accuracy did not improve from 0.53867\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6942 - accuracy: 0.5101 - precision: 0.5101 - recall: 0.5101 - mcc: 0.0200 - f1-score: 0.5087 - auc: 0.5121 - prc: 0.5076 - val_loss: 0.6931 - val_accuracy: 0.5069 - val_precision: 0.5069 - val_recall: 0.5069 - val_mcc: 0.0000e+00 - val_f1-score: 0.3364 - val_auc: 0.5255 - val_prc: 0.5207 - lr: 0.0010\n",
            "Epoch 40/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5161 - precision: 0.5161 - recall: 0.5161 - mcc: 0.0311 - f1-score: 0.5095 - auc: 0.5182 - prc: 0.5142\n",
            "Epoch 00040: val_accuracy improved from 0.53867 to 0.53911, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6932 - accuracy: 0.5161 - precision: 0.5161 - recall: 0.5161 - mcc: 0.0311 - f1-score: 0.5095 - auc: 0.5182 - prc: 0.5142 - val_loss: 0.6919 - val_accuracy: 0.5391 - val_precision: 0.5391 - val_recall: 0.5391 - val_mcc: 0.0779 - val_f1-score: 0.5260 - val_auc: 0.5476 - val_prc: 0.5342 - lr: 0.0010\n",
            "Epoch 41/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6938 - accuracy: 0.5223 - precision: 0.5223 - recall: 0.5223 - mcc: 0.0465 - f1-score: 0.5181 - auc: 0.5276 - prc: 0.5216\n",
            "Epoch 00041: val_accuracy did not improve from 0.53911\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6938 - accuracy: 0.5223 - precision: 0.5223 - recall: 0.5223 - mcc: 0.0465 - f1-score: 0.5181 - auc: 0.5276 - prc: 0.5216 - val_loss: 0.6945 - val_accuracy: 0.5293 - val_precision: 0.5293 - val_recall: 0.5293 - val_mcc: 0.0626 - val_f1-score: 0.5252 - val_auc: 0.5415 - val_prc: 0.5351 - lr: 0.0010\n",
            "Epoch 42/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.5346 - precision: 0.5346 - recall: 0.5346 - mcc: 0.0696 - f1-score: 0.5325 - auc: 0.5528 - prc: 0.5443\n",
            "Epoch 00042: val_accuracy did not improve from 0.53911\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6914 - accuracy: 0.5346 - precision: 0.5346 - recall: 0.5346 - mcc: 0.0696 - f1-score: 0.5325 - auc: 0.5528 - prc: 0.5443 - val_loss: 0.7023 - val_accuracy: 0.5047 - val_precision: 0.5047 - val_recall: 0.5047 - val_mcc: -0.0139 - val_f1-score: 0.3509 - val_auc: 0.5247 - val_prc: 0.5244 - lr: 0.0010\n",
            "Epoch 43/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6946 - accuracy: 0.5197 - precision: 0.5197 - recall: 0.5197 - mcc: 0.0410 - f1-score: 0.5113 - auc: 0.5310 - prc: 0.5263\n",
            "Epoch 00043: val_accuracy improved from 0.53911 to 0.58024, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.6946 - accuracy: 0.5197 - precision: 0.5197 - recall: 0.5197 - mcc: 0.0410 - f1-score: 0.5113 - auc: 0.5310 - prc: 0.5263 - val_loss: 0.6824 - val_accuracy: 0.5802 - val_precision: 0.5802 - val_recall: 0.5802 - val_mcc: 0.1745 - val_f1-score: 0.5541 - val_auc: 0.5905 - val_prc: 0.5767 - lr: 0.0010\n",
            "Epoch 44/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.5688 - precision: 0.5688 - recall: 0.5688 - mcc: 0.1470 - f1-score: 0.5566 - auc: 0.6002 - prc: 0.5962\n",
            "Epoch 00044: val_accuracy did not improve from 0.58024\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6783 - accuracy: 0.5688 - precision: 0.5688 - recall: 0.5688 - mcc: 0.1470 - f1-score: 0.5566 - auc: 0.6002 - prc: 0.5962 - val_loss: 0.6982 - val_accuracy: 0.5168 - val_precision: 0.5168 - val_recall: 0.5168 - val_mcc: 0.0562 - val_f1-score: 0.3782 - val_auc: 0.5331 - val_prc: 0.5251 - lr: 0.0010\n",
            "Epoch 45/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6813 - accuracy: 0.5644 - precision: 0.5644 - recall: 0.5644 - mcc: 0.1430 - f1-score: 0.5483 - auc: 0.5911 - prc: 0.5883\n",
            "Epoch 00045: val_accuracy did not improve from 0.58024\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6813 - accuracy: 0.5644 - precision: 0.5644 - recall: 0.5644 - mcc: 0.1430 - f1-score: 0.5483 - auc: 0.5911 - prc: 0.5883 - val_loss: 0.6857 - val_accuracy: 0.5637 - val_precision: 0.5637 - val_recall: 0.5637 - val_mcc: 0.1848 - val_f1-score: 0.4832 - val_auc: 0.5927 - val_prc: 0.5860 - lr: 0.0010\n",
            "Epoch 46/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.5820 - precision: 0.5820 - recall: 0.5820 - mcc: 0.1869 - f1-score: 0.5582 - auc: 0.6261 - prc: 0.6304\n",
            "Epoch 00046: val_accuracy improved from 0.58024 to 0.59633, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.6627 - accuracy: 0.5820 - precision: 0.5820 - recall: 0.5820 - mcc: 0.1869 - f1-score: 0.5582 - auc: 0.6261 - prc: 0.6304 - val_loss: 0.6660 - val_accuracy: 0.5963 - val_precision: 0.5963 - val_recall: 0.5963 - val_mcc: 0.2307 - val_f1-score: 0.5542 - val_auc: 0.6342 - val_prc: 0.6299 - lr: 0.0010\n",
            "Epoch 47/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7073 - accuracy: 0.5177 - precision: 0.5177 - recall: 0.5177 - mcc: 0.0377 - f1-score: 0.5125 - auc: 0.5310 - prc: 0.5292\n",
            "Epoch 00047: val_accuracy did not improve from 0.59633\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.7073 - accuracy: 0.5177 - precision: 0.5177 - recall: 0.5177 - mcc: 0.0377 - f1-score: 0.5125 - auc: 0.5310 - prc: 0.5292 - val_loss: 0.6997 - val_accuracy: 0.5177 - val_precision: 0.5177 - val_recall: 0.5177 - val_mcc: 0.0462 - val_f1-score: 0.4944 - val_auc: 0.5224 - val_prc: 0.5227 - lr: 0.0010\n",
            "Epoch 48/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6948 - accuracy: 0.5246 - precision: 0.5246 - recall: 0.5246 - mcc: 0.0490 - f1-score: 0.5223 - auc: 0.5403 - prc: 0.5405\n",
            "Epoch 00048: val_accuracy did not improve from 0.59633\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.6948 - accuracy: 0.5246 - precision: 0.5246 - recall: 0.5246 - mcc: 0.0490 - f1-score: 0.5223 - auc: 0.5403 - prc: 0.5405 - val_loss: 0.7088 - val_accuracy: 0.5042 - val_precision: 0.5042 - val_recall: 0.5042 - val_mcc: -0.0357 - val_f1-score: 0.3376 - val_auc: 0.5230 - val_prc: 0.5249 - lr: 0.0010\n",
            "Epoch 49/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6912 - accuracy: 0.5409 - precision: 0.5409 - recall: 0.5409 - mcc: 0.0828 - f1-score: 0.5385 - auc: 0.5608 - prc: 0.5581\n",
            "Epoch 00049: val_accuracy did not improve from 0.59633\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.6912 - accuracy: 0.5409 - precision: 0.5409 - recall: 0.5409 - mcc: 0.0828 - f1-score: 0.5385 - auc: 0.5608 - prc: 0.5581 - val_loss: 0.6840 - val_accuracy: 0.5588 - val_precision: 0.5588 - val_recall: 0.5588 - val_mcc: 0.1674 - val_f1-score: 0.4789 - val_auc: 0.5981 - val_prc: 0.5923 - lr: 0.0010\n",
            "Epoch 50/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.5935 - precision: 0.5935 - recall: 0.5935 - mcc: 0.2161 - f1-score: 0.5691 - auc: 0.6366 - prc: 0.6395\n",
            "Epoch 00050: val_accuracy did not improve from 0.59633\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6602 - accuracy: 0.5935 - precision: 0.5935 - recall: 0.5935 - mcc: 0.2161 - f1-score: 0.5691 - auc: 0.6366 - prc: 0.6395 - val_loss: 0.6843 - val_accuracy: 0.5615 - val_precision: 0.5615 - val_recall: 0.5615 - val_mcc: 0.1947 - val_f1-score: 0.4694 - val_auc: 0.6048 - val_prc: 0.6038 - lr: 0.0010\n",
            "Epoch 51/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6391 - accuracy: 0.6205 - precision: 0.6205 - recall: 0.6205 - mcc: 0.2752 - f1-score: 0.5994 - auc: 0.6657 - prc: 0.6715\n",
            "Epoch 00051: val_accuracy improved from 0.59633 to 0.62137, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6391 - accuracy: 0.6205 - precision: 0.6205 - recall: 0.6205 - mcc: 0.2752 - f1-score: 0.5994 - auc: 0.6657 - prc: 0.6715 - val_loss: 0.6701 - val_accuracy: 0.6214 - val_precision: 0.6214 - val_recall: 0.6214 - val_mcc: 0.2982 - val_f1-score: 0.5792 - val_auc: 0.6667 - val_prc: 0.6654 - lr: 0.0010\n",
            "Epoch 52/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.6480 - precision: 0.6480 - recall: 0.6480 - mcc: 0.3444 - f1-score: 0.6243 - auc: 0.7072 - prc: 0.7103\n",
            "Epoch 00052: val_accuracy improved from 0.62137 to 0.64283, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.6146 - accuracy: 0.6480 - precision: 0.6480 - recall: 0.6480 - mcc: 0.3444 - f1-score: 0.6243 - auc: 0.7072 - prc: 0.7103 - val_loss: 0.6674 - val_accuracy: 0.6428 - val_precision: 0.6428 - val_recall: 0.6428 - val_mcc: 0.3482 - val_f1-score: 0.6050 - val_auc: 0.7033 - val_prc: 0.7003 - lr: 0.0010\n",
            "Epoch 53/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.6741 - precision: 0.6741 - recall: 0.6741 - mcc: 0.3877 - f1-score: 0.6568 - auc: 0.7375 - prc: 0.7432\n",
            "Epoch 00053: val_accuracy improved from 0.64283 to 0.67859, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.5890 - accuracy: 0.6741 - precision: 0.6741 - recall: 0.6741 - mcc: 0.3877 - f1-score: 0.6568 - auc: 0.7375 - prc: 0.7432 - val_loss: 0.6040 - val_accuracy: 0.6786 - val_precision: 0.6786 - val_recall: 0.6786 - val_mcc: 0.4254 - val_f1-score: 0.6485 - val_auc: 0.7482 - val_prc: 0.7466 - lr: 0.0010\n",
            "Epoch 54/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.7031 - precision: 0.7031 - recall: 0.7031 - mcc: 0.4311 - f1-score: 0.6955 - auc: 0.7744 - prc: 0.7777\n",
            "Epoch 00054: val_accuracy improved from 0.67859 to 0.69781, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.5602 - accuracy: 0.7031 - precision: 0.7031 - recall: 0.7031 - mcc: 0.4311 - f1-score: 0.6955 - auc: 0.7744 - prc: 0.7777 - val_loss: 0.5986 - val_accuracy: 0.6978 - val_precision: 0.6978 - val_recall: 0.6978 - val_mcc: 0.4122 - val_f1-score: 0.6895 - val_auc: 0.7664 - val_prc: 0.7609 - lr: 0.0010\n",
            "Epoch 55/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.7574 - precision: 0.7574 - recall: 0.7574 - mcc: 0.5348 - f1-score: 0.7531 - auc: 0.8292 - prc: 0.8307\n",
            "Epoch 00055: val_accuracy improved from 0.69781 to 0.72016, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.5046 - accuracy: 0.7574 - precision: 0.7574 - recall: 0.7574 - mcc: 0.5348 - f1-score: 0.7531 - auc: 0.8292 - prc: 0.8307 - val_loss: 0.5901 - val_accuracy: 0.7202 - val_precision: 0.7202 - val_recall: 0.7202 - val_mcc: 0.4784 - val_f1-score: 0.7065 - val_auc: 0.7990 - val_prc: 0.7947 - lr: 0.0010\n",
            "Epoch 56/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.8099 - precision: 0.8099 - recall: 0.8099 - mcc: 0.6271 - f1-score: 0.8090 - auc: 0.8858 - prc: 0.8861\n",
            "Epoch 00056: val_accuracy improved from 0.72016 to 0.80957, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.4269 - accuracy: 0.8099 - precision: 0.8099 - recall: 0.8099 - mcc: 0.6271 - f1-score: 0.8090 - auc: 0.8858 - prc: 0.8861 - val_loss: 0.4657 - val_accuracy: 0.8096 - val_precision: 0.8096 - val_recall: 0.8096 - val_mcc: 0.6261 - val_f1-score: 0.8079 - val_auc: 0.8824 - val_prc: 0.8786 - lr: 0.0010\n",
            "Epoch 57/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.3431 - accuracy: 0.8599 - precision: 0.8599 - recall: 0.8599 - mcc: 0.7212 - f1-score: 0.8599 - auc: 0.9292 - prc: 0.9280\n",
            "Epoch 00057: val_accuracy improved from 0.80957 to 0.82566, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.3431 - accuracy: 0.8599 - precision: 0.8599 - recall: 0.8599 - mcc: 0.7212 - f1-score: 0.8599 - auc: 0.9292 - prc: 0.9280 - val_loss: 0.3919 - val_accuracy: 0.8257 - val_precision: 0.8257 - val_recall: 0.8257 - val_mcc: 0.6597 - val_f1-score: 0.8240 - val_auc: 0.9101 - val_prc: 0.9088 - lr: 0.0010\n",
            "Epoch 58/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.2505 - accuracy: 0.8984 - precision: 0.8984 - recall: 0.8984 - mcc: 0.7969 - f1-score: 0.8984 - auc: 0.9631 - prc: 0.9625\n",
            "Epoch 00058: val_accuracy improved from 0.82566 to 0.87975, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.2505 - accuracy: 0.8984 - precision: 0.8984 - recall: 0.8984 - mcc: 0.7969 - f1-score: 0.8984 - auc: 0.9631 - prc: 0.9625 - val_loss: 0.3151 - val_accuracy: 0.8797 - val_precision: 0.8797 - val_recall: 0.8797 - val_mcc: 0.7598 - val_f1-score: 0.8796 - val_auc: 0.9512 - val_prc: 0.9481 - lr: 0.0010\n",
            "Epoch 59/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9193 - precision: 0.9193 - recall: 0.9193 - mcc: 0.8390 - f1-score: 0.9192 - auc: 0.9776 - prc: 0.9772\n",
            "Epoch 00059: val_accuracy improved from 0.87975 to 0.89763, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.1954 - accuracy: 0.9193 - precision: 0.9193 - recall: 0.9193 - mcc: 0.8390 - f1-score: 0.9192 - auc: 0.9776 - prc: 0.9772 - val_loss: 0.2602 - val_accuracy: 0.8976 - val_precision: 0.8976 - val_recall: 0.8976 - val_mcc: 0.7964 - val_f1-score: 0.8974 - val_auc: 0.9646 - val_prc: 0.9616 - lr: 0.0010\n",
            "Epoch 60/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.9359 - precision: 0.9359 - recall: 0.9359 - mcc: 0.8731 - f1-score: 0.9358 - auc: 0.9856 - prc: 0.9851\n",
            "Epoch 00060: val_accuracy improved from 0.89763 to 0.90300, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.1544 - accuracy: 0.9359 - precision: 0.9359 - recall: 0.9359 - mcc: 0.8731 - f1-score: 0.9358 - auc: 0.9856 - prc: 0.9851 - val_loss: 0.2510 - val_accuracy: 0.9030 - val_precision: 0.9030 - val_recall: 0.9030 - val_mcc: 0.8062 - val_f1-score: 0.9029 - val_auc: 0.9705 - val_prc: 0.9669 - lr: 0.0010\n",
            "Epoch 61/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9308 - precision: 0.9308 - recall: 0.9308 - mcc: 0.8627 - f1-score: 0.9308 - auc: 0.9846 - prc: 0.9840\n",
            "Epoch 00061: val_accuracy improved from 0.90300 to 0.90791, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.1607 - accuracy: 0.9308 - precision: 0.9308 - recall: 0.9308 - mcc: 0.8627 - f1-score: 0.9308 - auc: 0.9846 - prc: 0.9840 - val_loss: 0.2145 - val_accuracy: 0.9079 - val_precision: 0.9079 - val_recall: 0.9079 - val_mcc: 0.8233 - val_f1-score: 0.9077 - val_auc: 0.9736 - val_prc: 0.9728 - lr: 0.0010\n",
            "Epoch 62/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.9410 - precision: 0.9410 - recall: 0.9410 - mcc: 0.8836 - f1-score: 0.9409 - auc: 0.9886 - prc: 0.9884\n",
            "Epoch 00062: val_accuracy improved from 0.90791 to 0.93295, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.1387 - accuracy: 0.9410 - precision: 0.9410 - recall: 0.9410 - mcc: 0.8836 - f1-score: 0.9409 - auc: 0.9886 - prc: 0.9884 - val_loss: 0.1460 - val_accuracy: 0.9329 - val_precision: 0.9329 - val_recall: 0.9329 - val_mcc: 0.8704 - val_f1-score: 0.9329 - val_auc: 0.9870 - val_prc: 0.9864 - lr: 0.0010\n",
            "Epoch 63/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - mcc: 0.9127 - f1-score: 0.9557 - auc: 0.9942 - prc: 0.9941\n",
            "Epoch 00063: val_accuracy improved from 0.93295 to 0.94144, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0965 - accuracy: 0.9557 - precision: 0.9557 - recall: 0.9557 - mcc: 0.9127 - f1-score: 0.9557 - auc: 0.9942 - prc: 0.9941 - val_loss: 0.1446 - val_accuracy: 0.9414 - val_precision: 0.9414 - val_recall: 0.9414 - val_mcc: 0.8853 - val_f1-score: 0.9414 - val_auc: 0.9864 - val_prc: 0.9841 - lr: 0.0010\n",
            "Epoch 64/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.9555 - precision: 0.9555 - recall: 0.9555 - mcc: 0.9112 - f1-score: 0.9555 - auc: 0.9947 - prc: 0.9947\n",
            "Epoch 00064: val_accuracy improved from 0.94144 to 0.94412, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0948 - accuracy: 0.9555 - precision: 0.9555 - recall: 0.9555 - mcc: 0.9112 - f1-score: 0.9555 - auc: 0.9947 - prc: 0.9947 - val_loss: 0.1246 - val_accuracy: 0.9441 - val_precision: 0.9441 - val_recall: 0.9441 - val_mcc: 0.8883 - val_f1-score: 0.9441 - val_auc: 0.9891 - val_prc: 0.9877 - lr: 0.0010\n",
            "Epoch 65/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9627 - precision: 0.9627 - recall: 0.9627 - mcc: 0.9257 - f1-score: 0.9627 - auc: 0.9958 - prc: 0.9958\n",
            "Epoch 00065: val_accuracy improved from 0.94412 to 0.94770, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0836 - accuracy: 0.9627 - precision: 0.9627 - recall: 0.9627 - mcc: 0.9257 - f1-score: 0.9627 - auc: 0.9958 - prc: 0.9958 - val_loss: 0.1305 - val_accuracy: 0.9477 - val_precision: 0.9477 - val_recall: 0.9477 - val_mcc: 0.8955 - val_f1-score: 0.9477 - val_auc: 0.9900 - val_prc: 0.9892 - lr: 0.0010\n",
            "Epoch 66/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - mcc: 0.9287 - f1-score: 0.9643 - auc: 0.9958 - prc: 0.9956\n",
            "Epoch 00066: val_accuracy improved from 0.94770 to 0.95351, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0839 - accuracy: 0.9643 - precision: 0.9643 - recall: 0.9643 - mcc: 0.9287 - f1-score: 0.9643 - auc: 0.9958 - prc: 0.9956 - val_loss: 0.1223 - val_accuracy: 0.9535 - val_precision: 0.9535 - val_recall: 0.9535 - val_mcc: 0.9070 - val_f1-score: 0.9535 - val_auc: 0.9914 - val_prc: 0.9907 - lr: 0.0010\n",
            "Epoch 67/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9625 - precision: 0.9625 - recall: 0.9625 - mcc: 0.9252 - f1-score: 0.9625 - auc: 0.9942 - prc: 0.9938\n",
            "Epoch 00067: val_accuracy did not improve from 0.95351\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0971 - accuracy: 0.9625 - precision: 0.9625 - recall: 0.9625 - mcc: 0.9252 - f1-score: 0.9625 - auc: 0.9942 - prc: 0.9938 - val_loss: 0.1247 - val_accuracy: 0.9419 - val_precision: 0.9419 - val_recall: 0.9419 - val_mcc: 0.8839 - val_f1-score: 0.9419 - val_auc: 0.9895 - val_prc: 0.9885 - lr: 0.0010\n",
            "Epoch 68/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.9728 - precision: 0.9728 - recall: 0.9728 - mcc: 0.9457 - f1-score: 0.9728 - auc: 0.9972 - prc: 0.9971\n",
            "Epoch 00068: val_accuracy improved from 0.95351 to 0.95932, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 282ms/step - loss: 0.0698 - accuracy: 0.9728 - precision: 0.9728 - recall: 0.9728 - mcc: 0.9457 - f1-score: 0.9728 - auc: 0.9972 - prc: 0.9971 - val_loss: 0.1147 - val_accuracy: 0.9593 - val_precision: 0.9593 - val_recall: 0.9593 - val_mcc: 0.9190 - val_f1-score: 0.9593 - val_auc: 0.9922 - val_prc: 0.9910 - lr: 0.0010\n",
            "Epoch 69/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.9792 - precision: 0.9792 - recall: 0.9792 - mcc: 0.9583 - f1-score: 0.9792 - auc: 0.9986 - prc: 0.9985\n",
            "Epoch 00069: val_accuracy did not improve from 0.95932\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0509 - accuracy: 0.9792 - precision: 0.9792 - recall: 0.9792 - mcc: 0.9583 - f1-score: 0.9792 - auc: 0.9986 - prc: 0.9985 - val_loss: 0.1134 - val_accuracy: 0.9531 - val_precision: 0.9531 - val_recall: 0.9531 - val_mcc: 0.9061 - val_f1-score: 0.9531 - val_auc: 0.9925 - val_prc: 0.9917 - lr: 0.0010\n",
            "Epoch 70/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 0.9771 - precision: 0.9771 - recall: 0.9771 - mcc: 0.9543 - f1-score: 0.9771 - auc: 0.9981 - prc: 0.9981\n",
            "Epoch 00070: val_accuracy did not improve from 0.95932\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0583 - accuracy: 0.9771 - precision: 0.9771 - recall: 0.9771 - mcc: 0.9543 - f1-score: 0.9771 - auc: 0.9981 - prc: 0.9981 - val_loss: 0.1356 - val_accuracy: 0.9477 - val_precision: 0.9477 - val_recall: 0.9477 - val_mcc: 0.8958 - val_f1-score: 0.9476 - val_auc: 0.9903 - val_prc: 0.9896 - lr: 0.0010\n",
            "Epoch 71/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9766 - precision: 0.9766 - recall: 0.9766 - mcc: 0.9531 - f1-score: 0.9766 - auc: 0.9979 - prc: 0.9979\n",
            "Epoch 00071: val_accuracy did not improve from 0.95932\n",
            "69/69 [==============================] - 19s 273ms/step - loss: 0.0605 - accuracy: 0.9766 - precision: 0.9766 - recall: 0.9766 - mcc: 0.9531 - f1-score: 0.9766 - auc: 0.9979 - prc: 0.9979 - val_loss: 0.1506 - val_accuracy: 0.9526 - val_precision: 0.9526 - val_recall: 0.9526 - val_mcc: 0.9064 - val_f1-score: 0.9526 - val_auc: 0.9888 - val_prc: 0.9871 - lr: 0.0010\n",
            "Epoch 72/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.9763 - precision: 0.9763 - recall: 0.9763 - mcc: 0.9527 - f1-score: 0.9763 - auc: 0.9971 - prc: 0.9968\n",
            "Epoch 00072: val_accuracy did not improve from 0.95932\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0639 - accuracy: 0.9763 - precision: 0.9763 - recall: 0.9763 - mcc: 0.9527 - f1-score: 0.9763 - auc: 0.9971 - prc: 0.9968 - val_loss: 0.1731 - val_accuracy: 0.9392 - val_precision: 0.9392 - val_recall: 0.9392 - val_mcc: 0.8789 - val_f1-score: 0.9391 - val_auc: 0.9821 - val_prc: 0.9806 - lr: 0.0010\n",
            "Epoch 73/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9764 - precision: 0.9764 - recall: 0.9764 - mcc: 0.9529 - f1-score: 0.9764 - auc: 0.9977 - prc: 0.9975\n",
            "Epoch 00073: val_accuracy did not improve from 0.95932\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0617 - accuracy: 0.9764 - precision: 0.9764 - recall: 0.9764 - mcc: 0.9529 - f1-score: 0.9764 - auc: 0.9977 - prc: 0.9975 - val_loss: 0.1721 - val_accuracy: 0.9584 - val_precision: 0.9584 - val_recall: 0.9584 - val_mcc: 0.9169 - val_f1-score: 0.9584 - val_auc: 0.9862 - val_prc: 0.9832 - lr: 0.0010\n",
            "Epoch 74/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 0.9808 - precision: 0.9808 - recall: 0.9808 - mcc: 0.9615 - f1-score: 0.9808 - auc: 0.9984 - prc: 0.9983\n",
            "Epoch 00074: val_accuracy did not improve from 0.95932\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0522 - accuracy: 0.9808 - precision: 0.9808 - recall: 0.9808 - mcc: 0.9615 - f1-score: 0.9808 - auc: 0.9984 - prc: 0.9983 - val_loss: 0.1230 - val_accuracy: 0.9553 - val_precision: 0.9553 - val_recall: 0.9553 - val_mcc: 0.9107 - val_f1-score: 0.9553 - val_auc: 0.9906 - val_prc: 0.9890 - lr: 0.0010\n",
            "Epoch 75/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9861 - precision: 0.9861 - recall: 0.9861 - mcc: 0.9721 - f1-score: 0.9861 - auc: 0.9993 - prc: 0.9993\n",
            "Epoch 00075: val_accuracy did not improve from 0.95932\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0367 - accuracy: 0.9861 - precision: 0.9861 - recall: 0.9861 - mcc: 0.9721 - f1-score: 0.9861 - auc: 0.9993 - prc: 0.9993 - val_loss: 0.1326 - val_accuracy: 0.9571 - val_precision: 0.9571 - val_recall: 0.9571 - val_mcc: 0.9143 - val_f1-score: 0.9571 - val_auc: 0.9909 - val_prc: 0.9893 - lr: 0.0010\n",
            "Epoch 76/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - mcc: 0.9760 - f1-score: 0.9880 - auc: 0.9995 - prc: 0.9994\n",
            "Epoch 00076: val_accuracy improved from 0.95932 to 0.96334, saving model to my_best_model_4.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.0301 - accuracy: 0.9880 - precision: 0.9880 - recall: 0.9880 - mcc: 0.9760 - f1-score: 0.9880 - auc: 0.9995 - prc: 0.9994 - val_loss: 0.1432 - val_accuracy: 0.9633 - val_precision: 0.9633 - val_recall: 0.9633 - val_mcc: 0.9267 - val_f1-score: 0.9633 - val_auc: 0.9896 - val_prc: 0.9874 - lr: 0.0010\n",
            "Epoch 77/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - mcc: 0.9805 - f1-score: 0.9903 - auc: 0.9995 - prc: 0.9994\n",
            "Epoch 00077: val_accuracy did not improve from 0.96334\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0290 - accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - mcc: 0.9805 - f1-score: 0.9903 - auc: 0.9995 - prc: 0.9994 - val_loss: 0.1790 - val_accuracy: 0.9589 - val_precision: 0.9589 - val_recall: 0.9589 - val_mcc: 0.9181 - val_f1-score: 0.9589 - val_auc: 0.9845 - val_prc: 0.9806 - lr: 0.0010\n",
            "Epoch 78/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - mcc: 0.9805 - f1-score: 0.9903 - auc: 0.9995 - prc: 0.9994\n",
            "Epoch 00078: val_accuracy did not improve from 0.96334\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 0.0263 - accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - mcc: 0.9805 - f1-score: 0.9903 - auc: 0.9995 - prc: 0.9994 - val_loss: 0.1492 - val_accuracy: 0.9616 - val_precision: 0.9616 - val_recall: 0.9616 - val_mcc: 0.9231 - val_f1-score: 0.9615 - val_auc: 0.9898 - val_prc: 0.9875 - lr: 0.0010\n",
            "Epoch 79/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - mcc: 0.9651 - f1-score: 0.9826 - auc: 0.9985 - prc: 0.9983\n",
            "Epoch 00079: val_accuracy did not improve from 0.96334\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.0467 - accuracy: 0.9826 - precision: 0.9826 - recall: 0.9826 - mcc: 0.9651 - f1-score: 0.9826 - auc: 0.9985 - prc: 0.9983 - val_loss: 0.1788 - val_accuracy: 0.9361 - val_precision: 0.9361 - val_recall: 0.9361 - val_mcc: 0.8729 - val_f1-score: 0.9361 - val_auc: 0.9835 - val_prc: 0.9813 - lr: 0.0010\n",
            "Epoch 80/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9812 - mcc: 0.9624 - f1-score: 0.9812 - auc: 0.9978 - prc: 0.9976\n",
            "Epoch 00080: val_accuracy did not improve from 0.96334\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0554 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9812 - mcc: 0.9624 - f1-score: 0.9812 - auc: 0.9978 - prc: 0.9976 - val_loss: 0.1497 - val_accuracy: 0.9584 - val_precision: 0.9584 - val_recall: 0.9584 - val_mcc: 0.9169 - val_f1-score: 0.9584 - val_auc: 0.9895 - val_prc: 0.9875 - lr: 0.0010\n",
            "==================End training 4========================\n",
            "accuracy: 0.9615642458100558, precision: 0.9631531933899062, recall: 0.9601513802315227, specificity: 0.9599731663685152, mcc: 0.923132813444822 ,f1-score: 0.9616499442586399\n",
            "==================== Training time  5 =====================\n",
            "Epoch 1/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 2.1042 - accuracy: 0.5927 - precision: 0.5927 - recall: 0.5927 - mcc: 0.1854 - f1-score: 0.5927 - auc: 0.6696 - prc: 0.6976\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.51855, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 53s 367ms/step - loss: 2.1042 - accuracy: 0.5927 - precision: 0.5927 - recall: 0.5927 - mcc: 0.1854 - f1-score: 0.5927 - auc: 0.6696 - prc: 0.6976 - val_loss: 1.5737 - val_accuracy: 0.5186 - val_precision: 0.5186 - val_recall: 0.5186 - val_mcc: 0.0366 - val_f1-score: 0.5182 - val_auc: 0.5132 - val_prc: 0.5070 - lr: 0.0010\n",
            "Epoch 2/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 1.3546 - accuracy: 0.4888 - precision: 0.4888 - recall: 0.4888 - mcc: -0.0223 - f1-score: 0.4887 - auc: 0.4880 - prc: 0.4903\n",
            "Epoch 00002: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 274ms/step - loss: 1.3546 - accuracy: 0.4888 - precision: 0.4888 - recall: 0.4888 - mcc: -0.0223 - f1-score: 0.4887 - auc: 0.4880 - prc: 0.4903 - val_loss: 1.0953 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078 - val_mcc: 0.0000e+00 - val_f1-score: 0.3368 - val_auc: 0.5076 - val_prc: 0.5059 - lr: 0.0010\n",
            "Epoch 3/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.9879 - accuracy: 0.5048 - precision: 0.5048 - recall: 0.5048 - mcc: 0.0098 - f1-score: 0.5043 - auc: 0.5141 - prc: 0.5116\n",
            "Epoch 00003: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.9879 - accuracy: 0.5048 - precision: 0.5048 - recall: 0.5048 - mcc: 0.0098 - f1-score: 0.5043 - auc: 0.5141 - prc: 0.5116 - val_loss: 0.9009 - val_accuracy: 0.5101 - val_precision: 0.5101 - val_recall: 0.5101 - val_mcc: 0.0175 - val_f1-score: 0.5051 - val_auc: 0.5148 - val_prc: 0.5102 - lr: 0.0010\n",
            "Epoch 4/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.8498 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - mcc: 0.0299 - f1-score: 0.5148 - auc: 0.5236 - prc: 0.5178\n",
            "Epoch 00004: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.8498 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - mcc: 0.0299 - f1-score: 0.5148 - auc: 0.5236 - prc: 0.5178 - val_loss: 0.8120 - val_accuracy: 0.4904 - val_precision: 0.4904 - val_recall: 0.4904 - val_mcc: -0.0130 - val_f1-score: 0.3536 - val_auc: 0.4938 - val_prc: 0.4933 - lr: 0.0010\n",
            "Epoch 5/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7850 - accuracy: 0.4989 - precision: 0.4989 - recall: 0.4989 - mcc: -0.0026 - f1-score: 0.4975 - auc: 0.5053 - prc: 0.5041\n",
            "Epoch 00005: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.7850 - accuracy: 0.4989 - precision: 0.4989 - recall: 0.4989 - mcc: -0.0026 - f1-score: 0.4975 - auc: 0.5053 - prc: 0.5041 - val_loss: 0.7635 - val_accuracy: 0.5087 - val_precision: 0.5087 - val_recall: 0.5087 - val_mcc: 0.0096 - val_f1-score: 0.4484 - val_auc: 0.5194 - val_prc: 0.5148 - lr: 0.0010\n",
            "Epoch 6/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7505 - accuracy: 0.5134 - precision: 0.5134 - recall: 0.5134 - mcc: 0.0268 - f1-score: 0.5132 - auc: 0.5177 - prc: 0.5145\n",
            "Epoch 00006: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.7505 - accuracy: 0.5134 - precision: 0.5134 - recall: 0.5134 - mcc: 0.0268 - f1-score: 0.5132 - auc: 0.5177 - prc: 0.5145 - val_loss: 0.7401 - val_accuracy: 0.5034 - val_precision: 0.5034 - val_recall: 0.5034 - val_mcc: -0.0124 - val_f1-score: 0.3895 - val_auc: 0.5179 - val_prc: 0.5129 - lr: 0.0010\n",
            "Epoch 7/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7321 - accuracy: 0.5164 - precision: 0.5164 - recall: 0.5164 - mcc: 0.0338 - f1-score: 0.5157 - auc: 0.5216 - prc: 0.5178\n",
            "Epoch 00007: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.7321 - accuracy: 0.5164 - precision: 0.5164 - recall: 0.5164 - mcc: 0.0338 - f1-score: 0.5157 - auc: 0.5216 - prc: 0.5178 - val_loss: 0.7262 - val_accuracy: 0.5092 - val_precision: 0.5092 - val_recall: 0.5092 - val_mcc: 0.0105 - val_f1-score: 0.4406 - val_auc: 0.5141 - val_prc: 0.5094 - lr: 0.0010\n",
            "Epoch 8/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7216 - accuracy: 0.5157 - precision: 0.5157 - recall: 0.5157 - mcc: 0.0316 - f1-score: 0.5157 - auc: 0.5208 - prc: 0.5170\n",
            "Epoch 00008: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.7216 - accuracy: 0.5157 - precision: 0.5157 - recall: 0.5157 - mcc: 0.0316 - f1-score: 0.5157 - auc: 0.5208 - prc: 0.5170 - val_loss: 0.7190 - val_accuracy: 0.4931 - val_precision: 0.4931 - val_recall: 0.4931 - val_mcc: 0.0111 - val_f1-score: 0.3356 - val_auc: 0.5002 - val_prc: 0.5002 - lr: 0.0010\n",
            "Epoch 9/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7147 - accuracy: 0.5209 - precision: 0.5209 - recall: 0.5209 - mcc: 0.0419 - f1-score: 0.5209 - auc: 0.5252 - prc: 0.5210\n",
            "Epoch 00009: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.7147 - accuracy: 0.5209 - precision: 0.5209 - recall: 0.5209 - mcc: 0.0419 - f1-score: 0.5209 - auc: 0.5252 - prc: 0.5210 - val_loss: 0.7132 - val_accuracy: 0.5096 - val_precision: 0.5096 - val_recall: 0.5096 - val_mcc: 0.0112 - val_f1-score: 0.4082 - val_auc: 0.5136 - val_prc: 0.5093 - lr: 0.0010\n",
            "Epoch 10/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7111 - accuracy: 0.5153 - precision: 0.5153 - recall: 0.5153 - mcc: 0.0303 - f1-score: 0.5151 - auc: 0.5200 - prc: 0.5128\n",
            "Epoch 00010: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.7111 - accuracy: 0.5153 - precision: 0.5153 - recall: 0.5153 - mcc: 0.0303 - f1-score: 0.5151 - auc: 0.5200 - prc: 0.5128 - val_loss: 0.7092 - val_accuracy: 0.5087 - val_precision: 0.5087 - val_recall: 0.5087 - val_mcc: 0.0091 - val_f1-score: 0.4367 - val_auc: 0.5112 - val_prc: 0.5064 - lr: 0.0010\n",
            "Epoch 11/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7067 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - mcc: 0.0558 - f1-score: 0.5265 - auc: 0.5335 - prc: 0.5240\n",
            "Epoch 00011: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.7067 - accuracy: 0.5277 - precision: 0.5277 - recall: 0.5277 - mcc: 0.0558 - f1-score: 0.5265 - auc: 0.5335 - prc: 0.5240 - val_loss: 0.7066 - val_accuracy: 0.5118 - val_precision: 0.5118 - val_recall: 0.5118 - val_mcc: 0.0187 - val_f1-score: 0.4854 - val_auc: 0.5198 - val_prc: 0.5134 - lr: 0.0010\n",
            "Epoch 12/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7050 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - mcc: 0.0448 - f1-score: 0.5224 - auc: 0.5270 - prc: 0.5189\n",
            "Epoch 00012: val_accuracy did not improve from 0.51855\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.7050 - accuracy: 0.5224 - precision: 0.5224 - recall: 0.5224 - mcc: 0.0448 - f1-score: 0.5224 - auc: 0.5270 - prc: 0.5189 - val_loss: 0.7042 - val_accuracy: 0.5123 - val_precision: 0.5123 - val_recall: 0.5123 - val_mcc: 0.0213 - val_f1-score: 0.5034 - val_auc: 0.5252 - val_prc: 0.5163 - lr: 0.0010\n",
            "Epoch 13/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.5420 - precision: 0.5420 - recall: 0.5420 - mcc: 0.0843 - f1-score: 0.5414 - auc: 0.5440 - prc: 0.5324\n",
            "Epoch 00013: val_accuracy improved from 0.51855 to 0.53062, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.7015 - accuracy: 0.5420 - precision: 0.5420 - recall: 0.5420 - mcc: 0.0843 - f1-score: 0.5414 - auc: 0.5440 - prc: 0.5324 - val_loss: 0.7005 - val_accuracy: 0.5306 - val_precision: 0.5306 - val_recall: 0.5306 - val_mcc: 0.0625 - val_f1-score: 0.4928 - val_auc: 0.5478 - val_prc: 0.5556 - lr: 0.0010\n",
            "Epoch 14/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7046 - accuracy: 0.5126 - precision: 0.5126 - recall: 0.5126 - mcc: 0.0240 - f1-score: 0.5067 - auc: 0.5160 - prc: 0.5151\n",
            "Epoch 00014: val_accuracy did not improve from 0.53062\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.7046 - accuracy: 0.5126 - precision: 0.5126 - recall: 0.5126 - mcc: 0.0240 - f1-score: 0.5067 - auc: 0.5160 - prc: 0.5151 - val_loss: 0.7047 - val_accuracy: 0.5051 - val_precision: 0.5051 - val_recall: 0.5051 - val_mcc: -0.0244 - val_f1-score: 0.3427 - val_auc: 0.5133 - val_prc: 0.5138 - lr: 0.0010\n",
            "Epoch 15/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7034 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0131 - f1-score: 0.5036 - auc: 0.5083 - prc: 0.5059\n",
            "Epoch 00015: val_accuracy did not improve from 0.53062\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.7034 - accuracy: 0.5062 - precision: 0.5062 - recall: 0.5062 - mcc: 0.0131 - f1-score: 0.5036 - auc: 0.5083 - prc: 0.5059 - val_loss: 0.7022 - val_accuracy: 0.5056 - val_precision: 0.5056 - val_recall: 0.5056 - val_mcc: -0.0040 - val_f1-score: 0.3920 - val_auc: 0.5025 - val_prc: 0.5001 - lr: 0.0010\n",
            "Epoch 16/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.5088 - precision: 0.5088 - recall: 0.5088 - mcc: 0.0171 - f1-score: 0.5063 - auc: 0.5154 - prc: 0.5113\n",
            "Epoch 00016: val_accuracy did not improve from 0.53062\n",
            "69/69 [==============================] - 19s 275ms/step - loss: 0.7015 - accuracy: 0.5088 - precision: 0.5088 - recall: 0.5088 - mcc: 0.0171 - f1-score: 0.5063 - auc: 0.5154 - prc: 0.5113 - val_loss: 0.7009 - val_accuracy: 0.5078 - val_precision: 0.5078 - val_recall: 0.5078 - val_mcc: 0.0000e+00 - val_f1-score: 0.3368 - val_auc: 0.5148 - val_prc: 0.5112 - lr: 0.0010\n",
            "Epoch 17/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6993 - accuracy: 0.5192 - precision: 0.5192 - recall: 0.5192 - mcc: 0.0386 - f1-score: 0.5188 - auc: 0.5285 - prc: 0.5220\n",
            "Epoch 00017: val_accuracy did not improve from 0.53062\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6993 - accuracy: 0.5192 - precision: 0.5192 - recall: 0.5192 - mcc: 0.0386 - f1-score: 0.5188 - auc: 0.5285 - prc: 0.5220 - val_loss: 0.7019 - val_accuracy: 0.5083 - val_precision: 0.5083 - val_recall: 0.5083 - val_mcc: 0.0087 - val_f1-score: 0.4527 - val_auc: 0.5211 - val_prc: 0.5178 - lr: 0.0010\n",
            "Epoch 18/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6980 - accuracy: 0.5382 - precision: 0.5382 - recall: 0.5382 - mcc: 0.0754 - f1-score: 0.5350 - auc: 0.5405 - prc: 0.5284\n",
            "Epoch 00018: val_accuracy did not improve from 0.53062\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.6980 - accuracy: 0.5382 - precision: 0.5382 - recall: 0.5382 - mcc: 0.0754 - f1-score: 0.5350 - auc: 0.5405 - prc: 0.5284 - val_loss: 0.6992 - val_accuracy: 0.5002 - val_precision: 0.5002 - val_recall: 0.5002 - val_mcc: -0.0052 - val_f1-score: 0.4836 - val_auc: 0.5176 - val_prc: 0.5183 - lr: 0.0010\n",
            "Epoch 19/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6990 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - mcc: 0.0319 - f1-score: 0.5084 - auc: 0.5251 - prc: 0.5236\n",
            "Epoch 00019: val_accuracy did not improve from 0.53062\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6990 - accuracy: 0.5149 - precision: 0.5149 - recall: 0.5149 - mcc: 0.0319 - f1-score: 0.5084 - auc: 0.5251 - prc: 0.5236 - val_loss: 0.6988 - val_accuracy: 0.5110 - val_precision: 0.5110 - val_recall: 0.5110 - val_mcc: 0.0158 - val_f1-score: 0.4654 - val_auc: 0.5240 - val_prc: 0.5176 - lr: 0.0010\n",
            "Epoch 20/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.5386 - precision: 0.5386 - recall: 0.5386 - mcc: 0.0793 - f1-score: 0.5368 - auc: 0.5531 - prc: 0.5439\n",
            "Epoch 00020: val_accuracy improved from 0.53062 to 0.55700, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.6955 - accuracy: 0.5386 - precision: 0.5386 - recall: 0.5386 - mcc: 0.0793 - f1-score: 0.5368 - auc: 0.5531 - prc: 0.5439 - val_loss: 0.6934 - val_accuracy: 0.5570 - val_precision: 0.5570 - val_recall: 0.5570 - val_mcc: 0.1179 - val_f1-score: 0.5548 - val_auc: 0.5772 - val_prc: 0.5670 - lr: 0.0010\n",
            "Epoch 21/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6868 - accuracy: 0.5614 - precision: 0.5614 - recall: 0.5614 - mcc: 0.1274 - f1-score: 0.5513 - auc: 0.5857 - prc: 0.5839\n",
            "Epoch 00021: val_accuracy did not improve from 0.55700\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6868 - accuracy: 0.5614 - precision: 0.5614 - recall: 0.5614 - mcc: 0.1274 - f1-score: 0.5513 - auc: 0.5857 - prc: 0.5839 - val_loss: 0.7441 - val_accuracy: 0.5449 - val_precision: 0.5449 - val_recall: 0.5449 - val_mcc: 0.0895 - val_f1-score: 0.5321 - val_auc: 0.5508 - val_prc: 0.5450 - lr: 0.0010\n",
            "Epoch 22/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.5692 - precision: 0.5692 - recall: 0.5692 - mcc: 0.1473 - f1-score: 0.5492 - auc: 0.5952 - prc: 0.5913\n",
            "Epoch 00022: val_accuracy improved from 0.55700 to 0.58516, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 282ms/step - loss: 0.6845 - accuracy: 0.5692 - precision: 0.5692 - recall: 0.5692 - mcc: 0.1473 - f1-score: 0.5492 - auc: 0.5952 - prc: 0.5913 - val_loss: 0.6749 - val_accuracy: 0.5852 - val_precision: 0.5852 - val_recall: 0.5852 - val_mcc: 0.2456 - val_f1-score: 0.5343 - val_auc: 0.6140 - val_prc: 0.6148 - lr: 0.0010\n",
            "Epoch 23/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.5866 - precision: 0.5866 - recall: 0.5866 - mcc: 0.1838 - f1-score: 0.5741 - auc: 0.6149 - prc: 0.6088\n",
            "Epoch 00023: val_accuracy improved from 0.58516 to 0.59455, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.6769 - accuracy: 0.5866 - precision: 0.5866 - recall: 0.5866 - mcc: 0.1838 - f1-score: 0.5741 - auc: 0.6149 - prc: 0.6088 - val_loss: 0.6670 - val_accuracy: 0.5945 - val_precision: 0.5945 - val_recall: 0.5945 - val_mcc: 0.2585 - val_f1-score: 0.5511 - val_auc: 0.6314 - val_prc: 0.6314 - lr: 0.0010\n",
            "Epoch 24/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6656 - accuracy: 0.5964 - precision: 0.5964 - recall: 0.5964 - mcc: 0.2126 - f1-score: 0.5767 - auc: 0.6341 - prc: 0.6321\n",
            "Epoch 00024: val_accuracy did not improve from 0.59455\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.6656 - accuracy: 0.5964 - precision: 0.5964 - recall: 0.5964 - mcc: 0.2126 - f1-score: 0.5767 - auc: 0.6341 - prc: 0.6321 - val_loss: 0.6881 - val_accuracy: 0.5557 - val_precision: 0.5557 - val_recall: 0.5557 - val_mcc: 0.1385 - val_f1-score: 0.5270 - val_auc: 0.5859 - val_prc: 0.5760 - lr: 0.0010\n",
            "Epoch 25/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.6081 - precision: 0.6081 - recall: 0.6081 - mcc: 0.2482 - f1-score: 0.5822 - auc: 0.6458 - prc: 0.6451\n",
            "Epoch 00025: val_accuracy improved from 0.59455 to 0.62539, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.6575 - accuracy: 0.6081 - precision: 0.6081 - recall: 0.6081 - mcc: 0.2482 - f1-score: 0.5822 - auc: 0.6458 - prc: 0.6451 - val_loss: 0.6355 - val_accuracy: 0.6254 - val_precision: 0.6254 - val_recall: 0.6254 - val_mcc: 0.3091 - val_f1-score: 0.5973 - val_auc: 0.6754 - val_prc: 0.6812 - lr: 0.0010\n",
            "Epoch 26/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - mcc: 0.2820 - f1-score: 0.5907 - auc: 0.6661 - prc: 0.6676\n",
            "Epoch 00026: val_accuracy did not improve from 0.62539\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.6446 - accuracy: 0.6204 - precision: 0.6204 - recall: 0.6204 - mcc: 0.2820 - f1-score: 0.5907 - auc: 0.6661 - prc: 0.6676 - val_loss: 0.6585 - val_accuracy: 0.5950 - val_precision: 0.5950 - val_recall: 0.5950 - val_mcc: 0.1910 - val_f1-score: 0.5949 - val_auc: 0.6399 - val_prc: 0.6494 - lr: 0.0010\n",
            "Epoch 27/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.6456 - precision: 0.6456 - recall: 0.6456 - mcc: 0.3298 - f1-score: 0.6218 - auc: 0.7033 - prc: 0.7060\n",
            "Epoch 00027: val_accuracy improved from 0.62539 to 0.64059, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 283ms/step - loss: 0.6198 - accuracy: 0.6456 - precision: 0.6456 - recall: 0.6456 - mcc: 0.3298 - f1-score: 0.6218 - auc: 0.7033 - prc: 0.7060 - val_loss: 0.6198 - val_accuracy: 0.6406 - val_precision: 0.6406 - val_recall: 0.6406 - val_mcc: 0.3418 - val_f1-score: 0.6150 - val_auc: 0.7001 - val_prc: 0.7038 - lr: 0.0010\n",
            "Epoch 28/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.6712 - precision: 0.6712 - recall: 0.6712 - mcc: 0.3791 - f1-score: 0.6553 - auc: 0.7333 - prc: 0.7326\n",
            "Epoch 00028: val_accuracy improved from 0.64059 to 0.67769, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.6020 - accuracy: 0.6712 - precision: 0.6712 - recall: 0.6712 - mcc: 0.3791 - f1-score: 0.6553 - auc: 0.7333 - prc: 0.7326 - val_loss: 0.6078 - val_accuracy: 0.6777 - val_precision: 0.6777 - val_recall: 0.6777 - val_mcc: 0.3981 - val_f1-score: 0.6642 - val_auc: 0.7355 - val_prc: 0.7391 - lr: 0.0010\n",
            "Epoch 29/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.6923 - precision: 0.6923 - recall: 0.6923 - mcc: 0.4071 - f1-score: 0.6820 - auc: 0.7660 - prc: 0.7663\n",
            "Epoch 00029: val_accuracy did not improve from 0.67769\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.5749 - accuracy: 0.6923 - precision: 0.6923 - recall: 0.6923 - mcc: 0.4071 - f1-score: 0.6820 - auc: 0.7660 - prc: 0.7663 - val_loss: 0.6133 - val_accuracy: 0.6710 - val_precision: 0.6710 - val_recall: 0.6710 - val_mcc: 0.4316 - val_f1-score: 0.6424 - val_auc: 0.7539 - val_prc: 0.7610 - lr: 0.0010\n",
            "Epoch 30/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5432 - accuracy: 0.7183 - precision: 0.7183 - recall: 0.7183 - mcc: 0.4750 - f1-score: 0.7067 - auc: 0.7948 - prc: 0.7970\n",
            "Epoch 00030: val_accuracy improved from 0.67769 to 0.70541, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.5432 - accuracy: 0.7183 - precision: 0.7183 - recall: 0.7183 - mcc: 0.4750 - f1-score: 0.7067 - auc: 0.7948 - prc: 0.7970 - val_loss: 0.5724 - val_accuracy: 0.7054 - val_precision: 0.7054 - val_recall: 0.7054 - val_mcc: 0.4206 - val_f1-score: 0.7034 - val_auc: 0.7800 - val_prc: 0.7816 - lr: 0.0010\n",
            "Epoch 31/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.5005 - accuracy: 0.7543 - precision: 0.7543 - recall: 0.7543 - mcc: 0.5247 - f1-score: 0.7503 - auc: 0.8368 - prc: 0.8366\n",
            "Epoch 00031: val_accuracy improved from 0.70541 to 0.74698, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.5005 - accuracy: 0.7543 - precision: 0.7543 - recall: 0.7543 - mcc: 0.5247 - f1-score: 0.7503 - auc: 0.8368 - prc: 0.8366 - val_loss: 0.5262 - val_accuracy: 0.7470 - val_precision: 0.7470 - val_recall: 0.7470 - val_mcc: 0.5039 - val_f1-score: 0.7455 - val_auc: 0.8339 - val_prc: 0.8328 - lr: 0.0010\n",
            "Epoch 32/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.4208 - accuracy: 0.8133 - precision: 0.8133 - recall: 0.8133 - mcc: 0.6303 - f1-score: 0.8127 - auc: 0.8910 - prc: 0.8891\n",
            "Epoch 00032: val_accuracy improved from 0.74698 to 0.80644, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.4208 - accuracy: 0.8133 - precision: 0.8133 - recall: 0.8133 - mcc: 0.6303 - f1-score: 0.8127 - auc: 0.8910 - prc: 0.8891 - val_loss: 0.4511 - val_accuracy: 0.8064 - val_precision: 0.8064 - val_recall: 0.8064 - val_mcc: 0.6293 - val_f1-score: 0.8047 - val_auc: 0.8870 - val_prc: 0.8879 - lr: 0.0010\n",
            "Epoch 33/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.3162 - accuracy: 0.8719 - precision: 0.8719 - recall: 0.8719 - mcc: 0.7439 - f1-score: 0.8719 - auc: 0.9406 - prc: 0.9388\n",
            "Epoch 00033: val_accuracy improved from 0.80644 to 0.87841, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.3162 - accuracy: 0.8719 - precision: 0.8719 - recall: 0.8719 - mcc: 0.7439 - f1-score: 0.8719 - auc: 0.9406 - prc: 0.9388 - val_loss: 0.3064 - val_accuracy: 0.8784 - val_precision: 0.8784 - val_recall: 0.8784 - val_mcc: 0.7568 - val_f1-score: 0.8784 - val_auc: 0.9451 - val_prc: 0.9434 - lr: 0.0010\n",
            "Epoch 34/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.9043 - precision: 0.9043 - recall: 0.9043 - mcc: 0.8094 - f1-score: 0.9043 - auc: 0.9671 - prc: 0.9659\n",
            "Epoch 00034: val_accuracy improved from 0.87841 to 0.90255, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 282ms/step - loss: 0.2357 - accuracy: 0.9043 - precision: 0.9043 - recall: 0.9043 - mcc: 0.8094 - f1-score: 0.9043 - auc: 0.9671 - prc: 0.9659 - val_loss: 0.2632 - val_accuracy: 0.9025 - val_precision: 0.9025 - val_recall: 0.9025 - val_mcc: 0.8093 - val_f1-score: 0.9021 - val_auc: 0.9617 - val_prc: 0.9580 - lr: 0.0010\n",
            "Epoch 35/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - mcc: 0.8134 - f1-score: 0.9063 - auc: 0.9709 - prc: 0.9706\n",
            "Epoch 00035: val_accuracy did not improve from 0.90255\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.2228 - accuracy: 0.9064 - precision: 0.9064 - recall: 0.9064 - mcc: 0.8134 - f1-score: 0.9063 - auc: 0.9709 - prc: 0.9706 - val_loss: 0.2614 - val_accuracy: 0.8963 - val_precision: 0.8963 - val_recall: 0.8963 - val_mcc: 0.7925 - val_f1-score: 0.8963 - val_auc: 0.9603 - val_prc: 0.9576 - lr: 0.0010\n",
            "Epoch 36/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9357 - precision: 0.9357 - recall: 0.9357 - mcc: 0.8728 - f1-score: 0.9357 - auc: 0.9866 - prc: 0.9862\n",
            "Epoch 00036: val_accuracy improved from 0.90255 to 0.93742, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.1495 - accuracy: 0.9357 - precision: 0.9357 - recall: 0.9357 - mcc: 0.8728 - f1-score: 0.9357 - auc: 0.9866 - prc: 0.9862 - val_loss: 0.1568 - val_accuracy: 0.9374 - val_precision: 0.9374 - val_recall: 0.9374 - val_mcc: 0.8766 - val_f1-score: 0.9373 - val_auc: 0.9844 - val_prc: 0.9830 - lr: 0.0010\n",
            "Epoch 37/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - mcc: 0.9020 - f1-score: 0.9509 - auc: 0.9926 - prc: 0.9925\n",
            "Epoch 00037: val_accuracy improved from 0.93742 to 0.93831, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 283ms/step - loss: 0.1099 - accuracy: 0.9509 - precision: 0.9509 - recall: 0.9509 - mcc: 0.9020 - f1-score: 0.9509 - auc: 0.9926 - prc: 0.9925 - val_loss: 0.1463 - val_accuracy: 0.9383 - val_precision: 0.9383 - val_recall: 0.9383 - val_mcc: 0.8766 - val_f1-score: 0.9383 - val_auc: 0.9867 - val_prc: 0.9845 - lr: 0.0010\n",
            "Epoch 38/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9592 - precision: 0.9592 - recall: 0.9592 - mcc: 0.9188 - f1-score: 0.9592 - auc: 0.9948 - prc: 0.9944\n",
            "Epoch 00038: val_accuracy improved from 0.93831 to 0.94457, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0891 - accuracy: 0.9592 - precision: 0.9592 - recall: 0.9592 - mcc: 0.9188 - f1-score: 0.9592 - auc: 0.9948 - prc: 0.9944 - val_loss: 0.1347 - val_accuracy: 0.9446 - val_precision: 0.9446 - val_recall: 0.9446 - val_mcc: 0.8898 - val_f1-score: 0.9445 - val_auc: 0.9876 - val_prc: 0.9856 - lr: 0.0010\n",
            "Epoch 39/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9621 - precision: 0.9621 - recall: 0.9621 - mcc: 0.9243 - f1-score: 0.9621 - auc: 0.9958 - prc: 0.9957\n",
            "Epoch 00039: val_accuracy improved from 0.94457 to 0.95664, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0824 - accuracy: 0.9621 - precision: 0.9621 - recall: 0.9621 - mcc: 0.9243 - f1-score: 0.9621 - auc: 0.9958 - prc: 0.9957 - val_loss: 0.1170 - val_accuracy: 0.9566 - val_precision: 0.9566 - val_recall: 0.9566 - val_mcc: 0.9138 - val_f1-score: 0.9566 - val_auc: 0.9905 - val_prc: 0.9889 - lr: 0.0010\n",
            "Epoch 40/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9580 - precision: 0.9580 - recall: 0.9580 - mcc: 0.9160 - f1-score: 0.9580 - auc: 0.9940 - prc: 0.9937\n",
            "Epoch 00040: val_accuracy did not improve from 0.95664\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0983 - accuracy: 0.9580 - precision: 0.9580 - recall: 0.9580 - mcc: 0.9160 - f1-score: 0.9580 - auc: 0.9940 - prc: 0.9937 - val_loss: 0.1787 - val_accuracy: 0.9271 - val_precision: 0.9271 - val_recall: 0.9271 - val_mcc: 0.8548 - val_f1-score: 0.9270 - val_auc: 0.9811 - val_prc: 0.9800 - lr: 0.0010\n",
            "Epoch 41/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1212 - accuracy: 0.9493 - precision: 0.9493 - recall: 0.9493 - mcc: 0.8986 - f1-score: 0.9493 - auc: 0.9914 - prc: 0.9912\n",
            "Epoch 00041: val_accuracy did not improve from 0.95664\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.1212 - accuracy: 0.9493 - precision: 0.9493 - recall: 0.9493 - mcc: 0.8986 - f1-score: 0.9493 - auc: 0.9914 - prc: 0.9912 - val_loss: 0.1347 - val_accuracy: 0.9468 - val_precision: 0.9468 - val_recall: 0.9468 - val_mcc: 0.8945 - val_f1-score: 0.9467 - val_auc: 0.9878 - val_prc: 0.9860 - lr: 0.0010\n",
            "Epoch 42/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - mcc: 0.9301 - f1-score: 0.9650 - auc: 0.9960 - prc: 0.9959\n",
            "Epoch 00042: val_accuracy did not improve from 0.95664\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0803 - accuracy: 0.9650 - precision: 0.9650 - recall: 0.9650 - mcc: 0.9301 - f1-score: 0.9650 - auc: 0.9960 - prc: 0.9959 - val_loss: 0.1289 - val_accuracy: 0.9540 - val_precision: 0.9540 - val_recall: 0.9540 - val_mcc: 0.9080 - val_f1-score: 0.9539 - val_auc: 0.9894 - val_prc: 0.9878 - lr: 0.0010\n",
            "Epoch 43/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9637 - precision: 0.9637 - recall: 0.9637 - mcc: 0.9273 - f1-score: 0.9637 - auc: 0.9954 - prc: 0.9952\n",
            "Epoch 00043: val_accuracy did not improve from 0.95664\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0873 - accuracy: 0.9637 - precision: 0.9637 - recall: 0.9637 - mcc: 0.9273 - f1-score: 0.9637 - auc: 0.9954 - prc: 0.9952 - val_loss: 0.1142 - val_accuracy: 0.9535 - val_precision: 0.9535 - val_recall: 0.9535 - val_mcc: 0.9072 - val_f1-score: 0.9535 - val_auc: 0.9920 - val_prc: 0.9915 - lr: 0.0010\n",
            "Epoch 44/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9692 - precision: 0.9692 - recall: 0.9692 - mcc: 0.9384 - f1-score: 0.9692 - auc: 0.9964 - prc: 0.9962\n",
            "Epoch 00044: val_accuracy improved from 0.95664 to 0.96111, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 282ms/step - loss: 0.0754 - accuracy: 0.9692 - precision: 0.9692 - recall: 0.9692 - mcc: 0.9384 - f1-score: 0.9692 - auc: 0.9964 - prc: 0.9962 - val_loss: 0.1058 - val_accuracy: 0.9611 - val_precision: 0.9611 - val_recall: 0.9611 - val_mcc: 0.9222 - val_f1-score: 0.9611 - val_auc: 0.9919 - val_prc: 0.9907 - lr: 0.0010\n",
            "Epoch 45/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9634 - precision: 0.9634 - recall: 0.9634 - mcc: 0.9269 - f1-score: 0.9634 - auc: 0.9948 - prc: 0.9945\n",
            "Epoch 00045: val_accuracy did not improve from 0.96111\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0915 - accuracy: 0.9634 - precision: 0.9634 - recall: 0.9634 - mcc: 0.9269 - f1-score: 0.9634 - auc: 0.9948 - prc: 0.9945 - val_loss: 0.1323 - val_accuracy: 0.9473 - val_precision: 0.9473 - val_recall: 0.9473 - val_mcc: 0.8946 - val_f1-score: 0.9472 - val_auc: 0.9893 - val_prc: 0.9890 - lr: 0.0010\n",
            "Epoch 46/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9661 - precision: 0.9661 - recall: 0.9661 - mcc: 0.9323 - f1-score: 0.9661 - auc: 0.9951 - prc: 0.9948\n",
            "Epoch 00046: val_accuracy did not improve from 0.96111\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0892 - accuracy: 0.9661 - precision: 0.9661 - recall: 0.9661 - mcc: 0.9323 - f1-score: 0.9661 - auc: 0.9951 - prc: 0.9948 - val_loss: 0.1446 - val_accuracy: 0.9388 - val_precision: 0.9388 - val_recall: 0.9388 - val_mcc: 0.8785 - val_f1-score: 0.9388 - val_auc: 0.9889 - val_prc: 0.9885 - lr: 0.0010\n",
            "Epoch 47/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.9723 - precision: 0.9723 - recall: 0.9723 - mcc: 0.9445 - f1-score: 0.9723 - auc: 0.9972 - prc: 0.9970\n",
            "Epoch 00047: val_accuracy did not improve from 0.96111\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0673 - accuracy: 0.9723 - precision: 0.9723 - recall: 0.9723 - mcc: 0.9445 - f1-score: 0.9723 - auc: 0.9972 - prc: 0.9970 - val_loss: 0.1007 - val_accuracy: 0.9562 - val_precision: 0.9562 - val_recall: 0.9562 - val_mcc: 0.9127 - val_f1-score: 0.9562 - val_auc: 0.9928 - val_prc: 0.9920 - lr: 0.0010\n",
            "Epoch 48/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9778 - precision: 0.9778 - recall: 0.9778 - mcc: 0.9556 - f1-score: 0.9778 - auc: 0.9983 - prc: 0.9983\n",
            "Epoch 00048: val_accuracy did not improve from 0.96111\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0543 - accuracy: 0.9778 - precision: 0.9778 - recall: 0.9778 - mcc: 0.9556 - f1-score: 0.9778 - auc: 0.9983 - prc: 0.9983 - val_loss: 0.1170 - val_accuracy: 0.9450 - val_precision: 0.9450 - val_recall: 0.9450 - val_mcc: 0.8921 - val_f1-score: 0.9450 - val_auc: 0.9916 - val_prc: 0.9908 - lr: 0.0010\n",
            "Epoch 49/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9778 - precision: 0.9778 - recall: 0.9778 - mcc: 0.9557 - f1-score: 0.9778 - auc: 0.9980 - prc: 0.9978\n",
            "Epoch 00049: val_accuracy did not improve from 0.96111\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0546 - accuracy: 0.9778 - precision: 0.9778 - recall: 0.9778 - mcc: 0.9557 - f1-score: 0.9778 - auc: 0.9980 - prc: 0.9978 - val_loss: 0.1105 - val_accuracy: 0.9557 - val_precision: 0.9557 - val_recall: 0.9557 - val_mcc: 0.9115 - val_f1-score: 0.9557 - val_auc: 0.9923 - val_prc: 0.9914 - lr: 0.0010\n",
            "Epoch 50/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9788 - precision: 0.9788 - recall: 0.9788 - mcc: 0.9577 - f1-score: 0.9788 - auc: 0.9976 - prc: 0.9973\n",
            "Epoch 00050: val_accuracy improved from 0.96111 to 0.96200, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 282ms/step - loss: 0.0600 - accuracy: 0.9788 - precision: 0.9788 - recall: 0.9788 - mcc: 0.9577 - f1-score: 0.9788 - auc: 0.9976 - prc: 0.9973 - val_loss: 0.0950 - val_accuracy: 0.9620 - val_precision: 0.9620 - val_recall: 0.9620 - val_mcc: 0.9242 - val_f1-score: 0.9620 - val_auc: 0.9937 - val_prc: 0.9930 - lr: 0.0010\n",
            "Epoch 51/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - mcc: 0.9586 - f1-score: 0.9793 - auc: 0.9983 - prc: 0.9982\n",
            "Epoch 00051: val_accuracy improved from 0.96200 to 0.96826, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.0543 - accuracy: 0.9793 - precision: 0.9793 - recall: 0.9793 - mcc: 0.9586 - f1-score: 0.9793 - auc: 0.9983 - prc: 0.9982 - val_loss: 0.1041 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_mcc: 0.9367 - val_f1-score: 0.9683 - val_auc: 0.9931 - val_prc: 0.9919 - lr: 0.0010\n",
            "Epoch 52/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0524 - accuracy: 0.9817 - precision: 0.9817 - recall: 0.9817 - mcc: 0.9633 - f1-score: 0.9817 - auc: 0.9978 - prc: 0.9974\n",
            "Epoch 00052: val_accuracy did not improve from 0.96826\n",
            "69/69 [==============================] - 19s 283ms/step - loss: 0.0524 - accuracy: 0.9817 - precision: 0.9817 - recall: 0.9817 - mcc: 0.9633 - f1-score: 0.9817 - auc: 0.9978 - prc: 0.9974 - val_loss: 0.1030 - val_accuracy: 0.9651 - val_precision: 0.9651 - val_recall: 0.9651 - val_mcc: 0.9304 - val_f1-score: 0.9651 - val_auc: 0.9925 - val_prc: 0.9910 - lr: 0.0010\n",
            "Epoch 53/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9857 - precision: 0.9857 - recall: 0.9857 - mcc: 0.9715 - f1-score: 0.9857 - auc: 0.9991 - prc: 0.9991\n",
            "Epoch 00053: val_accuracy did not improve from 0.96826\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.0370 - accuracy: 0.9857 - precision: 0.9857 - recall: 0.9857 - mcc: 0.9715 - f1-score: 0.9857 - auc: 0.9991 - prc: 0.9991 - val_loss: 0.0956 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_mcc: 0.9368 - val_f1-score: 0.9683 - val_auc: 0.9936 - val_prc: 0.9923 - lr: 0.0010\n",
            "Epoch 54/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - mcc: 0.9762 - f1-score: 0.9881 - auc: 0.9992 - prc: 0.9991\n",
            "Epoch 00054: val_accuracy improved from 0.96826 to 0.97094, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 20s 286ms/step - loss: 0.0325 - accuracy: 0.9881 - precision: 0.9881 - recall: 0.9881 - mcc: 0.9762 - f1-score: 0.9881 - auc: 0.9992 - prc: 0.9991 - val_loss: 0.1148 - val_accuracy: 0.9709 - val_precision: 0.9709 - val_recall: 0.9709 - val_mcc: 0.9421 - val_f1-score: 0.9709 - val_auc: 0.9919 - val_prc: 0.9901 - lr: 0.0010\n",
            "Epoch 55/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9912 - precision: 0.9912 - recall: 0.9912 - mcc: 0.9824 - f1-score: 0.9912 - auc: 0.9996 - prc: 0.9995\n",
            "Epoch 00055: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0263 - accuracy: 0.9912 - precision: 0.9912 - recall: 0.9912 - mcc: 0.9824 - f1-score: 0.9912 - auc: 0.9996 - prc: 0.9995 - val_loss: 0.1124 - val_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_mcc: 0.9393 - val_f1-score: 0.9696 - val_auc: 0.9922 - val_prc: 0.9905 - lr: 0.0010\n",
            "Epoch 56/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9929 - precision: 0.9929 - recall: 0.9929 - mcc: 0.9857 - f1-score: 0.9929 - auc: 0.9997 - prc: 0.9996\n",
            "Epoch 00056: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.0223 - accuracy: 0.9929 - precision: 0.9929 - recall: 0.9929 - mcc: 0.9857 - f1-score: 0.9929 - auc: 0.9997 - prc: 0.9996 - val_loss: 0.1264 - val_accuracy: 0.9705 - val_precision: 0.9705 - val_recall: 0.9705 - val_mcc: 0.9410 - val_f1-score: 0.9705 - val_auc: 0.9908 - val_prc: 0.9884 - lr: 0.0010\n",
            "Epoch 57/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - mcc: 0.9817 - f1-score: 0.9908 - auc: 0.9994 - prc: 0.9993\n",
            "Epoch 00057: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0265 - accuracy: 0.9908 - precision: 0.9908 - recall: 0.9908 - mcc: 0.9817 - f1-score: 0.9908 - auc: 0.9994 - prc: 0.9993 - val_loss: 0.1374 - val_accuracy: 0.9656 - val_precision: 0.9656 - val_recall: 0.9656 - val_mcc: 0.9319 - val_f1-score: 0.9656 - val_auc: 0.9889 - val_prc: 0.9863 - lr: 0.0010\n",
            "Epoch 58/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - mcc: 0.9660 - f1-score: 0.9830 - auc: 0.9980 - prc: 0.9977\n",
            "Epoch 00058: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0508 - accuracy: 0.9830 - precision: 0.9830 - recall: 0.9830 - mcc: 0.9660 - f1-score: 0.9830 - auc: 0.9980 - prc: 0.9977 - val_loss: 0.0931 - val_accuracy: 0.9669 - val_precision: 0.9669 - val_recall: 0.9669 - val_mcc: 0.9345 - val_f1-score: 0.9669 - val_auc: 0.9940 - val_prc: 0.9929 - lr: 0.0010\n",
            "Epoch 59/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9819 - precision: 0.9819 - recall: 0.9819 - mcc: 0.9638 - f1-score: 0.9819 - auc: 0.9978 - prc: 0.9975\n",
            "Epoch 00059: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0539 - accuracy: 0.9819 - precision: 0.9819 - recall: 0.9819 - mcc: 0.9638 - f1-score: 0.9819 - auc: 0.9978 - prc: 0.9975 - val_loss: 0.1401 - val_accuracy: 0.9508 - val_precision: 0.9508 - val_recall: 0.9508 - val_mcc: 0.9033 - val_f1-score: 0.9508 - val_auc: 0.9900 - val_prc: 0.9889 - lr: 0.0010\n",
            "Epoch 60/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0755 - accuracy: 0.9748 - precision: 0.9748 - recall: 0.9748 - mcc: 0.9495 - f1-score: 0.9748 - auc: 0.9960 - prc: 0.9956\n",
            "Epoch 00060: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 20s 284ms/step - loss: 0.0755 - accuracy: 0.9748 - precision: 0.9748 - recall: 0.9748 - mcc: 0.9495 - f1-score: 0.9748 - auc: 0.9960 - prc: 0.9956 - val_loss: 0.1227 - val_accuracy: 0.9678 - val_precision: 0.9678 - val_recall: 0.9678 - val_mcc: 0.9361 - val_f1-score: 0.9678 - val_auc: 0.9917 - val_prc: 0.9900 - lr: 0.0010\n",
            "Epoch 61/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - mcc: 0.9812 - f1-score: 0.9906 - auc: 0.9994 - prc: 0.9993\n",
            "Epoch 00061: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0293 - accuracy: 0.9906 - precision: 0.9906 - recall: 0.9906 - mcc: 0.9812 - f1-score: 0.9906 - auc: 0.9994 - prc: 0.9993 - val_loss: 0.1097 - val_accuracy: 0.9678 - val_precision: 0.9678 - val_recall: 0.9678 - val_mcc: 0.9361 - val_f1-score: 0.9678 - val_auc: 0.9937 - val_prc: 0.9925 - lr: 0.0010\n",
            "Epoch 62/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9885 - auc: 0.9994 - prc: 0.9994\n",
            "Epoch 00062: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0316 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9885 - auc: 0.9994 - prc: 0.9994 - val_loss: 0.1377 - val_accuracy: 0.9571 - val_precision: 0.9571 - val_recall: 0.9571 - val_mcc: 0.9142 - val_f1-score: 0.9571 - val_auc: 0.9896 - val_prc: 0.9882 - lr: 0.0010\n",
            "Epoch 63/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - mcc: 0.9744 - f1-score: 0.9872 - auc: 0.9985 - prc: 0.9982\n",
            "Epoch 00063: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0416 - accuracy: 0.9872 - precision: 0.9872 - recall: 0.9872 - mcc: 0.9744 - f1-score: 0.9872 - auc: 0.9985 - prc: 0.9982 - val_loss: 0.1111 - val_accuracy: 0.9624 - val_precision: 0.9624 - val_recall: 0.9624 - val_mcc: 0.9249 - val_f1-score: 0.9624 - val_auc: 0.9915 - val_prc: 0.9902 - lr: 0.0010\n",
            "Epoch 64/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9879 - precision: 0.9879 - recall: 0.9879 - mcc: 0.9758 - f1-score: 0.9879 - auc: 0.9989 - prc: 0.9988\n",
            "Epoch 00064: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0369 - accuracy: 0.9879 - precision: 0.9879 - recall: 0.9879 - mcc: 0.9758 - f1-score: 0.9879 - auc: 0.9989 - prc: 0.9988 - val_loss: 0.1008 - val_accuracy: 0.9705 - val_precision: 0.9705 - val_recall: 0.9705 - val_mcc: 0.9412 - val_f1-score: 0.9705 - val_auc: 0.9932 - val_prc: 0.9918 - lr: 0.0010\n",
            "Epoch 65/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9885 - auc: 0.9993 - prc: 0.9993\n",
            "Epoch 00065: val_accuracy did not improve from 0.97094\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0329 - accuracy: 0.9885 - precision: 0.9885 - recall: 0.9885 - mcc: 0.9769 - f1-score: 0.9885 - auc: 0.9993 - prc: 0.9993 - val_loss: 0.1051 - val_accuracy: 0.9696 - val_precision: 0.9696 - val_recall: 0.9696 - val_mcc: 0.9393 - val_f1-score: 0.9696 - val_auc: 0.9920 - val_prc: 0.9901 - lr: 0.0010\n",
            "Epoch 66/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9933 - precision: 0.9933 - recall: 0.9933 - mcc: 0.9866 - f1-score: 0.9933 - auc: 0.9998 - prc: 0.9998\n",
            "Epoch 00066: val_accuracy improved from 0.97094 to 0.97273, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.0203 - accuracy: 0.9933 - precision: 0.9933 - recall: 0.9933 - mcc: 0.9866 - f1-score: 0.9933 - auc: 0.9998 - prc: 0.9998 - val_loss: 0.1118 - val_accuracy: 0.9727 - val_precision: 0.9727 - val_recall: 0.9727 - val_mcc: 0.9455 - val_f1-score: 0.9727 - val_auc: 0.9916 - val_prc: 0.9894 - lr: 0.0010\n",
            "Epoch 67/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9956 - mcc: 0.9912 - f1-score: 0.9956 - auc: 0.9999 - prc: 0.9999\n",
            "Epoch 00067: val_accuracy improved from 0.97273 to 0.97407, saving model to my_best_model_5.hdf5\n",
            "69/69 [==============================] - 19s 281ms/step - loss: 0.0139 - accuracy: 0.9956 - precision: 0.9956 - recall: 0.9956 - mcc: 0.9912 - f1-score: 0.9956 - auc: 0.9999 - prc: 0.9999 - val_loss: 0.1220 - val_accuracy: 0.9741 - val_precision: 0.9741 - val_recall: 0.9741 - val_mcc: 0.9483 - val_f1-score: 0.9741 - val_auc: 0.9899 - val_prc: 0.9871 - lr: 0.0010\n",
            "Epoch 68/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - mcc: 0.9946 - f1-score: 0.9973 - auc: 1.0000 - prc: 1.0000\n",
            "Epoch 00068: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0091 - accuracy: 0.9973 - precision: 0.9973 - recall: 0.9973 - mcc: 0.9946 - f1-score: 0.9973 - auc: 1.0000 - prc: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9727 - val_precision: 0.9727 - val_recall: 0.9727 - val_mcc: 0.9455 - val_f1-score: 0.9727 - val_auc: 0.9889 - val_prc: 0.9858 - lr: 0.0010\n",
            "Epoch 69/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - mcc: 0.9950 - f1-score: 0.9975 - auc: 1.0000 - prc: 1.0000\n",
            "Epoch 00069: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 276ms/step - loss: 0.0088 - accuracy: 0.9975 - precision: 0.9975 - recall: 0.9975 - mcc: 0.9950 - f1-score: 0.9975 - auc: 1.0000 - prc: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9732 - val_precision: 0.9732 - val_recall: 0.9732 - val_mcc: 0.9464 - val_f1-score: 0.9732 - val_auc: 0.9864 - val_prc: 0.9824 - lr: 0.0010\n",
            "Epoch 70/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 0.9964 - precision: 0.9964 - recall: 0.9964 - mcc: 0.9928 - f1-score: 0.9964 - auc: 0.9997 - prc: 0.9997\n",
            "Epoch 00070: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0106 - accuracy: 0.9964 - precision: 0.9964 - recall: 0.9964 - mcc: 0.9928 - f1-score: 0.9964 - auc: 0.9997 - prc: 0.9997 - val_loss: 0.1479 - val_accuracy: 0.9736 - val_precision: 0.9736 - val_recall: 0.9736 - val_mcc: 0.9473 - val_f1-score: 0.9736 - val_auc: 0.9866 - val_prc: 0.9828 - lr: 0.0010\n",
            "Epoch 71/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - mcc: 0.9805 - f1-score: 0.9903 - auc: 0.9990 - prc: 0.9988\n",
            "Epoch 00071: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0318 - accuracy: 0.9903 - precision: 0.9903 - recall: 0.9903 - mcc: 0.9805 - f1-score: 0.9903 - auc: 0.9990 - prc: 0.9988 - val_loss: 0.1830 - val_accuracy: 0.9473 - val_precision: 0.9473 - val_recall: 0.9473 - val_mcc: 0.8951 - val_f1-score: 0.9473 - val_auc: 0.9836 - val_prc: 0.9805 - lr: 0.0010\n",
            "Epoch 72/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9868 - precision: 0.9868 - recall: 0.9868 - mcc: 0.9735 - f1-score: 0.9868 - auc: 0.9986 - prc: 0.9984\n",
            "Epoch 00072: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 279ms/step - loss: 0.0434 - accuracy: 0.9868 - precision: 0.9868 - recall: 0.9868 - mcc: 0.9735 - f1-score: 0.9868 - auc: 0.9986 - prc: 0.9984 - val_loss: 0.1326 - val_accuracy: 0.9669 - val_precision: 0.9669 - val_recall: 0.9669 - val_mcc: 0.9339 - val_f1-score: 0.9669 - val_auc: 0.9909 - val_prc: 0.9890 - lr: 0.0010\n",
            "Epoch 73/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9874 - precision: 0.9874 - recall: 0.9874 - mcc: 0.9749 - f1-score: 0.9874 - auc: 0.9990 - prc: 0.9989\n",
            "Epoch 00073: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0358 - accuracy: 0.9874 - precision: 0.9874 - recall: 0.9874 - mcc: 0.9749 - f1-score: 0.9874 - auc: 0.9990 - prc: 0.9989 - val_loss: 0.1301 - val_accuracy: 0.9660 - val_precision: 0.9660 - val_recall: 0.9660 - val_mcc: 0.9321 - val_f1-score: 0.9660 - val_auc: 0.9894 - val_prc: 0.9872 - lr: 0.0010\n",
            "Epoch 74/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9864 - precision: 0.9864 - recall: 0.9864 - mcc: 0.9728 - f1-score: 0.9864 - auc: 0.9981 - prc: 0.9977\n",
            "Epoch 00074: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 280ms/step - loss: 0.0442 - accuracy: 0.9864 - precision: 0.9864 - recall: 0.9864 - mcc: 0.9728 - f1-score: 0.9864 - auc: 0.9981 - prc: 0.9977 - val_loss: 0.1242 - val_accuracy: 0.9683 - val_precision: 0.9683 - val_recall: 0.9683 - val_mcc: 0.9368 - val_f1-score: 0.9683 - val_auc: 0.9908 - val_prc: 0.9886 - lr: 0.0010\n",
            "Epoch 75/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 0.9795 - precision: 0.9795 - recall: 0.9795 - mcc: 0.9590 - f1-score: 0.9795 - auc: 0.9972 - prc: 0.9968\n",
            "Epoch 00075: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0603 - accuracy: 0.9795 - precision: 0.9795 - recall: 0.9795 - mcc: 0.9590 - f1-score: 0.9795 - auc: 0.9972 - prc: 0.9968 - val_loss: 0.1609 - val_accuracy: 0.9499 - val_precision: 0.9499 - val_recall: 0.9499 - val_mcc: 0.9001 - val_f1-score: 0.9499 - val_auc: 0.9832 - val_prc: 0.9802 - lr: 0.0010\n",
            "Epoch 76/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9828 - precision: 0.9828 - recall: 0.9828 - mcc: 0.9656 - f1-score: 0.9828 - auc: 0.9969 - prc: 0.9964\n",
            "Epoch 00076: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 278ms/step - loss: 0.0578 - accuracy: 0.9828 - precision: 0.9828 - recall: 0.9828 - mcc: 0.9656 - f1-score: 0.9828 - auc: 0.9969 - prc: 0.9964 - val_loss: 0.1286 - val_accuracy: 0.9669 - val_precision: 0.9669 - val_recall: 0.9669 - val_mcc: 0.9339 - val_f1-score: 0.9669 - val_auc: 0.9894 - val_prc: 0.9868 - lr: 0.0010\n",
            "Epoch 77/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9933 - precision: 0.9933 - recall: 0.9933 - mcc: 0.9866 - f1-score: 0.9933 - auc: 0.9990 - prc: 0.9988\n",
            "Epoch 00077: val_accuracy did not improve from 0.97407\n",
            "69/69 [==============================] - 19s 277ms/step - loss: 0.0265 - accuracy: 0.9933 - precision: 0.9933 - recall: 0.9933 - mcc: 0.9866 - f1-score: 0.9933 - auc: 0.9990 - prc: 0.9988 - val_loss: 0.1152 - val_accuracy: 0.9678 - val_precision: 0.9678 - val_recall: 0.9678 - val_mcc: 0.9357 - val_f1-score: 0.9678 - val_auc: 0.9914 - val_prc: 0.9894 - lr: 0.0010\n",
            "Epoch 78/80\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - mcc: 0.9900 - f1-score: 0.9950 - auc: 0.9994 - prc: 0.9993\n",
            "Epoch 00078: val_accuracy did not improve from 0.97407\n",
            "Restoring model weights from the end of the best epoch: 58.\n",
            "69/69 [==============================] - 19s 282ms/step - loss: 0.0186 - accuracy: 0.9950 - precision: 0.9950 - recall: 0.9950 - mcc: 0.9900 - f1-score: 0.9950 - auc: 0.9994 - prc: 0.9993 - val_loss: 0.1407 - val_accuracy: 0.9718 - val_precision: 0.9718 - val_recall: 0.9718 - val_mcc: 0.9437 - val_f1-score: 0.9718 - val_auc: 0.9890 - val_prc: 0.9859 - lr: 0.0010\n",
            "Epoch 00078: early stopping\n",
            "==================End training 5========================\n",
            "accuracy: 0.9626352015732547, precision: 0.9603273438889878, recall: 0.9651349901662792, specificity: 0.9649658641753504, mcc: 0.9252820289726972 ,f1-score: 0.962725164972356\n",
            "CPU times: user 1h 48min 6s, sys: 23min 53s, total: 2h 12min\n",
            "Wall time: 1h 57min 18s\n"
          ]
        }
      ],
      "source": [
        "# Remove log directory from last run\n",
        "%%time\n",
        "!rm -rf ./logs\n",
        "session_num = 0\n",
        "seq_size=seq_tensor.shape[1]\n",
        "dim=seq_tensor.shape[2]\n",
        "for epsilon in HP_EPSILON.domain.values:\n",
        "  for learning_rate in HP_LEARNING_RATE.domain.values:\n",
        "    for first_dense in HP_FIRST_DENSE.domain.values:\n",
        "      for kernel_size in HP_KERNEL_SIZE.domain.values:\n",
        "        for pooling_kernel in HP_POOLING_KERNEL.domain.values:\n",
        "          for conv_hidden_dim in HP_CONV_HIDDEN_DIM.domain.values:\n",
        "            for rnn_hidden_dim in HP_RNN_HIDDEN_DIM.domain.values:\n",
        "              for activation in HP_ACTIVATION.domain.values:\n",
        "                for activation_conv in HP_ACTIVATION_CONV.domain.values:\n",
        "                  for regularizer in HP_REGULARIZER.domain.values:\n",
        "                    for conv_padding in HP_CONV_PADDING.domain.values:\n",
        "                      for dropout in HP_DROPOUT.domain.values:\n",
        "                        for batch_size in HP_BATCH_SIZE.domain.values:\n",
        "                          for leaky_relu in HP_LEAKY_RELU.domain.values:\n",
        "                            hparams = {\n",
        "                                HP_EPSILON: epsilon,\n",
        "                                HP_LEARNING_RATE: learning_rate,\n",
        "                                HP_FIRST_DENSE: first_dense,\n",
        "                                HP_KERNEL_SIZE: kernel_size,\n",
        "                                HP_POOLING_KERNEL: pooling_kernel,\n",
        "                                HP_CONV_HIDDEN_DIM: conv_hidden_dim,\n",
        "                                HP_RNN_HIDDEN_DIM: rnn_hidden_dim,\n",
        "                                HP_ACTIVATION: activation,\n",
        "                                HP_ACTIVATION_CONV: activation_conv,\n",
        "                                HP_REGULARIZER: regularizer,\n",
        "                                HP_CONV_PADDING: conv_padding,\n",
        "                                HP_DROPOUT: dropout,\n",
        "                                HP_BATCH_SIZE: batch_size,\n",
        "                                HP_LEAKY_RELU: leaky_relu\n",
        "                            }\n",
        "                            run_name = \"run-%d\" % session_num\n",
        "                            print('--- Starting trial: %s' % run_name)\n",
        "                            print({h.name: hparams[h] for h in hparams})\n",
        "                            run('logs/hparam_tuning/' + run_name, hparams)\n",
        "                            session_num += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = build_model(hparams)\n",
        "model = tf.keras.models.load_model('/content/my_best_model_2.hdf5')"
      ],
      "metadata": {
        "id": "dwB5rnGtVsDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([seq_tensor[seq_index1[test]], seq_tensor[seq_index2[test]]], class_labels[test])"
      ],
      "metadata": {
        "id": "1RTatqmwi6TX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    print(layer.name)"
      ],
      "metadata": {
        "id": "0fN1bss4XMAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2de45c-a53c-46e5-c719-ac871cda27c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "seq1\n",
            "seq2\n",
            "conv1d_84\n",
            "max_pooling1d_140\n",
            "max_pooling1d_145\n",
            "bidirectional_70\n",
            "concatenate_146\n",
            "concatenate_151\n",
            "conv1d_85\n",
            "max_pooling1d_141\n",
            "max_pooling1d_146\n",
            "bidirectional_71\n",
            "concatenate_147\n",
            "concatenate_152\n",
            "conv1d_86\n",
            "max_pooling1d_142\n",
            "max_pooling1d_147\n",
            "bidirectional_72\n",
            "concatenate_148\n",
            "concatenate_153\n",
            "conv1d_87\n",
            "max_pooling1d_143\n",
            "max_pooling1d_148\n",
            "bidirectional_73\n",
            "concatenate_149\n",
            "concatenate_154\n",
            "conv1d_88\n",
            "max_pooling1d_144\n",
            "max_pooling1d_149\n",
            "bidirectional_74\n",
            "concatenate_150\n",
            "concatenate_155\n",
            "conv1d_89\n",
            "global_average_pooling1d_28\n",
            "global_average_pooling1d_29\n",
            "multiply_12\n",
            "tf.math.multiply_6\n",
            "tf.math.cos_3\n",
            "tf.math.multiply_7\n",
            "dense_44\n",
            "dense_45\n",
            "tf.math.sin_3\n",
            "dropout_32\n",
            "dropout_33\n",
            "dense_46\n",
            "tf.__operators__.add_6\n",
            "dropout_34\n",
            "tf.__operators__.add_7\n",
            "dense_47\n",
            "dropout_35\n",
            "dense_48\n",
            "dropout_36\n",
            "dense_49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se hoi hon hon may phan nay vi chua hieu lam"
      ],
      "metadata": {
        "id": "jonPYQx6-PGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################Intermediate Layer prediction (Abstraction features extraction)######################################\n",
        "intermediate_layer_model = Model(inputs=model.input,outputs=model.get_layer('dense_48').output)\n",
        "\n",
        "# Use intermediate layer to transform pairs matrix\n",
        "intermediate_output_p1 = intermediate_layer_model.predict([seq_tensor[seq_index1],seq_tensor[seq_index2]])  \n",
        "\n",
        "\n",
        "p_merge=pd.DataFrame(intermediate_output_p1)    \n",
        "Trainlabels = np.zeros((len(class_labels),))\n",
        "for i in range(len(class_labels)):\n",
        "  if np.allclose(np.array([1., 0.]), class_labels[i]):\n",
        "    Trainlabels[i] = 1.\n",
        "# create dataframe use transformed pairs matrix outputs and labels\n",
        "X_train_feat=pd.concat((p_merge,pd.DataFrame(pd.DataFrame(Trainlabels))),axis=1,ignore_index=True)\n",
        "\n",
        "# write to file dataframe of transformed pairs matrix and labels\n",
        "X_train_feat.to_csv('X_train.csv',header=False, index=False)\n",
        "\n",
        "# read dataframe of transformed pairs matrix and labels\n",
        "Train=pd.read_csv(\"X_train.csv\",header=None)\n",
        "Train=Train.sample(frac=1)\n",
        "\n",
        "X=Train.iloc[:,0:28].values\n",
        "y=Train.iloc[:,28:].values\n",
        "\n",
        "extracted_df=X_train_feat\n",
        "\n",
        "scaler=RobustScaler()\n",
        "# scaler=MinMaxScaler()\n",
        "# scaler = StandardScaler()\n",
        "X=scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "W6JYKHUj7UsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import matthews_corrcoef,accuracy_score, precision_score,recall_score\n",
        "from sklearn.manifold import TSNE\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import lightgbm as lgb\n",
        "import time"
      ],
      "metadata": {
        "id": "pyeOFPG3aw3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f506962-9f08-4ea3-8039-39787f5669ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### Five-fold Cross-Validation ##########################################################\n",
        "kf=StratifiedKFold(n_splits=5, random_state=455, shuffle=True)\n",
        "\n",
        "\n",
        "accuracy = []\n",
        "specificity = []\n",
        "sensitivity = []\n",
        "precision=[]\n",
        "recall=[]\n",
        "m_coef=[]\n",
        "\n",
        "auc_list=[]\n",
        "xgb_fpr_list=[]\n",
        "xgb_tpr_list=[]\n",
        "o=0\n",
        "max_accuracy=float(\"-inf\")\n",
        "xgb_fpr=None\n",
        "xgb_tpr=None\n",
        "\n",
        "y = y.reshape(-1, )\n",
        "training_time = 1\n",
        "for train, test in kf.split(X,y):\n",
        "    o=o+1\n",
        "    model_=LGBMClassifier(learning_rate=.2, gamma=0, max_depth=10, n_estimators=1000)\n",
        "    # model_=XGBClassifier(n_estimators=100)\n",
        "    print(f\"========================== START TRAINING TIME {training_time} ===========================\")\n",
        "    hist=model_.fit(X[train], y[train],eval_set=[(X[test], y[test])],verbose=False)\n",
        "    # hist = lgb.train(param, train_data, num_round, valid_sets=[validation_data])\n",
        "    y_score=model_.predict_proba(X[test])\n",
        "    y_test=tf.keras.utils.to_categorical(y[test]) \n",
        "    \n",
        "    # fpr, tpr, _ = roc_curve(y_test[:,0].ravel(), y_score[:,0].ravel())\n",
        "    auc = metrics.roc_auc_score(y_test, y_score)\n",
        "    auc_list.append(auc)\n",
        "    coef=matthews_corrcoef(y_test.argmax(axis=1), y_score.argmax(axis=1), sample_weight=None)\n",
        "    m_coef.append(coef)\n",
        "    \n",
        "    cm1=confusion_matrix(y_test.argmax(axis=1), y_score.argmax(axis=1))\n",
        "    acc = (cm1[0,0]+cm1[1,1])/(cm1[0,0]+cm1[0,1]+cm1[1,0]+cm1[1,1])\n",
        "    spec= (cm1[0,0])/(cm1[0,0]+cm1[0,1])\n",
        "    sens = (cm1[1,1])/(cm1[1,0]+cm1[1,1])\n",
        "    prec=cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
        "    rec=cm1[1,1]/(cm1[1,1]+cm1[1,0])\n",
        "    sensitivity.append(sens)\n",
        "    specificity.append(spec)\n",
        "    accuracy.append(acc)\n",
        "    precision.append(prec)\n",
        "    recall.append(rec)\n",
        "    # xgb_fpr_list.append(fpr)\n",
        "    # xgb_tpr_list.append(tpr)\n",
        "    print(f\"========================== PERFOMANCE METRICS AT TRAINING TIME {training_time} ===========================\")\n",
        "    print(f\"accuracy: {acc}, specificity: {spec}, sensitivity: {sens}, precision= {prec}, recall: {rec} \")\n",
        "    # if max_accuracy<acc:\n",
        "    #     max_accuracy=acc\n",
        "    #     xgb_fpr=fpr\n",
        "    #     xgb_tpr=tpr\n",
        "    training_time += 1\n",
        "        \n",
        "print(\"====================================== END CROSS VALIDATION ===============================\\n\")\n",
        "xgb_fpr=pd.DataFrame(xgb_fpr)\n",
        "xgb_tpr=pd.DataFrame(xgb_tpr)\n",
        "\n",
        "xgb_fpr.to_csv('fprdnn_xgb.csv',header=False, index=False)\n",
        "xgb_tpr.to_csv('tprdnn_xgb.csv',header=False, index=False)   \n",
        " \n",
        "mean_acc=np.mean(accuracy)\n",
        "std_acc=np.std(accuracy)\n",
        "var_acc=np.var(accuracy)\n",
        "print(\"Accuracy:\"+str(mean_acc)+\" Â± \"+str(std_acc))\n",
        "print(\"Accuracy_Var:\"+str(mean_acc)+\" Â± \"+str(var_acc))\n",
        "mean_spec=np.mean(specificity)\n",
        "std_spec=np.std(specificity)\n",
        "print(\"Specificity:\"+str(mean_spec)+\" Â± \"+str(std_spec))\n",
        "mean_sens=np.mean(sensitivity)\n",
        "std_sens=np.std(sensitivity)\n",
        "print(\"Sensitivity:\"+str(mean_sens)+\" Â± \"+str(std_sens))\n",
        "mean_prec=np.mean(precision)\n",
        "std_prec=np.std(precision)\n",
        "print(\"Precison:\"+str(mean_prec)+\" Â± \"+str(std_prec))\n",
        "mean_rec=np.mean(recall)\n",
        "std_rec=np.std(recall)\n",
        "print(\"Recall:\"+str(mean_rec)+\" Â± \"+str(std_rec))\n",
        "mean_coef=np.mean(m_coef)\n",
        "std_coef=np.std(m_coef)\n",
        "print(\"MCC:\"+str(mean_coef)+\" Â± \"+str(std_coef))\n",
        "\n",
        "print(\"AUC:\"+str(np.mean(auc_list)))\n",
        "\n"
      ],
      "metadata": {
        "id": "TJFn3Uk0Z83o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ec0ecf-569a-4852-db47-7a64c9c18362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================== START TRAINING TIME 1 ===========================\n",
            "========================== PERFOMANCE METRICS AT TRAINING TIME 1 ===========================\n",
            "accuracy: 0.985254691689008, specificity: 0.9883824843610366, sensitivity: 0.9821268990169795, precision= 0.9883093525179856, recall: 0.9821268990169795 \n",
            "========================== START TRAINING TIME 2 ===========================\n",
            "========================== PERFOMANCE METRICS AT TRAINING TIME 2 ===========================\n",
            "accuracy: 0.9857015192135835, specificity: 0.9919571045576407, sensitivity: 0.9794459338695264, precision= 0.9918552036199095, recall: 0.9794459338695264 \n",
            "========================== START TRAINING TIME 3 ===========================\n",
            "========================== PERFOMANCE METRICS AT TRAINING TIME 3 ===========================\n",
            "accuracy: 0.9883772910147519, specificity: 0.9848078641644326, sensitivity: 0.9919499105545617, precision= 0.9849023090586145, recall: 0.9919499105545617 \n",
            "========================== START TRAINING TIME 4 ===========================\n",
            "========================== PERFOMANCE METRICS AT TRAINING TIME 4 ===========================\n",
            "accuracy: 0.9906124273580689, specificity: 0.9883824843610366, sensitivity: 0.9928443649373881, precision= 0.9884238646482636, recall: 0.9928443649373881 \n",
            "========================== START TRAINING TIME 5 ===========================\n",
            "========================== PERFOMANCE METRICS AT TRAINING TIME 5 ===========================\n",
            "accuracy: 0.9874832364774251, specificity: 0.9910554561717353, sensitivity: 0.9839142091152815, precision= 0.990999099909991, recall: 0.9839142091152815 \n",
            "====================================== END CROSS VALIDATION ===============================\n",
            "\n",
            "Accuracy:0.9874858331505674 Â± 0.0019355652224564163\n",
            "Accuracy_Var:0.9874858331505674 Â± 3.746412730382757e-06\n",
            "Specificity:0.9889170787231762 Â± 0.002500865519797959\n",
            "Sensitivity:0.9860562634987474 Â± 0.0053765817538478375\n",
            "Precison:0.9888979659509529 Â± 0.002437069156363505\n",
            "Recall:0.9860562634987474 Â± 0.0053765817538478375\n",
            "MCC:0.9750026526861418 Â± 0.003858261372696793\n",
            "AUC:0.9978352696845171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "def TSNE_extracted():\n",
        "    \n",
        "    pos=extracted_df[extracted_df.iloc[:,-1]==1]\n",
        "    neg=extracted_df[extracted_df.iloc[:,-1]==0]\n",
        "    X_feat=pd.concat([pos,neg])\n",
        "    X_feat=X_feat.iloc[:,:-1]\n",
        "    t=TSNE(n_components=2).fit_transform(X_feat)\n",
        "    pos_t=t[:int(len(t)/2),:]\n",
        "    neg_t=t[int(len(t)/2):,:]\n",
        "    plt.scatter(pos_t[:,0],pos_t[:,1],label=\"Positive\",s=4)\n",
        "    plt.scatter(neg_t[:,0],neg_t[:,1],label=\"Negative\",s=4)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "TSNE_extracted()"
      ],
      "metadata": {
        "id": "L_3asJh5ZtZ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "outputId": "96c5ada1-2de5-47cd-b8a8-582dd4f3f93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhjyFk1XOHNJ"
      },
      "source": [
        "### Tensorboard monitor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjolcDW-w5jY"
      },
      "outputs": [],
      "source": [
        "# %reload_ext tensorboard\n",
        "# %tensorboard --logdir=/content/logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "PIPR-LGBM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}