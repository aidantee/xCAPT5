{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhvt00/PIPR/blob/master/d_script_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6CM-cOfY7fq"
      },
      "source": [
        "### Check GPU hardware"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNNQihr0y9Tv",
        "outputId": "fff9b94f-2b4f-435e-afe9-ce88929dcb55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 24 07:00:01 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    33W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEnKElYqY_-n"
      },
      "source": [
        "### Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgXp5ZBzqqTK",
        "outputId": "e50619d8-6972-49ca-f683-9e229ed62ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dscript\n",
            "  Downloading dscript-0.1.6-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from dscript) (0.11.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from dscript) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dscript) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from dscript) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from dscript) (4.62.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from dscript) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from dscript) (3.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from dscript) (1.10.0+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from dscript) (1.1.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->dscript) (1.5.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dscript) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dscript) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dscript) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dscript) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->dscript) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->dscript) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->dscript) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->dscript) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->dscript) (3.10.0.2)\n",
            "Installing collected packages: dscript\n",
            "Successfully installed dscript-0.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install dscript\n",
        "import sys\n",
        "import argparse\n",
        "import h5py\n",
        "import datetime\n",
        "import subprocess as sp\n",
        "import numpy as np\n",
        "import gc\n",
        "import pandas as pd\n",
        "import gzip as gz\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import matplotlib\n",
        "\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_curve,\n",
        "    average_precision_score,\n",
        "    roc_curve,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from sklearn.metrics import average_precision_score as average_precision\n",
        "\n",
        "import dscript\n",
        "from dscript.utils import PairedDataset, collate_paired_sequences\n",
        "from dscript.models.embedding import (\n",
        "    IdentityEmbed,\n",
        "    FullyConnectedEmbed,\n",
        ")\n",
        "from dscript.models.contact import ContactCNN\n",
        "from dscript.models.interaction import ModelInteraction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GINvBJMPTEyG"
      },
      "source": [
        "### Download data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xSBqCoqXxnx",
        "outputId": "9f489b10-5437-4cfe-fb42-74fe4b55b5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-24 01:35:46--  https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast_train.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 143200 (140K) [text/plain]\n",
            "Saving to: ‘yeast_train.tsv’\n",
            "\n",
            "\ryeast_train.tsv       0%[                    ]       0  --.-KB/s               \ryeast_train.tsv     100%[===================>] 139.84K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-01-24 01:35:46 (13.4 MB/s) - ‘yeast_train.tsv’ saved [143200/143200]\n",
            "\n",
            "--2022-01-24 01:35:46--  https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast_test.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35808 (35K) [text/plain]\n",
            "Saving to: ‘yeast_test.tsv’\n",
            "\n",
            "yeast_test.tsv      100%[===================>]  34.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-24 01:35:46 (85.5 MB/s) - ‘yeast_test.tsv’ saved [35808/35808]\n",
            "\n",
            "--2022-01-24 01:35:46--  https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast.fasta\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1417576 (1.4M) [text/plain]\n",
            "Saving to: ‘yeast.fasta’\n",
            "\n",
            "yeast.fasta         100%[===================>]   1.35M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-01-24 01:35:46 (49.6 MB/s) - ‘yeast.fasta’ saved [1417576/1417576]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast_train.tsv\n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast_test.tsv\n",
        "!wget https://raw.githubusercontent.com/anhvt00/PIPR/master/data/Tunning-architecture-dataset/yeast.fasta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1kMZHiUJWv1"
      },
      "source": [
        "### Embedding fasta sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoyTXCHzS34q",
        "outputId": "b4ed1f6f-1a5a-4fe9-d48b-ca1047e77b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Using CUDA device 0 - Tesla P100-PCIE-16GB\n",
            "# Loading Model...\n",
            "Downloading model lm_v1 from http://cb.csail.mit.edu/cb/dscript/data/models/dscript_lm_v1.pt...\n",
            "# Loading Sequences...\n",
            "100% 1545/1545 [00:00<00:00, 28559.72it/s]\n",
            "# 1545 Sequences Loaded\n",
            "# Approximate Storage Required (varies by average sequence length): ~12.36GB\n",
            "# Storing to /content/human.h5...\n",
            "100% 1545/1545 [04:43<00:00,  5.46it/s]\n"
          ]
        }
      ],
      "source": [
        "!dscript embed --seqs human_test_dict.fasta --outfile /content/human.h5 --device 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsA0AJkFa4W0"
      },
      "source": [
        "### Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKvtwtROeSv-"
      },
      "outputs": [],
      "source": [
        "def add_args(parser):\n",
        "    \"\"\"\n",
        "    Create parser for command line utility.\n",
        "\n",
        "    :meta private:\n",
        "    \"\"\"\n",
        "\n",
        "    data_grp = parser.add_argument_group(\"Data\")\n",
        "    proj_grp = parser.add_argument_group(\"Projection Module\")\n",
        "    contact_grp = parser.add_argument_group(\"Contact Module\")\n",
        "    inter_grp = parser.add_argument_group(\"Interaction Module\")\n",
        "    train_grp = parser.add_argument_group(\"Training\")\n",
        "    misc_grp = parser.add_argument_group(\"Output and Device\")\n",
        "\n",
        "    # Data\n",
        "    data_grp.add_argument(\"--train\", help=\"Training data\", required=True)\n",
        "    data_grp.add_argument(\"--val\", help=\"Validation data\", required=True)\n",
        "    data_grp.add_argument(\"--embedding\", help=\"h5 file with embedded sequences\", required=True)\n",
        "    data_grp.add_argument(\n",
        "        \"--no-augment\",\n",
        "        action=\"store_false\",\n",
        "        dest='augment',\n",
        "        help=\"Set flag to not augment data by adding (B A) for all pairs (A B)\",\n",
        "    )\n",
        "\n",
        "    # Embedding model\n",
        "    proj_grp.add_argument(\n",
        "        \"--projection-dim\",\n",
        "        type=int,\n",
        "        default=100,\n",
        "        help=\"Dimension of embedding projection layer (default: 100)\",\n",
        "    )\n",
        "    proj_grp.add_argument(\n",
        "        \"--dropout-p\",\n",
        "        type=float,\n",
        "        default=0.5,\n",
        "        help=\"Parameter p for embedding dropout layer (default: 0.5)\",\n",
        "    )\n",
        "\n",
        "    # Contact model\n",
        "    contact_grp.add_argument(\n",
        "        \"--hidden-dim\",\n",
        "        type=int,\n",
        "        default=50,\n",
        "        help=\"Number of hidden units for comparison layer in contact prediction (default: 50)\",\n",
        "    )\n",
        "    contact_grp.add_argument(\n",
        "        \"--kernel-width\",\n",
        "        type=int,\n",
        "        default=7,\n",
        "        help=\"Width of convolutional filter for contact prediction (default: 7)\",\n",
        "    )\n",
        "\n",
        "    # Interaction Model\n",
        "    inter_grp.add_argument(\n",
        "        \"--no-w\",\n",
        "        action=\"store_false\",\n",
        "        dest='use_w',\n",
        "        help=\"Don't use weight matrix in interaction prediction model\",\n",
        "    )\n",
        "    inter_grp.add_argument(\n",
        "        \"--pool-width\",\n",
        "        type=int,\n",
        "        default=9,\n",
        "        help=\"Size of max-pool in interaction model (default: 9)\",\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    train_grp.add_argument(\n",
        "        \"--negative-ratio\",\n",
        "        type=int,\n",
        "        default=10,\n",
        "        help=\"Number of negative training samples for each positive training sample (default: 10)\",\n",
        "    )\n",
        "    train_grp.add_argument(\n",
        "        \"--epoch-scale\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Report heldout performance every this many epochs (default: 1)\",\n",
        "    )\n",
        "    train_grp.add_argument(\"--num-epochs\", type=int, default=10, help=\"Number of epochs (default: 10)\")\n",
        "    train_grp.add_argument(\"--batch-size\", type=int, default=25, help=\"Minibatch size (default: 25)\")\n",
        "    train_grp.add_argument(\"--weight-decay\", type=float, default=0, help=\"L2 regularization (default: 0)\")\n",
        "    train_grp.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate (default: 0.001)\")\n",
        "    train_grp.add_argument(\n",
        "        \"--lambda\",\n",
        "        dest=\"lambda_\",\n",
        "        type=float,\n",
        "        default=0.35,\n",
        "        help=\"Weight on the similarity objective (default: 0.35)\",\n",
        "    )\n",
        "\n",
        "    # Output\n",
        "    misc_grp.add_argument(\"-o\", \"--outfile\", help=\"Output file path (default: stdout)\")\n",
        "    misc_grp.add_argument(\"--save-prefix\", help=\"Path prefix for saving models\")\n",
        "    misc_grp.add_argument(\"-d\", \"--device\", type=int, default=-1, help=\"Compute device to use\")\n",
        "    misc_grp.add_argument(\"--checkpoint\", help=\"Checkpoint model to start training from\")\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "def predict_interaction(model, n0, n1, tensors, use_cuda):\n",
        "    \"\"\"\n",
        "    Predict whether a list of protein pairs will interact.\n",
        "\n",
        "    :param model: Model to be trained\n",
        "    :type model: dscript.models.interaction.ModelInteraction\n",
        "    :param n0: First protein names\n",
        "    :type n0: list[str]\n",
        "    :param n1: Second protein names\n",
        "    :type n1: list[str]\n",
        "    :param tensors: Dictionary of protein names to embeddings\n",
        "    :type tensors: dict[str, torch.Tensor]\n",
        "    :param use_cuda: Whether to use GPU\n",
        "    :type use_cuda: bool\n",
        "    \"\"\"\n",
        "\n",
        "    b = len(n0)\n",
        "\n",
        "    p_hat = []\n",
        "    for i in range(b):\n",
        "        z_a = tensors[n0[i]]\n",
        "        z_b = tensors[n1[i]]\n",
        "        if use_cuda:\n",
        "            z_a = z_a.cuda()\n",
        "            z_b = z_b.cuda()\n",
        "\n",
        "        p_hat.append(model.predict(z_a, z_b))\n",
        "    p_hat = torch.stack(p_hat, 0)\n",
        "    return p_hat\n",
        "\n",
        "\n",
        "def predict_cmap_interaction(model, n0, n1, tensors, use_cuda):\n",
        "    \"\"\"\n",
        "    Predict whether a list of protein pairs will interact, as well as their contact map.\n",
        "\n",
        "    :param model: Model to be trained\n",
        "    :type model: dscript.models.interaction.ModelInteraction\n",
        "    :param n0: First protein names\n",
        "    :type n0: list[str]\n",
        "    :param n1: Second protein names\n",
        "    :type n1: list[str]\n",
        "    :param tensors: Dictionary of protein names to embeddings\n",
        "    :type tensors: dict[str, torch.Tensor]\n",
        "    :param use_cuda: Whether to use GPU\n",
        "    :type use_cuda: bool\n",
        "    \"\"\"\n",
        "\n",
        "    b = len(n0)\n",
        "\n",
        "    p_hat = []\n",
        "    c_map_mag = []\n",
        "    for i in range(b):\n",
        "        z_a = tensors[n0[i]]\n",
        "        z_b = tensors[n1[i]]\n",
        "        if use_cuda:\n",
        "            z_a = z_a.cuda()\n",
        "            z_b = z_b.cuda()\n",
        "\n",
        "        cm, ph = model.map_predict(z_a, z_b)\n",
        "        p_hat.append(ph)\n",
        "        c_map_mag.append(torch.mean(cm))\n",
        "    p_hat = torch.stack(p_hat, 0)\n",
        "    c_map_mag = torch.stack(c_map_mag, 0)\n",
        "    return c_map_mag, p_hat\n",
        "\n",
        "\n",
        "def interaction_grad(model, n0, n1, y, tensors, use_cuda, weight=0.35):\n",
        "    \"\"\"\n",
        "    Compute gradient and backpropagate loss for a batch.\n",
        "\n",
        "    :param model: Model to be trained\n",
        "    :type model: dscript.models.interaction.ModelInteraction\n",
        "    :param n0: First protein names\n",
        "    :type n0: list[str]\n",
        "    :param n1: Second protein names\n",
        "    :type n1: list[str]\n",
        "    :param y: Interaction labels\n",
        "    :type y: torch.Tensor\n",
        "    :param tensors: Dictionary of protein names to embeddings\n",
        "    :type tensors: dict[str, torch.Tensor]\n",
        "    :param use_cuda: Whether to use GPU\n",
        "    :type use_cuda: bool\n",
        "    :param weight: Weight on the contact map magnitude objective. BCE loss is :math:`1 - \\\\text{weight}`.\n",
        "    :type weight: float\n",
        "\n",
        "    :return: (Loss, number correct, mean square error, batch size)\n",
        "    :rtype: (torch.Tensor, int, torch.Tensor, int)\n",
        "    \"\"\"\n",
        "\n",
        "    c_map_mag, p_hat = predict_cmap_interaction(model, n0, n1, tensors, use_cuda)\n",
        "    if use_cuda:\n",
        "        y = y.cuda()\n",
        "    y = Variable(y)\n",
        "\n",
        "    bce_loss = F.binary_cross_entropy(p_hat.float(), y.float())\n",
        "    cmap_loss = torch.mean(c_map_mag)\n",
        "    loss = (weight * bce_loss) + ((1 - weight) * cmap_loss)\n",
        "    b = len(p_hat)\n",
        "\n",
        "    # backprop loss\n",
        "    loss.backward()\n",
        "\n",
        "    if use_cuda:\n",
        "        y = y.cpu()\n",
        "        p_hat = p_hat.cpu()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        guess_cutoff = 0.5\n",
        "        p_hat = p_hat.float()\n",
        "        p_guess = (guess_cutoff * torch.ones(b) < p_hat).float()\n",
        "        y = y.float()\n",
        "        correct = torch.sum(p_guess == y).item()\n",
        "        mse = torch.mean((y.float() - p_hat) ** 2).item()\n",
        "    return loss, correct, mse, b\n",
        "\n",
        "\n",
        "def interaction_eval(model, test_iterator, tensors, use_cuda):\n",
        "    \"\"\"\n",
        "    Evaluate test data set performance.\n",
        "\n",
        "    :param model: Model to be trained\n",
        "    :type model: dscript.models.interaction.ModelInteraction\n",
        "    :param test_iterator: Test data iterator\n",
        "    :type test_iterator: torch.utils.data.DataLoader\n",
        "    :param tensors: Dictionary of protein names to embeddings\n",
        "    :type tensors: dict[str, torch.Tensor]\n",
        "    :param use_cuda: Whether to use GPU\n",
        "    :type use_cuda: bool\n",
        "\n",
        "    :return: (Loss, number correct, mean square error, precision, recall, F1 Score, AUPR)\n",
        "    :rtype: (torch.Tensor, int, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor)\n",
        "    \"\"\"\n",
        "    p_hat = []\n",
        "    true_y = []\n",
        "\n",
        "    for n0, n1, y in test_iterator:\n",
        "        p_hat.append(predict_interaction(model, n0, n1, tensors, use_cuda))\n",
        "        true_y.append(y)\n",
        "\n",
        "    y = torch.cat(true_y, 0)\n",
        "    p_hat = torch.cat(p_hat, 0)\n",
        "\n",
        "    if use_cuda:\n",
        "        y.cuda()\n",
        "        p_hat = torch.Tensor([x.cuda() for x in p_hat])\n",
        "        p_hat.cuda()\n",
        "\n",
        "    loss = F.binary_cross_entropy(p_hat.float(), y.float()).item()\n",
        "    b = len(y)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        guess_cutoff = torch.Tensor([0.5]).float()\n",
        "        p_hat = p_hat.float()\n",
        "        y = y.float()\n",
        "        p_guess = (guess_cutoff * torch.ones(b) < p_hat).float()\n",
        "        correct = torch.sum(p_guess == y).item()\n",
        "        mse = torch.mean((y.float() - p_hat) ** 2).item()\n",
        "\n",
        "        tp = torch.sum(y * p_hat).item()\n",
        "        pr = tp / torch.sum(p_hat).item()\n",
        "        re = tp / torch.sum(y).item()\n",
        "        f1 = 2 * pr * re / (pr + re)\n",
        "\n",
        "    y = y.cpu().numpy()\n",
        "    p_hat = p_hat.data.cpu().numpy()\n",
        "\n",
        "    aupr = average_precision(y, p_hat)\n",
        "    return loss, correct, mse, pr, re, f1, aupr\n",
        "\n",
        "\n",
        "def plot_eval_predictions(labels, predictions, path=\"figure\"):\n",
        "    \"\"\"\n",
        "    Plot histogram of positive and negative predictions, precision-recall curve, and receiver operating characteristic curve.\n",
        "\n",
        "    :param y: Labels\n",
        "    :type y: np.ndarray\n",
        "    :param phat: Predicted probabilities\n",
        "    :type phat: np.ndarray\n",
        "    :param path: File prefix for plots to be saved to [default: figure]\n",
        "    :type path: str\n",
        "    \"\"\"\n",
        "\n",
        "    pos_phat = predictions[labels == 1]\n",
        "    neg_phat = predictions[labels == 0]\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "    fig.suptitle(\"Distribution of Predictions\")\n",
        "    ax1.hist(pos_phat)\n",
        "    ax1.set_xlim(0, 1)\n",
        "    ax1.set_title(\"Positive\")\n",
        "    ax1.set_xlabel(\"p-hat\")\n",
        "    ax2.hist(neg_phat)\n",
        "    ax2.set_xlim(0, 1)\n",
        "    ax2.set_title(\"Negative\")\n",
        "    ax2.set_xlabel(\"p-hat\")\n",
        "    plt.savefig(path + \".phat_dist.png\")\n",
        "    plt.close()\n",
        "\n",
        "    precision, recall, pr_thresh = precision_recall_curve(labels, predictions)\n",
        "    aupr = average_precision_score(labels, predictions)\n",
        "    print(\"AUPR:\", aupr)\n",
        "\n",
        "    plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
        "    plt.fill_between(recall, precision, step=\"post\", alpha=0.2, color=\"b\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title(\"Precision-Recall (AUPR: {:.3})\".format(aupr))\n",
        "    plt.savefig(path + \".aupr.png\")\n",
        "    plt.close()\n",
        "\n",
        "    fpr, tpr, roc_thresh = roc_curve(labels, predictions)\n",
        "    auroc = roc_auc_score(labels, predictions)\n",
        "    print(\"AUROC:\", auroc)\n",
        "\n",
        "    plt.step(fpr, tpr, color=\"b\", alpha=0.2, where=\"post\")\n",
        "    plt.fill_between(fpr, tpr, step=\"post\", alpha=0.2, color=\"b\")\n",
        "    plt.xlabel(\"FPR\")\n",
        "    plt.ylabel(\"TPR\")\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title(\"Receiver Operating Characteristic (AUROC: {:.3})\".format(auroc))\n",
        "    plt.savefig(path + \".auroc.png\")\n",
        "    plt.close()\n",
        "\n",
        "def get_state_dict(version=\"human_v1\", verbose=True):\n",
        "    \"\"\"\n",
        "    Download a pre-trained model if not already exists on local device.\n",
        "\n",
        "    :param version: Version of trained model to download [default: human_1]\n",
        "    :type version: str\n",
        "    :param verbose: Print model download status on stdout [default: True]\n",
        "    :type verbose: bool\n",
        "    :return: Path to state dictionary for pre-trained language model\n",
        "    :rtype: str\n",
        "    \"\"\"\n",
        "    state_dict_basename = f\"dscript_{version}.pt\"\n",
        "    state_dict_fullname = f\"/content/{state_dict_basename}\"\n",
        "    state_dict_url = f\"http://cb.csail.mit.edu/cb/dscript/data/models/{state_dict_basename}\"\n",
        "    if not os.path.exists(state_dict_fullname):\n",
        "        try:\n",
        "            import urllib.request\n",
        "            import shutil\n",
        "            if verbose: print(f\"Downloading model {version} from {state_dict_url}...\")\n",
        "            with urllib.request.urlopen(state_dict_url) as response, open(state_dict_fullname, 'wb') as out_file:\n",
        "                shutil.copyfileobj(response, out_file)\n",
        "        except Exception as e:\n",
        "            print(\"Unable to download model - {}\".format(e))\n",
        "            sys.exit(1)\n",
        "    return state_dict_fullname"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrJ2L-MZJlnS"
      },
      "source": [
        "### Prepare dataloader object for train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwTVEz1keycz",
        "outputId": "1413413b-2b31-4a61-b8e2-5e76ae36529e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Called as: /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-ac06099f-20e2-438a-8dc6-1956db621a7d.json\n",
            "# Using CUDA device 0 - Tesla P100-PCIE-16GB\n",
            "# Loading training pairs from human_train.tsv...\n",
            "# Loading testing pairs from human_test.tsv...\n",
            "# Loading embeddings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1038/1038 [00:24<00:00, 42.38it/s]\n"
          ]
        }
      ],
      "source": [
        "# Specify output file\n",
        "output = sys.stdout\n",
        "\n",
        "print(f'# Called as: {\" \".join(sys.argv)}', file=output)\n",
        "if output is not sys.stdout:\n",
        "    print(f'Called as: {\" \".join(sys.argv)}')\n",
        "\n",
        "# Set device for loading data\n",
        "device = 0\n",
        "use_cuda = (device >= 0) and torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    torch.cuda.set_device(device)\n",
        "    print(\n",
        "        f\"# Using CUDA device {device} - {torch.cuda.get_device_name(device)}\",\n",
        "        file=output,\n",
        "    )\n",
        "else:\n",
        "    print(\"# Using CPU\", file=output)\n",
        "    device = \"cpu\"\n",
        "\n",
        "# prepare for loading data\n",
        "batch_size = 1\n",
        "train_fi = 'human_train.tsv'\n",
        "test_fi = 'human_test.tsv'\n",
        "augment = True\n",
        "embedding_h5 = 'human.h5'\n",
        "h5fi = h5py.File(embedding_h5, \"r\")\n",
        "\n",
        "print(f\"# Loading training pairs from {train_fi}...\", file=output)\n",
        "output.flush()\n",
        "\n",
        "# read train index pairs\n",
        "train_df = pd.read_csv(train_fi, sep=\"\\t\", header=None)\n",
        "if augment:\n",
        "    train_n0 = pd.concat((train_df[0], train_df[1]), axis=0).reset_index(drop=True)\n",
        "    train_n1 = pd.concat((train_df[1], train_df[0]), axis=0).reset_index(drop=True)\n",
        "    train_y = torch.from_numpy(pd.concat((train_df[2], train_df[2])).values)\n",
        "else:\n",
        "    train_n0, train_n1 = train_df[0], train_df[1]\n",
        "    train_y = torch.from_numpy(train_df[2].values)\n",
        "\n",
        "print(f\"# Loading testing pairs from {test_fi}...\", file=output)\n",
        "output.flush()\n",
        "\n",
        "# read test index pairs\n",
        "test_df = pd.read_csv(test_fi, sep=\"\\t\", header=None)\n",
        "test_n0, test_n1 = test_df[0], test_df[1]\n",
        "test_y = torch.from_numpy(test_df[2].values)\n",
        "output.flush()\n",
        "\n",
        "# create train index pairs dataloader\n",
        "train_pairs = PairedDataset(train_n0, train_n1, train_y)\n",
        "pairs_train_iterator = torch.utils.data.DataLoader(\n",
        "    train_pairs,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_paired_sequences,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# create test index pairs dataloader\n",
        "test_pairs = PairedDataset(test_n0, test_n1, test_y)\n",
        "pairs_test_iterator = torch.utils.data.DataLoader(\n",
        "    test_pairs,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_paired_sequences,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "output.flush()\n",
        "\n",
        "# load embeddings of sequences into cpu ram \n",
        "print(f\"# Loading embeddings\", file=output)\n",
        "tensors = {}\n",
        "all_proteins = set(train_n0).union(set(train_n1)).union(set(test_n0)).union(set(test_n1))\n",
        "for prot_name in tqdm(all_proteins):\n",
        "    tensors[prot_name] = torch.from_numpy(h5fi[prot_name][:, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOLvYI-yKrp7"
      },
      "source": [
        "### Define architecture of d-script model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX-MWauGKlYd",
        "outputId": "8d5c99f7-ea4e-47db-938d-430d41db75d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Loading model from checkpoint human_v1.sav\n"
          ]
        }
      ],
      "source": [
        "use_cuda = (0 > -1) and torch.cuda.is_available()\n",
        "checkpoint = 'human_v1.sav'\n",
        "if checkpoint is None:\n",
        "    # Create projection module\n",
        "    projection_dim = 100\n",
        "    dropout_p = .5\n",
        "    embedding = FullyConnectedEmbed(6165, projection_dim, dropout=dropout_p)\n",
        "    print(\"# Initializing embedding model with:\", file=output)\n",
        "    print(f\"\\tprojection_dim: {projection_dim}\", file=output)\n",
        "    print(f\"\\tdropout_p: {dropout_p}\", file=output)\n",
        "\n",
        "    # Create contact module\n",
        "    hidden_dim = 50\n",
        "    kernel_width = 7\n",
        "    print(\"# Initializing contact model with:\", file=output)\n",
        "    print(f\"\\thidden_dim: {hidden_dim}\", file=output)\n",
        "    print(f\"\\tkernel_width: {kernel_width}\", file=output)\n",
        "\n",
        "    contact = ContactCNN(projection_dim, hidden_dim, kernel_width)\n",
        "\n",
        "    # Create the full model including projection module and contact module\n",
        "    use_W = True\n",
        "    pool_width = 9\n",
        "    print(\"# Initializing interaction model with:\", file=output)\n",
        "    print(f\"\\tpool_width: {pool_width}\", file=output)\n",
        "    print(f\"\\tuse_w: {use_W}\", file=output)\n",
        "    model = ModelInteraction(embedding, contact, use_W=use_W, pool_size=pool_width)\n",
        "\n",
        "    print(model, file=output)\n",
        "\n",
        "else:\n",
        "    print(\"# Loading model from checkpoint {}\".format(checkpoint), file=output)\n",
        "    model = torch.load(checkpoint)\n",
        "    model.use_cuda = use_cuda\n",
        "\n",
        "if use_cuda:\n",
        "    model = model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmCi_1vHMjwV"
      },
      "source": [
        "### Hyperparameters for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIOHPkX1Ma1Y",
        "outputId": "e53e0af7-174e-4331-b50b-5dc87bf04a62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Using save prefix \"2022-01-24-07-42\"\n",
            "# Training with Adam: lr=0.001, weight_decay=0.0\n",
            "\tnum_epochs: 20\n",
            "\tepoch_scale: 1\n",
            "\tbatch_size: 1\n",
            "\tinteraction weight: 0.35\n",
            "\tcontact map weight: 0.65\n"
          ]
        }
      ],
      "source": [
        "lr = .001\n",
        "wd = .0\n",
        "num_epochs = 20\n",
        "batch_size = 1\n",
        "report_steps = 1\n",
        "inter_weight = .35\n",
        "cmap_weight = 1 - inter_weight\n",
        "digits = int(np.floor(np.log10(num_epochs))) + 1\n",
        "save_prefix = None\n",
        "if save_prefix is None:\n",
        "    save_prefix = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optim = torch.optim.Adam(params, lr=lr, weight_decay=wd)\n",
        "\n",
        "print(f'# Using save prefix \"{save_prefix}\"', file=output)\n",
        "print(f\"# Training with Adam: lr={lr}, weight_decay={wd}\", file=output)\n",
        "print(f\"\\tnum_epochs: {num_epochs}\", file=output)\n",
        "print(f\"\\tepoch_scale: {report_steps}\", file=output)\n",
        "print(f\"\\tbatch_size: {batch_size}\", file=output)\n",
        "print(f\"\\tinteraction weight: {inter_weight}\", file=output)\n",
        "print(f\"\\tcontact map weight: {cmap_weight}\", file=output)\n",
        "output.flush()\n",
        "\n",
        "batch_report_fmt = \"# [{}/{}] training {:.1%}: Loss={:.6}, Accuracy={:.3%}, MSE={:.6}\"\n",
        "epoch_report_fmt = \"# Finished Epoch {}/{}: Loss={:.6}, Accuracy={:.3%}, MSE={:.6}, Precision={:.6}, Recall={:.6}, F1={:.6}, AUPR={:.6}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWAQkuCgMmh1"
      },
      "source": [
        "### Train on training dataset and evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXRbeYG8MhLy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c7b5cc-2f7c-421d-e447-a89e8e94deae"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 880/880 [00:55<00:00, 15.81it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 1/20: Loss=0.547597, Accuracy=90.090%, MSE=0.0982272, Precision=0.123681, Recall=0.00446679, F1=0.00862219, AUPR=0.389835\n",
            "# Saving model to 2022-01-24-07-42_epoch01.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 880/880 [00:55<00:00, 15.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 2/20: Loss=0.56626, Accuracy=90.090%, MSE=0.0984395, Precision=0.0943053, Recall=0.00340927, F1=0.00658064, AUPR=0.156991\n",
            "# Saving model to 2022-01-24-07-42_epoch02.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 880/880 [00:55<00:00, 15.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 3/20: Loss=0.563098, Accuracy=90.090%, MSE=0.0983753, Precision=0.113076, Recall=0.00370661, F1=0.00717792, AUPR=0.316639\n",
            "# Saving model to 2022-01-24-07-42_epoch03.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 880/880 [00:55<00:00, 15.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 4/20: Loss=0.572399, Accuracy=90.090%, MSE=0.0984726, Precision=0.103162, Recall=0.00320891, F1=0.00622421, AUPR=0.44617\n",
            "# Saving model to 2022-01-24-07-42_epoch04.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 880/880 [00:55<00:00, 15.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 5/20: Loss=0.514893, Accuracy=90.090%, MSE=0.0946148, Precision=0.416301, Recall=0.0245684, F1=0.0463985, AUPR=0.415485\n",
            "# Saving model to 2022-01-24-07-42_epoch05.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 880/880 [00:55<00:00, 15.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 6/20: Loss=0.522397, Accuracy=90.991%, MSE=0.0895244, Precision=0.780091, Recall=0.0920547, F1=0.164677, AUPR=0.369144\n",
            "# Saving model to 2022-01-24-07-42_epoch06.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 880/880 [00:55<00:00, 15.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 7/20: Loss=0.255894, Accuracy=94.595%, MSE=0.0486587, Precision=0.949436, Recall=0.476291, F1=0.634354, AUPR=0.735368\n",
            "# Saving model to 2022-01-24-07-42_epoch07.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 880/880 [00:55<00:00, 15.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 8/20: Loss=0.585204, Accuracy=90.090%, MSE=0.0985525, Precision=0.10021, Recall=0.00279648, F1=0.00544111, AUPR=0.235771\n",
            "# Saving model to 2022-01-24-07-42_epoch08.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 880/880 [00:55<00:00, 15.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 9/20: Loss=0.585696, Accuracy=90.090%, MSE=0.0985513, Precision=0.103239, Recall=0.00280053, F1=0.00545313, AUPR=0.271559\n",
            "# Saving model to 2022-01-24-07-42_epoch09.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 880/880 [00:55<00:00, 15.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 10/20: Loss=0.301581, Accuracy=94.595%, MSE=0.0532583, Precision=0.948589, Recall=0.437327, F1=0.598656, AUPR=0.704958\n",
            "# Saving model to 2022-01-24-07-42_epoch10.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 880/880 [00:55<00:00, 15.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 11/20: Loss=0.32653, Accuracy=93.694%, MSE=0.0599212, Precision=0.940226, Recall=0.371762, F1=0.532841, AUPR=0.804167\n",
            "# Saving model to 2022-01-24-07-42_epoch11.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 880/880 [00:55<00:00, 15.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 12/20: Loss=0.596618, Accuracy=89.189%, MSE=0.100978, Precision=0.0340126, Recall=0.00275935, F1=0.00510459, AUPR=0.254801\n",
            "# Saving model to 2022-01-24-07-42_epoch12.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 880/880 [00:55<00:00, 15.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 13/20: Loss=0.604322, Accuracy=90.090%, MSE=0.100784, Precision=0.0354292, Recall=0.0024419, F1=0.00456889, AUPR=0.261205\n",
            "# Saving model to 2022-01-24-07-42_epoch13.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20: 100%|██████████| 880/880 [00:55<00:00, 15.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 14/20: Loss=0.587673, Accuracy=90.090%, MSE=0.0984733, Precision=0.130435, Recall=0.00319144, F1=0.00623044, AUPR=0.405639\n",
            "# Saving model to 2022-01-24-07-42_epoch14.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20: 100%|██████████| 880/880 [00:55<00:00, 15.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 15/20: Loss=0.263398, Accuracy=94.595%, MSE=0.0489413, Precision=0.757365, Recall=0.590466, F1=0.663582, AUPR=0.791769\n",
            "# Saving model to 2022-01-24-07-42_epoch15.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20: 100%|██████████| 880/880 [00:55<00:00, 15.83it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 16/20: Loss=0.316557, Accuracy=92.793%, MSE=0.062671, Precision=0.643753, Recall=0.625234, F1=0.634358, AUPR=0.746699\n",
            "# Saving model to 2022-01-24-07-42_epoch16.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20: 100%|██████████| 880/880 [00:55<00:00, 15.84it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 17/20: Loss=0.584278, Accuracy=90.090%, MSE=0.0983055, Precision=0.179144, Recall=0.00404348, F1=0.00790846, AUPR=0.350467\n",
            "# Saving model to 2022-01-24-07-42_epoch17.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20: 100%|██████████| 880/880 [00:55<00:00, 15.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 18/20: Loss=0.538839, Accuracy=90.991%, MSE=0.0892661, Precision=0.615871, Recall=0.180248, F1=0.278877, AUPR=0.413039\n",
            "# Saving model to 2022-01-24-07-42_epoch18.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20: 100%|██████████| 880/880 [00:55<00:00, 15.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 19/20: Loss=0.550474, Accuracy=90.991%, MSE=0.0912651, Precision=0.651481, Recall=0.0553717, F1=0.102068, AUPR=0.45325\n",
            "# Saving model to 2022-01-24-07-42_epoch19.sav\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20: 100%|██████████| 880/880 [00:55<00:00, 15.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Finished Epoch 20/20: Loss=0.461964, Accuracy=90.090%, MSE=0.0902703, Precision=0.570685, Recall=0.120456, F1=0.198924, AUPR=0.709059\n",
            "# Saving model to 2022-01-24-07-42_epoch20.sav\n"
          ]
        }
      ],
      "source": [
        "N = len(pairs_train_iterator) * batch_size\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    n = 0\n",
        "    loss_accum = 0\n",
        "    acc_accum = 0\n",
        "    mse_accum = 0\n",
        "\n",
        "    # Train batches\n",
        "    for (z0, z1, y) in tqdm(pairs_train_iterator, desc=f\"Epoch {epoch+1}/{num_epochs}\",total=len(pairs_train_iterator)):\n",
        "\n",
        "        loss, correct, mse, b = interaction_grad(model, z0, z1, y, tensors, use_cuda, weight=inter_weight)\n",
        "\n",
        "        n += b\n",
        "        delta = b * (loss - loss_accum)\n",
        "        loss_accum += delta / n\n",
        "\n",
        "        delta = correct - b * acc_accum\n",
        "        acc_accum += delta / n\n",
        "\n",
        "        delta = b * (mse - mse_accum)\n",
        "        mse_accum += delta / n\n",
        "\n",
        "        report = (n - b) // 100 < n // 100\n",
        "\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        model.clip()\n",
        "\n",
        "        if report:\n",
        "            tokens = [\n",
        "                epoch + 1,\n",
        "                num_epochs,\n",
        "                n / N,\n",
        "                loss_accum,\n",
        "                acc_accum,\n",
        "                mse_accum,\n",
        "            ]\n",
        "            if output is not sys.stdout:\n",
        "                print(batch_report_fmt.format(*tokens), file=output)\n",
        "                output.flush()\n",
        "\n",
        "    if (epoch + 1) % report_steps == 0:\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            (\n",
        "                inter_loss,\n",
        "                inter_correct,\n",
        "                inter_mse,\n",
        "                inter_pr,\n",
        "                inter_re,\n",
        "                inter_f1,\n",
        "                inter_aupr,\n",
        "            ) = interaction_eval(model, pairs_test_iterator, tensors, use_cuda)\n",
        "            tokens = [\n",
        "                epoch + 1,\n",
        "                num_epochs,\n",
        "                inter_loss,\n",
        "                inter_correct / (len(pairs_test_iterator) * batch_size),\n",
        "                inter_mse,\n",
        "                inter_pr,\n",
        "                inter_re,\n",
        "                inter_f1,\n",
        "                inter_aupr,\n",
        "            ]\n",
        "            print(epoch_report_fmt.format(*tokens), file=output)\n",
        "            output.flush()\n",
        "\n",
        "        # Save the model\n",
        "        if save_prefix is not None:\n",
        "            save_path = save_prefix + \"_epoch\" + str(epoch + 1).zfill(digits) + \".sav\"\n",
        "            print(f\"# Saving model to {save_path}\", file=output)\n",
        "            model.cpu()\n",
        "            torch.save(model, save_path)\n",
        "            if use_cuda:\n",
        "                model.cuda()\n",
        "\n",
        "    # collect variable by garbage collector and empty cache in cuda\n",
        "    output.flush()\n",
        "\n",
        "if save_prefix is not None:\n",
        "    save_path = save_prefix + \"_final.sav\"\n",
        "    print(f\"# Saving final model to {save_path}\", file=output)\n",
        "    model.cpu()\n",
        "    torch.save(model, save_path)\n",
        "    if use_cuda:\n",
        "        model.cuda()\n",
        "\n",
        "output.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation of pretrained model on new data "
      ],
      "metadata": {
        "id": "hY0ETqTOOikx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Device\n",
        "device = 0\n",
        "use_cuda = (device >= 0) and torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    torch.cuda.set_device(device)\n",
        "    print(f\"# Using CUDA device {device} - {torch.cuda.get_device_name(device)}\")\n",
        "else:\n",
        "    print(\"# Using CPU\")\n",
        "\n",
        "# Load Model\n",
        "model_path = 'human_v1.sav'\n",
        "if use_cuda:\n",
        "    model = torch.load(model_path).cuda()\n",
        "else:\n",
        "    model = torch.load(model_path).cpu()\n",
        "    model.use_cuda = False\n",
        "\n",
        "embeddingPath = 'human.h5'\n",
        "h5fi = h5py.File(embeddingPath, \"r\")\n",
        "\n",
        "# Load Pairs\n",
        "test_fi = 'human_test_100_pos.tsv'\n",
        "test_df = pd.read_csv(test_fi, sep=\"\\t\", header=None)\n",
        "\n",
        "outPath = None\n",
        "if outPath is None:\n",
        "    outPath = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
        "else:\n",
        "    outPath = args.outfile\n",
        "outFile = open(outPath + \".predictions.tsv\", \"w+\")\n",
        "\n",
        "allProteins = set(test_df[0]).union(test_df[1])\n",
        "\n",
        "seqEmbDict = {}\n",
        "for i in tqdm(allProteins, desc=\"Loading embeddings\"):\n",
        "    seqEmbDict[i] = torch.from_numpy(h5fi[i][:]).float()\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    phats = []\n",
        "    labels = []\n",
        "    for _, (n0, n1, label) in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Predicting pairs\"):\n",
        "        try:\n",
        "            p0 = seqEmbDict[n0]\n",
        "            p1 = seqEmbDict[n1]\n",
        "            if use_cuda:\n",
        "                p0 = p0.cuda()\n",
        "                p1 = p1.cuda()\n",
        "\n",
        "            pred = model.predict(p0, p1).item()\n",
        "            phats.append(pred)\n",
        "            labels.append(label)\n",
        "            print(\"{}\\t{}\\t{}\\t{:.5}\".format(n0, n1, label, pred), file=outFile)\n",
        "        except Exception as e:\n",
        "            sys.stderr.write(\"{} x {} - {}\".format(n0, n1, e))\n",
        "\n",
        "phats = np.array(phats)\n",
        "labels = np.array(labels)\n",
        "plot_eval_predictions(labels, phats, outPath)\n",
        "\n",
        "outFile.close()\n",
        "h5fi.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALDq1rYYOdSz",
        "outputId": "e85b2285-9d60-4bf2-815f-31c992f2a87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Using CUDA device 0 - Tesla P100-PCIE-16GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading embeddings: 100%|██████████| 1033/1033 [00:07<00:00, 138.99it/s]\n",
            "Predicting pairs: 100%|██████████| 550/550 [00:07<00:00, 74.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUPR: 0.6004142210493548\n",
            "AUROC: 0.8289000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp human_test_100.tsv human_test.tsv"
      ],
      "metadata": {
        "id": "hU3aGJu3-AAj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "d-script-model-2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}